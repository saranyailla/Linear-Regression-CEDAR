{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from itertools import islice\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the Training and Target datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingPercent = 80\n",
    "# ValidationPercent = 10\n",
    "# TestPercent = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the methods for Training, Testing and Validation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def concatenate(filepath1,filepath2,filepath3,noOfLines):\n",
    "#     with open(filepath1, 'w',newline='') as myfile:\n",
    "#         wr = csv.writer(myfile)\n",
    "#         with open(filepath2, 'r') as fi:\n",
    "#             reader = csv.reader(fi)\n",
    "#             writer = csv.writer(fi)\n",
    "#             dataRows = []\n",
    "#             for row in islice(reader,1,noOfLines):\n",
    "#                 #print(len(fi.readlines()))\n",
    "#                 dataRow=[]\n",
    "#                 dataRow.append(row[0])\n",
    "#                 dataRow.append(row[1])\n",
    "#                 dataRow.append(int(row[2]))\n",
    "#                 for column in islice(row,0,2):\n",
    "#                     with open(filepath3, 'r') as fi2:\n",
    "#                         reader1 = csv.reader(fi2)\n",
    "#                         for row2 in islice(reader1,1,1028):\n",
    "#                             for column2 in row2:\n",
    "#                                  if(column2==column):\n",
    "#                                     content = list(row2[i] for i in range(2,11))\n",
    "#                                     for word in content:\n",
    "#                                         dataRow.append(word)\n",
    "#                 dataRows.append(dataRow)\n",
    "#             # wr.writerow(dataRow)\n",
    "#             #print(dataRows)\n",
    "#             wr.writerows(dataRows)\n",
    "#            # print(dataRow)\n",
    "            \n",
    "# def subtract(filepath1,filepath2,noOfLines):\n",
    "#     with open(filepath1, 'w',newline='') as myfile:\n",
    "#         wr = csv.writer(myfile)\n",
    "#         with open(filepath2, 'r') as fi:\n",
    "#             #c=(len(fi.readlines()))\n",
    "#             reader = csv.reader(fi)\n",
    "#             writer = csv.writer(fi)\n",
    "        \n",
    "#             for row in islice(reader,0,noOfLines):\n",
    "#                 list=[]\n",
    "    \n",
    "#                 list.append(row[0])\n",
    "#                 list.append(row[1])\n",
    "#                 list.append(int(row[2]))\n",
    "#                 for i in range(2,11):\n",
    "#                     list.append(abs(int(row[i])-int(row[i+9])))\n",
    "#                 wr.writerow(list)\n",
    "def concatenate(filepath1,filepath2,filepath3,noOfLines):\n",
    "    with open(filepath1, 'w',newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        with open(filepath2, 'r') as fi:\n",
    "            reader = csv.reader(fi)\n",
    "            writer = csv.writer(fi)\n",
    "            for row in islice(reader,1,noOfLines):\n",
    "                #print(len(fi.readlines()))\n",
    "                dataRow = []\n",
    "                dataRow.append(row[0])\n",
    "                dataRow.append(row[1])\n",
    "                dataRow.append(int(row[2]))\n",
    "                for column in islice(row,0,2):\n",
    "                    with open(filepath3, 'r') as fi2:\n",
    "                        reader1 = csv.reader(fi2)\n",
    "                        for row2 in islice(reader1,1,14072):\n",
    "                            for column2 in row2:\n",
    "                                 if(column2==column):\n",
    "                                    content = list(row2[i] for i in range(1,513))\n",
    "                                    for word in content:\n",
    "                                        dataRow.append(word)\n",
    "    \n",
    "                wr.writerow(dataRow)\n",
    "\n",
    "def subtract(filepath1,filepath2,noOfLines):\n",
    "    with open(filepath1, 'w',newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        with open(filepath2, 'r') as fi:\n",
    "            #c=(len(fi.readlines()))\n",
    "            reader = csv.reader(fi)\n",
    "            writer = csv.writer(fi)\n",
    "        \n",
    "            for row in islice(reader,0,noOfLines):\n",
    "                list=[]\n",
    "                list.append(row[0])\n",
    "                list.append(row[1])\n",
    "                list.append(int(row[2]))\n",
    "                for i in range(2,514):\n",
    "                    list.append(abs(int(row[i])-int(row[i+512])))\n",
    "                wr.writerow(list)               \n",
    "\n",
    "def combine_pairs(filepath1,filepath2,filepath3):\n",
    "    fout=open(filepath1,\"w\",newline='')\n",
    "    for line in open(filepath2):\n",
    "         fout.write(line)\n",
    "            \n",
    "    with open(filepath3, \"r\") as source:\n",
    "        lines = [line for line in source]\n",
    "    random_choice = random.sample(lines, 500)\n",
    "    for l in random_choice:\n",
    "        fout.write(l)\n",
    "    fout.close()\n",
    "    \n",
    "def shuffled_pairs(filepath1,filepath2):\n",
    "    \n",
    "    fid = open(filepath2, \"r\")\n",
    "    li = fid.readlines()\n",
    "    fid.close()\n",
    "    #print(li)\n",
    "\n",
    "    random.shuffle(li)\n",
    "    #print(li)\n",
    "\n",
    "    fid = open(filepath1, \"w\",newline='')\n",
    "    fid.writelines(li)\n",
    "    fid.close()\n",
    "\n",
    "def GetTarget(filePath):\n",
    "    t = []\n",
    "    with open(filePath, 'rU') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:  \n",
    "            t.append(float(row[2]))\n",
    "        #print(\"Raw Training Generated..\")\n",
    "    \n",
    "    return t\n",
    "\n",
    "def GetRawData(filePath):    \n",
    "    dataMatrix = [] \n",
    "    with open(filePath, 'rU') as fi:\n",
    "        reader = csv.reader(fi)\n",
    "        for row in reader:\n",
    "            dataRow = []\n",
    "            for column in row[3:]:\n",
    "                dataRow.append(float(column))\n",
    "            dataMatrix.append(dataRow)   \n",
    "    \n",
    "    \n",
    "    #dataMatrix = np.delete(dataMatrix, [0,1,2], axis=1)\n",
    "    dataMatrix = np.transpose(dataMatrix)     \n",
    "    \n",
    "    \n",
    "    return dataMatrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Generating training target from raw target by restricting the length of the training target to only 80% of whole raw target.\n",
    "def GenerateTrainingTarget(rawTraining,TrainingPercent):\n",
    "    TrainingLen = int(math.ceil(len(rawTraining)*(TrainingPercent*0.01)))\n",
    "    #From the beginning to the calculated training length\n",
    "    t           = rawTraining[:TrainingLen]\n",
    "   # print(str(TrainingPercent) + \"% Training Target Generated..\")\n",
    "    return t\n",
    "\n",
    "\n",
    "#Generating training data from whole dataset by restricting the length of the  training dataset to be only 80% of whole raw dataset.\n",
    "def GenerateTrainingDataMatrix(rawData, TrainingPercent):\n",
    "    T_len = int(math.ceil(len(rawData[0])*0.01*TrainingPercent))\n",
    "    d2 = rawData[:,0:T_len]\n",
    "   # print(str(TrainingPercent) + \"% Training Data Generated..\")\n",
    "    return d2\n",
    "\n",
    "\n",
    "#Generating validation/testing target from raw target by restricting the length of the validation/testing target to be only 10% of whole raw target.\n",
    "def GenerateTargetData(rawData,ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData[0])*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    dataMatrix = rawData[:,TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Data Generated..\")  \n",
    "    return dataMatrix\n",
    "\n",
    "#Generating validation/testing data from whole dataset by restricting the length of the validation/testing dataset to only 10% of whole dataset\n",
    "def GenerateTargetVector(rawData,ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData)*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    t =rawData[TrainingCount+1:V_End]\n",
    "    return t\n",
    "\n",
    "def GenerateBigSigma(Data, MuMatrix,TrainingPercent):\n",
    "    BigSigma    = np.zeros((len(Data),len(Data)))\n",
    "    DataT       = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))        \n",
    "    varVect     = []\n",
    "    for i in range(0,len(DataT[0])):\n",
    "        vct = []\n",
    "        for j in range(0,int(TrainingLen)):\n",
    "            vct.append(Data[i][j])    \n",
    "        varVect.append(np.var(vct))\n",
    "    \n",
    "    for j in range(len(Data)):\n",
    "        BigSigma[j][j] = varVect[j]\n",
    "#     if IsSynthetic == True:\n",
    "#         BigSigma = np.dot(3,BigSigma)\n",
    "#     else:\n",
    "    BigSigma = np.dot(200,BigSigma)\n",
    "    ##print (\"BigSigma Generated..\")\n",
    "    return BigSigma\n",
    "\n",
    "def GetScalar(DataRow,MuRow, BigSigInv):  \n",
    "    R = np.subtract(DataRow,MuRow)\n",
    "    T = np.dot(BigSigInv,np.transpose(R))  \n",
    "    L = np.dot(R,T)\n",
    "    return L\n",
    "\n",
    "def GetRadialBasisOut(DataRow,MuRow, BigSigInv):    \n",
    "    phi_x = math.exp(-0.5*GetScalar(DataRow,MuRow,BigSigInv))\n",
    "    return phi_x\n",
    "\n",
    "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 80):\n",
    "    DataT = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
    "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
    "    BigSigInv = np.linalg.pinv(BigSigma)\n",
    "    for  C in range(0,len(MuMatrix)):\n",
    "        for R in range(0,int(TrainingLen)):\n",
    "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
    "    #print (\"PHI Generated..\")\n",
    "    return PHI\n",
    "\n",
    "def GetWeightsClosedForm(PHI, T, Lambda):\n",
    "    Lambda_I = np.identity(len(PHI[0]))\n",
    "    for i in range(0,len(PHI[0])):\n",
    "        Lambda_I[i][i] = Lambda\n",
    "    PHI_T       = np.transpose(PHI)\n",
    "    PHI_SQR     = np.dot(PHI_T,PHI)\n",
    "    PHI_SQR_LI  = np.add(Lambda_I,PHI_SQR)\n",
    "    PHI_SQR_INV = np.linalg.pinv(PHI_SQR_LI)\n",
    "    INTER       = np.dot(PHI_SQR_INV, PHI_T)\n",
    "    W           = np.dot(INTER, T)\n",
    "    ##print (\"Training Weights Generated..\")\n",
    "    return W\n",
    "\n",
    "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 80):\n",
    "    DataT = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
    "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
    "    BigSigInv = np.linalg.inv(BigSigma)\n",
    "    for  C in range(0,len(MuMatrix)):\n",
    "        for R in range(0,int(TrainingLen)):\n",
    "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
    "    #print (\"PHI Generated..\")\n",
    "    return PHI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of ConcatenatedTrainingTarget is  (1266,)\n",
      "The shape of ConcatenatedTrainingDataMatrix is  (1266, 18)\n",
      "The shape of ConcatenatedValidationTarget is  (158,)\n",
      "The shape of ConcatenatedValidationDataMatrix is  (158, 18)\n",
      "The shape of ConcatenatedTestingTarget is  (157,)\n",
      "The shape of ConcatenatedTestingDataMatrix is  (157, 18)\n",
      "The shape of SubtractedTrainingTarget is  (1266,)\n",
      "The shape of SubtractedTrainingDataMatrix is  (1266, 9)\n",
      "The shape of SubtractedValidationTarget is  (158,)\n",
      "The shape of SubtractedValidationDataMatrix is  (158, 9)\n",
      "The shape of SubtractedTestingTarget is  (157,)\n",
      "The shape of SubtractedTestingDataMatrix is  (157, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ravali pinnaka\\desktop\\python\\lib\\site-packages\\ipykernel_launcher.py:115: DeprecationWarning: 'U' mode is deprecated\n",
      "c:\\users\\ravali pinnaka\\desktop\\python\\lib\\site-packages\\ipykernel_launcher.py:125: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    }
   ],
   "source": [
    "# concatenate('humanobserved/concatenated_same_pairs.csv','humanobserved/same_pairs.csv','humanobserved/HumanObserved-Features-Data.csv',792)\n",
    "# subtract('humanobserved/subtracted_same_pairs.csv','humanobserved/concatenated_same_pairs.csv',791)\n",
    "# concatenate('humanobserved/concatenated_diff_pairs.csv','humanobserved/diffn_pairs.csv','humanobserved/HumanObserved-Features-Data.csv',3000)\n",
    "# subtract('humanobserved/subtracted_diff_pairs.csv','humanobserved/concatenated_diff_pairs.csv',3000)\n",
    "# combine_pairs('humanobserved/concatenated_pairs.csv','humanobserved/concatenated_same_pairs.csv','humanobserved/concatenated_diff_pairs.csv');\n",
    "# combine_pairs('humanobserved/subtracted_pairs.csv','humanobserved/subtracted_same_pairs.csv','humanobserved/subtracted_diff_pairs.csv');\n",
    "# shuffled_pairs('humanobserved/shuffled_concatenated_pairs.csv','humanobserved/concatenated_pairs.csv');\n",
    "# shuffled_pairs('humanobserved/shuffled_subtracted_pairs.csv','humanobserved/subtracted_pairs.csv');\n",
    "\n",
    "#RawTarget\n",
    "rawConcatenatedTarget = GetTarget('humanobserved/shuffled_concatenated_pairs.csv')\n",
    "rawSubtractedTarget = GetTarget('humanobserved/shuffled_subtracted_pairs.csv')\n",
    "#RawData\n",
    "rawConcatenatedData=GetRawData('humanobserved/shuffled_concatenated_pairs.csv')\n",
    "rawSubtractedData=GetRawData('humanobserved/shuffled_subtracted_pairs.csv')\n",
    "# print(rawConcatenatedData.shape)\n",
    "# print(rawSubtractedData.shape)\n",
    "#splitting\n",
    "TrainingPercent=80;\n",
    "ValidationPercent=10;\n",
    "TestPercent=10;\n",
    "ConcatenatedTrainingTarget = np.array(GenerateTrainingTarget(rawConcatenatedTarget,TrainingPercent))\n",
    "ConcatenatedTrainingDataMatrix   = np.transpose(GenerateTrainingDataMatrix(rawConcatenatedData,TrainingPercent))\n",
    "print(\"The shape of ConcatenatedTrainingTarget is \", ConcatenatedTrainingTarget.shape)\n",
    "print(\"The shape of ConcatenatedTrainingDataMatrix is \",ConcatenatedTrainingDataMatrix.shape)\n",
    "\n",
    "ConcatenatedValidationTarget = np.array(GenerateTargetVector(rawConcatenatedTarget,ValidationPercent, (len(ConcatenatedTrainingTarget))))\n",
    "ConcatenatedValidationDataMatrix    =np.transpose(GenerateTargetData(rawConcatenatedData,ValidationPercent, (len(ConcatenatedTrainingTarget))))\n",
    "\n",
    "print(\"The shape of ConcatenatedValidationTarget is \", ConcatenatedValidationTarget.shape)\n",
    "print(\"The shape of ConcatenatedValidationDataMatrix is \",ConcatenatedValidationDataMatrix.shape)\n",
    "ConcatenatedTestingTarget = np.array(GenerateTargetVector(rawConcatenatedTarget,TestPercent, (len(ConcatenatedTrainingTarget)+len(ConcatenatedValidationTarget))))\n",
    "ConcatenatedTestingDataMatrix = np.transpose(GenerateTargetData(rawConcatenatedData,TestPercent, (len(ConcatenatedTrainingTarget)+len(ConcatenatedValidationTarget))))\n",
    "\n",
    "print(\"The shape of ConcatenatedTestingTarget is \", ConcatenatedTestingTarget.shape)\n",
    "print(\"The shape of ConcatenatedTestingDataMatrix is \",ConcatenatedTestingDataMatrix.shape)\n",
    "#subtracted\n",
    "\n",
    "SubtractedTrainingTarget = np.array(GenerateTrainingTarget(rawSubtractedTarget,TrainingPercent))\n",
    "SubtractedTrainingDataMatrix   = np.transpose(GenerateTrainingDataMatrix(rawSubtractedData,TrainingPercent))\n",
    "SubtractedValidationTarget = np.array(GenerateTargetVector(rawSubtractedTarget,ValidationPercent, (len(SubtractedTrainingTarget))))\n",
    "SubtractedValidationDataMatrix    = np.transpose(GenerateTargetData(rawSubtractedData,ValidationPercent, (len(SubtractedTrainingTarget))))\n",
    "SubtractedTestingTarget = np.array(GenerateTargetVector(rawSubtractedTarget,TestPercent, (len(SubtractedTrainingTarget)+len(SubtractedValidationTarget))))\n",
    "SubtractedTestingDataMatrix = np.transpose(GenerateTargetData(rawSubtractedData,TestPercent, (len(SubtractedTrainingTarget)+len(SubtractedValidationTarget))))\n",
    "print(\"The shape of SubtractedTrainingTarget is \", SubtractedTrainingTarget.shape)\n",
    "print(\"The shape of SubtractedTrainingDataMatrix is \",SubtractedTrainingDataMatrix.shape)\n",
    "print(\"The shape of SubtractedValidationTarget is \", SubtractedValidationTarget.shape)\n",
    "print(\"The shape of SubtractedValidationDataMatrix is \",SubtractedValidationDataMatrix.shape)\n",
    "print(\"The shape of SubtractedTestingTarget is \", SubtractedTestingTarget.shape)\n",
    "print(\"The shape of SubtractedTestingDataMatrix is \",SubtractedTestingDataMatrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Keras model on Human Observed Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model on concatenated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_size = 18\n",
    "drop_out = 0.2   # to remove overfitting we use dropout\n",
    "first_dense_layer_nodes  = 512 \n",
    "second_dense_layer_nodes = 1\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    \n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('sigmoid')) \n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               9728      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 10,241\n",
      "Trainable params: 10,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1139 samples, validate on 127 samples\n",
      "Epoch 1/10000\n",
      "1139/1139 [==============================] - 0s 307us/step - loss: 0.6460 - acc: 0.6251 - val_loss: 0.5377 - val_acc: 0.8504\n",
      "Epoch 2/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 0.5134 - acc: 0.7858 - val_loss: 0.4372 - val_acc: 0.8346\n",
      "Epoch 3/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.4160 - acc: 0.8481 - val_loss: 0.3580 - val_acc: 0.8898\n",
      "Epoch 4/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.3612 - acc: 0.8841 - val_loss: 0.3229 - val_acc: 0.8740\n",
      "Epoch 5/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.3242 - acc: 0.8929 - val_loss: 0.2839 - val_acc: 0.9213\n",
      "Epoch 6/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.3020 - acc: 0.8911 - val_loss: 0.2620 - val_acc: 0.8898\n",
      "Epoch 7/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.2784 - acc: 0.9122 - val_loss: 0.2411 - val_acc: 0.9449\n",
      "Epoch 8/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.2638 - acc: 0.9148 - val_loss: 0.2258 - val_acc: 0.9134\n",
      "Epoch 9/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.2441 - acc: 0.9175 - val_loss: 0.2112 - val_acc: 0.9291\n",
      "Epoch 10/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.2379 - acc: 0.9280 - val_loss: 0.2010 - val_acc: 0.9291\n",
      "Epoch 11/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.2200 - acc: 0.9289 - val_loss: 0.1915 - val_acc: 0.9528\n",
      "Epoch 12/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.2143 - acc: 0.9298 - val_loss: 0.1797 - val_acc: 0.9291\n",
      "Epoch 13/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.2093 - acc: 0.9368 - val_loss: 0.1704 - val_acc: 0.9449\n",
      "Epoch 14/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.1926 - acc: 0.9438 - val_loss: 0.1657 - val_acc: 0.9370\n",
      "Epoch 15/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.1870 - acc: 0.9464 - val_loss: 0.1556 - val_acc: 0.9370\n",
      "Epoch 16/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1797 - acc: 0.9447 - val_loss: 0.1472 - val_acc: 0.9528\n",
      "Epoch 17/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.1710 - acc: 0.9482 - val_loss: 0.1419 - val_acc: 0.9449\n",
      "Epoch 18/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1660 - acc: 0.9535 - val_loss: 0.1350 - val_acc: 0.9606\n",
      "Epoch 19/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1554 - acc: 0.9526 - val_loss: 0.1295 - val_acc: 0.9606\n",
      "Epoch 20/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1580 - acc: 0.9500 - val_loss: 0.1267 - val_acc: 0.9764\n",
      "Epoch 21/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.1519 - acc: 0.9517 - val_loss: 0.1221 - val_acc: 0.9606\n",
      "Epoch 22/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.1457 - acc: 0.9579 - val_loss: 0.1190 - val_acc: 0.9606\n",
      "Epoch 23/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.1349 - acc: 0.9579 - val_loss: 0.1111 - val_acc: 0.9764\n",
      "Epoch 24/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.1344 - acc: 0.9596 - val_loss: 0.1080 - val_acc: 0.9685\n",
      "Epoch 25/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1311 - acc: 0.9614 - val_loss: 0.1059 - val_acc: 0.9606\n",
      "Epoch 26/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1237 - acc: 0.9570 - val_loss: 0.1014 - val_acc: 0.9764\n",
      "Epoch 27/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.1163 - acc: 0.9622 - val_loss: 0.0971 - val_acc: 0.9764\n",
      "Epoch 28/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.1172 - acc: 0.9622 - val_loss: 0.0954 - val_acc: 0.9764\n",
      "Epoch 29/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.1126 - acc: 0.9675 - val_loss: 0.0930 - val_acc: 0.9764\n",
      "Epoch 30/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.1100 - acc: 0.9614 - val_loss: 0.0912 - val_acc: 0.9764\n",
      "Epoch 31/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1087 - acc: 0.9675 - val_loss: 0.0886 - val_acc: 0.9764\n",
      "Epoch 32/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.1050 - acc: 0.9666 - val_loss: 0.0882 - val_acc: 0.9843\n",
      "Epoch 33/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1040 - acc: 0.9684 - val_loss: 0.0917 - val_acc: 0.9685\n",
      "Epoch 34/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.1038 - acc: 0.9658 - val_loss: 0.0850 - val_acc: 0.9843\n",
      "Epoch 35/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.1001 - acc: 0.9666 - val_loss: 0.0783 - val_acc: 0.9764\n",
      "Epoch 36/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0938 - acc: 0.9710 - val_loss: 0.0773 - val_acc: 0.9764\n",
      "Epoch 37/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0940 - acc: 0.9684 - val_loss: 0.0748 - val_acc: 0.9843\n",
      "Epoch 38/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0886 - acc: 0.9745 - val_loss: 0.0738 - val_acc: 0.9921\n",
      "Epoch 39/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0843 - acc: 0.9737 - val_loss: 0.0734 - val_acc: 0.9921\n",
      "Epoch 40/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0860 - acc: 0.9737 - val_loss: 0.0708 - val_acc: 0.9843\n",
      "Epoch 41/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0839 - acc: 0.9737 - val_loss: 0.0689 - val_acc: 0.9921\n",
      "Epoch 42/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0786 - acc: 0.9772 - val_loss: 0.0678 - val_acc: 0.9921\n",
      "Epoch 43/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0754 - acc: 0.9745 - val_loss: 0.0665 - val_acc: 0.9921\n",
      "Epoch 44/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0753 - acc: 0.9789 - val_loss: 0.0654 - val_acc: 0.9921\n",
      "Epoch 45/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0790 - acc: 0.9763 - val_loss: 0.0671 - val_acc: 0.9921\n",
      "Epoch 46/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 0.0744 - acc: 0.9772 - val_loss: 0.0640 - val_acc: 0.9921\n",
      "Epoch 47/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0745 - acc: 0.9781 - val_loss: 0.0620 - val_acc: 0.9921\n",
      "Epoch 48/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0711 - acc: 0.9789 - val_loss: 0.0610 - val_acc: 0.9921\n",
      "Epoch 49/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0692 - acc: 0.9781 - val_loss: 0.0608 - val_acc: 0.9921\n",
      "Epoch 50/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0673 - acc: 0.9789 - val_loss: 0.0598 - val_acc: 0.9921\n",
      "Epoch 51/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0691 - acc: 0.9842 - val_loss: 0.0587 - val_acc: 0.9921\n",
      "Epoch 52/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0669 - acc: 0.9781 - val_loss: 0.0603 - val_acc: 0.9921\n",
      "Epoch 53/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0647 - acc: 0.9824 - val_loss: 0.0578 - val_acc: 0.9921\n",
      "Epoch 54/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0662 - acc: 0.9851 - val_loss: 0.0566 - val_acc: 0.9921\n",
      "Epoch 55/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0611 - acc: 0.9851 - val_loss: 0.0564 - val_acc: 0.9921\n",
      "Epoch 56/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0599 - acc: 0.9860 - val_loss: 0.0564 - val_acc: 0.9921\n",
      "Epoch 57/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0568 - acc: 0.9798 - val_loss: 0.0544 - val_acc: 0.9921\n",
      "Epoch 58/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0592 - acc: 0.9816 - val_loss: 0.0566 - val_acc: 0.9921\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0558 - acc: 0.9851 - val_loss: 0.0536 - val_acc: 0.9921\n",
      "Epoch 60/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0544 - acc: 0.9842 - val_loss: 0.0546 - val_acc: 0.9921\n",
      "Epoch 61/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0561 - acc: 0.9860 - val_loss: 0.0522 - val_acc: 0.9921\n",
      "Epoch 62/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0528 - acc: 0.9886 - val_loss: 0.0531 - val_acc: 0.9921\n",
      "Epoch 63/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0518 - acc: 0.9860 - val_loss: 0.0551 - val_acc: 0.9921\n",
      "Epoch 64/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0546 - acc: 0.9868 - val_loss: 0.0535 - val_acc: 0.9921\n",
      "Epoch 65/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0505 - acc: 0.9877 - val_loss: 0.0541 - val_acc: 0.9921\n",
      "Epoch 66/10000\n",
      "1139/1139 [==============================] - 0s 17us/step - loss: 0.0477 - acc: 0.9886 - val_loss: 0.0505 - val_acc: 0.9921\n",
      "Epoch 67/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0495 - acc: 0.9868 - val_loss: 0.0511 - val_acc: 0.9921\n",
      "Epoch 68/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0474 - acc: 0.9895 - val_loss: 0.0514 - val_acc: 0.9921\n",
      "Epoch 69/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0491 - acc: 0.9868 - val_loss: 0.0488 - val_acc: 0.9921\n",
      "Epoch 70/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0480 - acc: 0.9851 - val_loss: 0.0474 - val_acc: 0.9921\n",
      "Epoch 71/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0458 - acc: 0.9868 - val_loss: 0.0483 - val_acc: 0.9921\n",
      "Epoch 72/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0447 - acc: 0.9877 - val_loss: 0.0478 - val_acc: 0.9921\n",
      "Epoch 73/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0434 - acc: 0.9886 - val_loss: 0.0470 - val_acc: 0.9921\n",
      "Epoch 74/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0447 - acc: 0.9868 - val_loss: 0.0471 - val_acc: 0.9921\n",
      "Epoch 75/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0406 - acc: 0.9895 - val_loss: 0.0473 - val_acc: 0.9921\n",
      "Epoch 76/10000\n",
      "1139/1139 [==============================] - 0s 44us/step - loss: 0.0412 - acc: 0.9895 - val_loss: 0.0467 - val_acc: 0.9921\n",
      "Epoch 77/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0386 - acc: 0.9912 - val_loss: 0.0460 - val_acc: 0.9921\n",
      "Epoch 78/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 0.0314 - acc: 1.000 - 0s 26us/step - loss: 0.0416 - acc: 0.9903 - val_loss: 0.0457 - val_acc: 0.9921\n",
      "Epoch 79/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0409 - acc: 0.9877 - val_loss: 0.0463 - val_acc: 0.9921\n",
      "Epoch 80/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0413 - acc: 0.9895 - val_loss: 0.0459 - val_acc: 0.9921\n",
      "Epoch 81/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0378 - acc: 0.9903 - val_loss: 0.0440 - val_acc: 0.9921\n",
      "Epoch 82/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0359 - acc: 0.9912 - val_loss: 0.0447 - val_acc: 0.9921\n",
      "Epoch 83/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0374 - acc: 0.9903 - val_loss: 0.0453 - val_acc: 0.9921\n",
      "Epoch 84/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 0.0355 - acc: 0.9912 - val_loss: 0.0447 - val_acc: 0.9921\n",
      "Epoch 85/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0370 - acc: 0.9903 - val_loss: 0.0451 - val_acc: 0.9921\n",
      "Epoch 86/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0355 - acc: 0.9930 - val_loss: 0.0468 - val_acc: 0.9921\n",
      "Epoch 87/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0359 - acc: 0.9912 - val_loss: 0.0434 - val_acc: 0.9921\n",
      "Epoch 88/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0339 - acc: 0.9921 - val_loss: 0.0449 - val_acc: 0.9921\n",
      "Epoch 89/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0349 - acc: 0.9903 - val_loss: 0.0446 - val_acc: 0.9921\n",
      "Epoch 90/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0335 - acc: 0.9930 - val_loss: 0.0429 - val_acc: 0.9921\n",
      "Epoch 91/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0314 - acc: 0.9921 - val_loss: 0.0415 - val_acc: 0.9921\n",
      "Epoch 92/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0311 - acc: 0.9921 - val_loss: 0.0420 - val_acc: 0.9921\n",
      "Epoch 93/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0305 - acc: 0.9921 - val_loss: 0.0430 - val_acc: 0.9921\n",
      "Epoch 94/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0323 - acc: 0.9886 - val_loss: 0.0411 - val_acc: 0.9921\n",
      "Epoch 95/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0310 - acc: 0.9939 - val_loss: 0.0404 - val_acc: 0.9921\n",
      "Epoch 96/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0295 - acc: 0.9939 - val_loss: 0.0413 - val_acc: 0.9921\n",
      "Epoch 97/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0302 - acc: 0.9912 - val_loss: 0.0407 - val_acc: 0.9921\n",
      "Epoch 98/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0291 - acc: 0.9912 - val_loss: 0.0399 - val_acc: 0.9921\n",
      "Epoch 99/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0287 - acc: 0.9939 - val_loss: 0.0420 - val_acc: 0.9921\n",
      "Epoch 100/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0291 - acc: 0.9912 - val_loss: 0.0397 - val_acc: 0.9921\n",
      "Epoch 101/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0268 - acc: 0.9912 - val_loss: 0.0413 - val_acc: 0.9921\n",
      "Epoch 102/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0281 - acc: 0.9930 - val_loss: 0.0395 - val_acc: 0.9921\n",
      "Epoch 103/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0263 - acc: 0.9939 - val_loss: 0.0401 - val_acc: 0.9921\n",
      "Epoch 104/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0249 - acc: 0.9921 - val_loss: 0.0399 - val_acc: 0.9921\n",
      "Epoch 105/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0274 - acc: 0.9912 - val_loss: 0.0385 - val_acc: 0.9921\n",
      "Epoch 106/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0267 - acc: 0.9939 - val_loss: 0.0394 - val_acc: 0.9921\n",
      "Epoch 107/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0255 - acc: 0.9912 - val_loss: 0.0386 - val_acc: 0.9921\n",
      "Epoch 108/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0273 - acc: 0.9939 - val_loss: 0.0407 - val_acc: 0.9921\n",
      "Epoch 109/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0267 - acc: 0.9921 - val_loss: 0.0370 - val_acc: 0.9921\n",
      "Epoch 110/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0244 - acc: 0.9930 - val_loss: 0.0389 - val_acc: 0.9921\n",
      "Epoch 111/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0238 - acc: 0.9930 - val_loss: 0.0371 - val_acc: 0.9921\n",
      "Epoch 112/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0234 - acc: 0.9956 - val_loss: 0.0389 - val_acc: 0.9921\n",
      "Epoch 113/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0253 - acc: 0.9930 - val_loss: 0.0382 - val_acc: 0.9921\n",
      "Epoch 114/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0241 - acc: 0.9939 - val_loss: 0.0381 - val_acc: 0.9921\n",
      "Epoch 115/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0240 - acc: 0.9939 - val_loss: 0.0371 - val_acc: 0.9921\n",
      "Epoch 116/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0216 - acc: 0.9947 - val_loss: 0.0363 - val_acc: 0.9921\n",
      "Epoch 117/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0235 - acc: 0.9921 - val_loss: 0.0358 - val_acc: 0.9921\n",
      "Epoch 118/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0217 - acc: 0.9956 - val_loss: 0.0366 - val_acc: 0.9921\n",
      "Epoch 119/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0354 - val_acc: 0.9921\n",
      "Epoch 120/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0357 - val_acc: 0.9921\n",
      "Epoch 121/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0202 - acc: 0.9930 - val_loss: 0.0354 - val_acc: 0.9921\n",
      "Epoch 122/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0230 - acc: 0.9939 - val_loss: 0.0381 - val_acc: 0.9921\n",
      "Epoch 123/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0217 - acc: 0.9921 - val_loss: 0.0340 - val_acc: 0.9921\n",
      "Epoch 124/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0205 - acc: 0.9939 - val_loss: 0.0363 - val_acc: 0.9921\n",
      "Epoch 125/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0205 - acc: 0.9947 - val_loss: 0.0356 - val_acc: 0.9921\n",
      "Epoch 126/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0180 - acc: 0.9939 - val_loss: 0.0359 - val_acc: 0.9921\n",
      "Epoch 127/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0343 - val_acc: 0.9921\n",
      "Epoch 128/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.0338 - val_acc: 0.9921\n",
      "Epoch 129/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0203 - acc: 0.9947 - val_loss: 0.0333 - val_acc: 0.9921\n",
      "Epoch 130/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0200 - acc: 0.9921 - val_loss: 0.0341 - val_acc: 0.9921\n",
      "Epoch 131/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0214 - acc: 0.9939 - val_loss: 0.0364 - val_acc: 0.9921\n",
      "Epoch 132/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0331 - val_acc: 0.9921\n",
      "Epoch 133/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0205 - acc: 0.9947 - val_loss: 0.0360 - val_acc: 0.9921\n",
      "Epoch 134/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0208 - acc: 0.9921 - val_loss: 0.0333 - val_acc: 0.9921\n",
      "Epoch 135/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0179 - acc: 0.9939 - val_loss: 0.0328 - val_acc: 0.9921\n",
      "Epoch 136/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0185 - acc: 0.9939 - val_loss: 0.0329 - val_acc: 0.9921\n",
      "Epoch 137/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0163 - acc: 0.9974 - val_loss: 0.0336 - val_acc: 0.9921\n",
      "Epoch 138/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0187 - acc: 0.9921 - val_loss: 0.0332 - val_acc: 0.9921\n",
      "Epoch 139/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0170 - acc: 0.9965 - val_loss: 0.0326 - val_acc: 0.9921\n",
      "Epoch 140/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0182 - acc: 0.9939 - val_loss: 0.0304 - val_acc: 0.9921\n",
      "Epoch 141/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 0.0142 - acc: 0.9947 - val_loss: 0.0329 - val_acc: 0.9921\n",
      "Epoch 142/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0158 - acc: 0.9956 - val_loss: 0.0327 - val_acc: 0.9921\n",
      "Epoch 143/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0185 - acc: 0.9956 - val_loss: 0.0328 - val_acc: 0.9921\n",
      "Epoch 144/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0181 - acc: 0.9947 - val_loss: 0.0308 - val_acc: 0.9921\n",
      "Epoch 145/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0152 - acc: 0.9939 - val_loss: 0.0313 - val_acc: 0.9921\n",
      "Epoch 146/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0155 - acc: 0.9956 - val_loss: 0.0304 - val_acc: 0.9921\n",
      "Epoch 147/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0322 - val_acc: 0.9921\n",
      "Epoch 148/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 0.0156 - acc: 0.9956 - val_loss: 0.0299 - val_acc: 0.9921\n",
      "Epoch 149/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0147 - acc: 0.9965 - val_loss: 0.0337 - val_acc: 0.9921\n",
      "Epoch 150/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0177 - acc: 0.9939 - val_loss: 0.0300 - val_acc: 0.9921\n",
      "Epoch 151/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0167 - acc: 0.9956 - val_loss: 0.0352 - val_acc: 0.9921\n",
      "Epoch 152/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0185 - acc: 0.9921 - val_loss: 0.0316 - val_acc: 0.9921\n",
      "Epoch 153/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0150 - acc: 0.9974 - val_loss: 0.0312 - val_acc: 0.9921\n",
      "Epoch 154/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0150 - acc: 0.9956 - val_loss: 0.0299 - val_acc: 0.9921\n",
      "Epoch 155/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0133 - acc: 0.9982 - val_loss: 0.0300 - val_acc: 0.9921\n",
      "Epoch 156/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0134 - acc: 0.9974 - val_loss: 0.0306 - val_acc: 0.9921\n",
      "Epoch 157/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0144 - acc: 0.9947 - val_loss: 0.0313 - val_acc: 0.9921\n",
      "Epoch 158/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0133 - acc: 0.9974 - val_loss: 0.0284 - val_acc: 0.9921\n",
      "Epoch 159/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0138 - acc: 0.9974 - val_loss: 0.0299 - val_acc: 0.9921\n",
      "Epoch 160/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0136 - acc: 0.9965 - val_loss: 0.0273 - val_acc: 0.9921\n",
      "Epoch 161/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0324 - val_acc: 0.9921\n",
      "Epoch 162/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0275 - val_acc: 0.9921\n",
      "Epoch 163/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0143 - acc: 0.9965 - val_loss: 0.0279 - val_acc: 0.9921\n",
      "Epoch 164/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0135 - acc: 0.9974 - val_loss: 0.0287 - val_acc: 0.9921\n",
      "Epoch 165/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.0295 - val_acc: 0.9921\n",
      "Epoch 166/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0124 - acc: 0.9974 - val_loss: 0.0266 - val_acc: 0.9921\n",
      "Epoch 167/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0305 - val_acc: 0.9921\n",
      "Epoch 168/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0132 - acc: 0.9974 - val_loss: 0.0291 - val_acc: 0.9921\n",
      "Epoch 169/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0302 - val_acc: 0.9921\n",
      "Epoch 170/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0128 - acc: 0.9974 - val_loss: 0.0289 - val_acc: 0.9921\n",
      "Epoch 171/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.0315 - val_acc: 0.9921\n",
      "Epoch 172/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0141 - acc: 0.9956 - val_loss: 0.0253 - val_acc: 0.9921\n",
      "Epoch 173/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0126 - acc: 0.9965 - val_loss: 0.0300 - val_acc: 0.9921\n",
      "Epoch 174/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0114 - acc: 0.9974 - val_loss: 0.0278 - val_acc: 0.9921\n",
      "Epoch 175/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0112 - acc: 0.9982 - val_loss: 0.0271 - val_acc: 0.9921\n",
      "Epoch 176/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0289 - val_acc: 0.9921\n",
      "Epoch 177/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0258 - val_acc: 0.9921\n",
      "Epoch 178/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0294 - val_acc: 0.9921\n",
      "Epoch 179/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0133 - acc: 0.9982 - val_loss: 0.0289 - val_acc: 0.9921\n",
      "Epoch 180/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0132 - acc: 0.9939 - val_loss: 0.0266 - val_acc: 0.9921\n",
      "Epoch 181/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0119 - acc: 0.9991 - val_loss: 0.0276 - val_acc: 0.9921\n",
      "Epoch 182/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0121 - acc: 0.9956 - val_loss: 0.0281 - val_acc: 0.9921\n",
      "Epoch 183/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0114 - acc: 0.9974 - val_loss: 0.0250 - val_acc: 0.9921\n",
      "Epoch 184/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0284 - val_acc: 0.9921\n",
      "Epoch 185/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0131 - acc: 0.9956 - val_loss: 0.0257 - val_acc: 0.9921\n",
      "Epoch 186/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0240 - val_acc: 0.9921\n",
      "Epoch 187/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0099 - acc: 0.9982 - val_loss: 0.0271 - val_acc: 0.9921\n",
      "Epoch 188/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0247 - val_acc: 0.9921\n",
      "Epoch 189/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0269 - val_acc: 0.9921\n",
      "Epoch 190/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0103 - acc: 0.9982 - val_loss: 0.0270 - val_acc: 0.9921\n",
      "Epoch 191/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0088 - acc: 0.9991 - val_loss: 0.0256 - val_acc: 0.9921\n",
      "Epoch 192/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0095 - acc: 0.9974 - val_loss: 0.0255 - val_acc: 0.9921\n",
      "Epoch 193/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 0.0106 - acc: 0.9974 - val_loss: 0.0287 - val_acc: 0.9921\n",
      "Epoch 194/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0117 - acc: 0.9956 - val_loss: 0.0274 - val_acc: 0.9921\n",
      "Epoch 195/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0087 - acc: 0.9982 - val_loss: 0.0272 - val_acc: 0.9921\n",
      "Epoch 196/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0085 - acc: 0.9991 - val_loss: 0.0259 - val_acc: 0.9921\n",
      "Epoch 197/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0113 - acc: 0.9982 - val_loss: 0.0248 - val_acc: 0.9921\n",
      "Epoch 198/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0259 - val_acc: 0.9921\n",
      "Epoch 199/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0089 - acc: 0.9982 - val_loss: 0.0267 - val_acc: 0.9921\n",
      "Epoch 200/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0081 - acc: 0.9991 - val_loss: 0.0268 - val_acc: 0.9921\n",
      "Epoch 201/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0250 - val_acc: 0.9921\n",
      "Epoch 202/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0082 - acc: 0.9991 - val_loss: 0.0249 - val_acc: 0.9921\n",
      "Epoch 203/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0247 - val_acc: 0.9921\n",
      "Epoch 204/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0274 - val_acc: 0.9921\n",
      "Epoch 205/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0072 - acc: 0.9982 - val_loss: 0.0232 - val_acc: 0.9921\n",
      "Epoch 206/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0090 - acc: 0.9991 - val_loss: 0.0269 - val_acc: 0.9921\n",
      "Epoch 207/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0224 - val_acc: 0.9921\n",
      "Epoch 208/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0098 - acc: 0.9982 - val_loss: 0.0272 - val_acc: 0.9921\n",
      "Epoch 209/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0085 - acc: 0.9991 - val_loss: 0.0227 - val_acc: 0.9921\n",
      "Epoch 210/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0264 - val_acc: 0.9921\n",
      "Epoch 211/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0098 - acc: 0.9974 - val_loss: 0.0229 - val_acc: 0.9921\n",
      "Epoch 212/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0090 - acc: 0.9982 - val_loss: 0.0258 - val_acc: 0.9921\n",
      "Epoch 213/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0102 - acc: 0.9956 - val_loss: 0.0249 - val_acc: 0.9921\n",
      "Epoch 214/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0092 - acc: 0.9991 - val_loss: 0.0255 - val_acc: 0.9921\n",
      "Epoch 215/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "Epoch 216/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0217 - val_acc: 0.9921\n",
      "Epoch 217/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0089 - acc: 0.9982 - val_loss: 0.0274 - val_acc: 0.9921\n",
      "Epoch 218/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0220 - val_acc: 0.9921\n",
      "Epoch 219/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0084 - acc: 0.9982 - val_loss: 0.0239 - val_acc: 0.9921\n",
      "Epoch 220/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0070 - acc: 0.9991 - val_loss: 0.0228 - val_acc: 0.9921\n",
      "Epoch 221/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0272 - val_acc: 0.9921\n",
      "Epoch 222/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0226 - val_acc: 0.9921\n",
      "Epoch 223/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "Epoch 224/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0076 - acc: 0.9991 - val_loss: 0.0246 - val_acc: 0.9921\n",
      "Epoch 225/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0072 - acc: 0.9982 - val_loss: 0.0245 - val_acc: 0.9921\n",
      "Epoch 226/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0088 - acc: 0.9982 - val_loss: 0.0247 - val_acc: 0.9921\n",
      "Epoch 227/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0213 - val_acc: 0.9921\n",
      "Epoch 228/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0246 - val_acc: 0.9921\n",
      "Epoch 229/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0074 - acc: 0.9991 - val_loss: 0.0231 - val_acc: 0.9921\n",
      "Epoch 230/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0252 - val_acc: 0.9921\n",
      "Epoch 231/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0221 - val_acc: 0.9921\n",
      "Epoch 232/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0234 - val_acc: 0.9921\n",
      "Epoch 233/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0239 - val_acc: 0.9921\n",
      "Epoch 234/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0256 - val_acc: 0.9921\n",
      "Epoch 235/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0235 - val_acc: 0.9921\n",
      "Epoch 236/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0230 - val_acc: 0.9921\n",
      "Epoch 237/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0088 - acc: 0.9956 - val_loss: 0.0201 - val_acc: 0.9921\n",
      "Epoch 238/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0070 - acc: 0.9991 - val_loss: 0.0251 - val_acc: 0.9921\n",
      "Epoch 239/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0217 - val_acc: 0.9921\n",
      "Epoch 240/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0219 - val_acc: 0.9921\n",
      "Epoch 241/10000\n",
      "1139/1139 [==============================] - 0s 19us/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0226 - val_acc: 0.9921\n",
      "Epoch 242/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0196 - val_acc: 0.9921\n",
      "Epoch 243/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0258 - val_acc: 0.9921\n",
      "Epoch 244/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0182 - val_acc: 0.9921\n",
      "Epoch 245/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0252 - val_acc: 0.9921\n",
      "Epoch 246/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0218 - val_acc: 0.9921\n",
      "Epoch 247/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0240 - val_acc: 0.9921\n",
      "Epoch 248/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0197 - val_acc: 0.9921\n",
      "Epoch 249/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0206 - val_acc: 0.9921\n",
      "Epoch 250/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0066 - acc: 0.9991 - val_loss: 0.0263 - val_acc: 0.9921\n",
      "Epoch 251/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "Epoch 252/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.0219 - val_acc: 0.9921\n",
      "Epoch 253/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0204 - val_acc: 0.9921\n",
      "Epoch 254/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0069 - acc: 0.9991 - val_loss: 0.0230 - val_acc: 0.9921\n",
      "Epoch 255/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0068 - acc: 0.9974 - val_loss: 0.0191 - val_acc: 0.9921\n",
      "Epoch 256/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0239 - val_acc: 0.9921\n",
      "Epoch 257/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0223 - val_acc: 0.9921\n",
      "Epoch 258/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0232 - val_acc: 0.9921\n",
      "Epoch 259/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0207 - val_acc: 0.9921\n",
      "Epoch 260/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0194 - val_acc: 0.9921\n",
      "Epoch 261/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0220 - val_acc: 0.9921\n",
      "Epoch 262/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0242 - val_acc: 0.9921\n",
      "Epoch 263/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0237 - val_acc: 0.9921\n",
      "Epoch 264/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0176 - val_acc: 0.9921\n",
      "Epoch 265/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0069 - acc: 0.9991 - val_loss: 0.0250 - val_acc: 0.9921\n",
      "Epoch 266/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.000 - 0s 34us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0156 - val_acc: 0.9921\n",
      "Epoch 267/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0225 - val_acc: 0.9921\n",
      "Epoch 268/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0236 - val_acc: 0.9921\n",
      "Epoch 269/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0177 - val_acc: 0.9921\n",
      "Epoch 270/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0255 - val_acc: 0.9921\n",
      "Epoch 271/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0077 - acc: 0.9965 - val_loss: 0.0202 - val_acc: 0.9921\n",
      "Epoch 272/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0075 - acc: 0.9991 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "Epoch 273/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0071 - acc: 0.9965 - val_loss: 0.0193 - val_acc: 0.9921\n",
      "Epoch 274/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0208 - val_acc: 0.9921\n",
      "Epoch 275/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0198 - val_acc: 0.9921\n",
      "Epoch 276/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9921\n",
      "Epoch 277/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0185 - val_acc: 0.9921\n",
      "Epoch 278/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0050 - acc: 0.9991 - val_loss: 0.0211 - val_acc: 0.9921\n",
      "Epoch 279/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 280/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0182 - val_acc: 0.9921\n",
      "Epoch 281/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 282/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0217 - val_acc: 0.9921\n",
      "Epoch 283/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0197 - val_acc: 0.9921\n",
      "Epoch 284/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9921\n",
      "Epoch 285/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0063 - acc: 0.9974 - val_loss: 0.0163 - val_acc: 0.9921\n",
      "Epoch 286/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0236 - val_acc: 0.9921\n",
      "Epoch 287/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0194 - val_acc: 0.9921\n",
      "Epoch 288/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0182 - val_acc: 0.9921\n",
      "Epoch 289/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0194 - val_acc: 0.9921\n",
      "Epoch 290/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0204 - val_acc: 0.9921\n",
      "Epoch 291/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0050 - acc: 0.9991 - val_loss: 0.0172 - val_acc: 0.9921\n",
      "Epoch 292/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0052 - acc: 0.9974 - val_loss: 0.0194 - val_acc: 0.9921\n",
      "Epoch 293/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0155 - val_acc: 0.9921\n",
      "Epoch 294/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 295/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0212 - val_acc: 0.9921\n",
      "Epoch 296/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9921\n",
      "Epoch 297/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0059 - acc: 0.9974 - val_loss: 0.0203 - val_acc: 0.9921\n",
      "Epoch 298/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0179 - val_acc: 0.9921\n",
      "Epoch 299/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0197 - val_acc: 0.9921\n",
      "Epoch 300/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0055 - acc: 0.9974 - val_loss: 0.0165 - val_acc: 0.9921\n",
      "Epoch 301/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 0.9921\n",
      "Epoch 302/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0186 - val_acc: 0.9921\n",
      "Epoch 303/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.0243 - val_acc: 0.9921\n",
      "Epoch 304/10000\n",
      "1139/1139 [==============================] - 0s 13us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 305/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0202 - val_acc: 0.9921\n",
      "Epoch 306/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0048 - acc: 0.9974 - val_loss: 0.0189 - val_acc: 0.9921\n",
      "Epoch 307/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0045 - acc: 0.9991 - val_loss: 0.0171 - val_acc: 0.9921\n",
      "Epoch 308/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0049 - acc: 0.9991 - val_loss: 0.0218 - val_acc: 0.9921\n",
      "Epoch 309/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9921\n",
      "Epoch 310/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0220 - val_acc: 0.9921\n",
      "Epoch 311/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0202 - val_acc: 0.9921\n",
      "Epoch 312/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 27us/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0166 - val_acc: 0.9921\n",
      "Epoch 313/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0194 - val_acc: 0.9921\n",
      "Epoch 314/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0061 - acc: 0.9974 - val_loss: 0.0150 - val_acc: 0.9921\n",
      "Epoch 315/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0054 - acc: 0.9991 - val_loss: 0.0150 - val_acc: 0.9921\n",
      "Epoch 316/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0049 - acc: 0.9982 - val_loss: 0.0207 - val_acc: 0.9921\n",
      "Epoch 317/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0057 - acc: 0.9974 - val_loss: 0.0151 - val_acc: 0.9921\n",
      "Epoch 318/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0045 - acc: 0.9991 - val_loss: 0.0210 - val_acc: 0.9921\n",
      "Epoch 319/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0165 - val_acc: 0.9921\n",
      "Epoch 320/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0049 - acc: 0.9991 - val_loss: 0.0221 - val_acc: 0.9921\n",
      "Epoch 321/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 322/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0187 - val_acc: 0.9921\n",
      "Epoch 323/10000\n",
      "1139/1139 [==============================] - 0s 17us/step - loss: 0.0043 - acc: 0.9991 - val_loss: 0.0190 - val_acc: 0.9921\n",
      "Epoch 324/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0042 - acc: 0.9982 - val_loss: 0.0220 - val_acc: 0.9921\n",
      "Epoch 325/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 0.0056 - acc: 0.9974 - val_loss: 0.0153 - val_acc: 0.9921\n",
      "Epoch 326/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0186 - val_acc: 0.9921\n",
      "Epoch 327/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0177 - val_acc: 0.9921\n",
      "Epoch 328/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0169 - val_acc: 0.9921\n",
      "Epoch 329/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0171 - val_acc: 0.9921\n",
      "Epoch 330/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9921\n",
      "Epoch 331/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0195 - val_acc: 0.9921\n",
      "Epoch 332/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0142 - val_acc: 0.9921\n",
      "Epoch 333/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9921\n",
      "Epoch 334/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0190 - val_acc: 0.9921\n",
      "Epoch 335/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9921\n",
      "Epoch 336/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0038 - acc: 0.9982 - val_loss: 0.0225 - val_acc: 0.9921\n",
      "Epoch 337/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0057 - acc: 0.9974 - val_loss: 0.0175 - val_acc: 0.9921\n",
      "Epoch 338/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0178 - val_acc: 0.9921\n",
      "Epoch 339/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0050 - acc: 0.9991 - val_loss: 0.0205 - val_acc: 0.9921\n",
      "Epoch 340/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.000 - 0s 27us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9921\n",
      "Epoch 341/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0042 - acc: 0.9982 - val_loss: 0.0203 - val_acc: 0.9921\n",
      "Epoch 342/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0046 - acc: 0.9982 - val_loss: 0.0207 - val_acc: 0.9921\n",
      "Epoch 343/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0218 - val_acc: 0.9921\n",
      "Epoch 344/10000\n",
      "1139/1139 [==============================] - 0s 16us/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0197 - val_acc: 0.9921\n",
      "Epoch 345/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0236 - val_acc: 0.9921\n",
      "Epoch 346/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 347/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0046 - acc: 0.9982 - val_loss: 0.0184 - val_acc: 0.9921\n",
      "Epoch 348/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9921\n",
      "Epoch 349/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 19us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0165 - val_acc: 0.9921\n",
      "Epoch 350/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0156 - val_acc: 0.9921\n",
      "Epoch 351/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0177 - val_acc: 0.9921\n",
      "Epoch 352/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0170 - val_acc: 0.9921\n",
      "Epoch 353/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0041 - acc: 0.9974 - val_loss: 0.0211 - val_acc: 0.9921\n",
      "Epoch 354/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0183 - val_acc: 0.9921\n",
      "Epoch 355/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0266 - val_acc: 0.9921\n",
      "Epoch 356/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0048 - acc: 0.9982 - val_loss: 0.0196 - val_acc: 0.9921\n",
      "Epoch 357/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 358/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0208 - val_acc: 0.9921\n",
      "Epoch 359/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0045 - acc: 0.9974 - val_loss: 0.0183 - val_acc: 0.9921\n",
      "Epoch 360/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0047 - acc: 0.9982 - val_loss: 0.0148 - val_acc: 0.9921\n",
      "Epoch 361/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0040 - acc: 0.9982 - val_loss: 0.0144 - val_acc: 0.9921\n",
      "Epoch 362/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9921\n",
      "Epoch 363/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 0.9921\n",
      "Epoch 364/10000\n",
      "1139/1139 [==============================] - 0s 16us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 365/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9921\n",
      "Epoch 366/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0034 - acc: 0.9982 - val_loss: 0.0159 - val_acc: 0.9921\n",
      "Epoch 367/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0200 - val_acc: 0.9921\n",
      "Epoch 368/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 369/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9921\n",
      "Epoch 370/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0162 - val_acc: 0.9921\n",
      "Epoch 371/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0173 - val_acc: 0.9921\n",
      "Epoch 372/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0205 - val_acc: 0.9921\n",
      "Epoch 373/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0192 - val_acc: 0.9921\n",
      "Epoch 374/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0228 - val_acc: 0.9921\n",
      "Epoch 375/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9921\n",
      "Epoch 376/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0032 - acc: 0.9982 - val_loss: 0.0215 - val_acc: 0.9921\n",
      "Epoch 377/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 0.9921\n",
      "Epoch 378/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0204 - val_acc: 0.9921\n",
      "Epoch 379/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9921\n",
      "Epoch 380/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0157 - val_acc: 0.9921\n",
      "Epoch 381/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0217 - val_acc: 0.9921\n",
      "Epoch 382/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0035 - acc: 0.9982 - val_loss: 0.0198 - val_acc: 0.9921\n",
      "Epoch 383/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9921\n",
      "Epoch 384/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0196 - val_acc: 0.9921\n",
      "Epoch 385/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 0.9921\n",
      "Epoch 386/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9921\n",
      "Epoch 387/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9921\n",
      "Epoch 388/10000\n",
      "1139/1139 [==============================] - 0s 15us/step - loss: 0.0038 - acc: 0.9982 - val_loss: 0.0160 - val_acc: 0.9921\n",
      "Epoch 389/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 0.9921\n",
      "Epoch 390/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 391/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 0.9921\n",
      "Epoch 392/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0037 - acc: 0.9982 - val_loss: 0.0151 - val_acc: 0.9921\n",
      "Epoch 393/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0139 - val_acc: 0.9921\n",
      "Epoch 394/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9921\n",
      "Epoch 395/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0162 - val_acc: 0.9921\n",
      "Epoch 396/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0171 - val_acc: 0.9921\n",
      "Epoch 397/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 0.9921\n",
      "Epoch 398/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0031 - acc: 0.9982 - val_loss: 0.0153 - val_acc: 0.9921\n",
      "Epoch 399/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0187 - val_acc: 0.9921\n",
      "Epoch 400/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0166 - val_acc: 0.9921\n",
      "Epoch 401/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0173 - val_acc: 0.9921\n",
      "Epoch 402/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0219 - val_acc: 0.9921\n",
      "Epoch 403/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0179 - val_acc: 0.9921\n",
      "Epoch 404/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0151 - val_acc: 0.9921\n",
      "Epoch 405/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0187 - val_acc: 0.9921\n",
      "Epoch 406/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0147 - val_acc: 0.9921\n",
      "Epoch 407/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 14us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9921\n",
      "Epoch 408/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 409/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0182 - val_acc: 0.9921\n",
      "Epoch 410/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9921\n",
      "Epoch 411/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 0.9921\n",
      "Epoch 412/10000\n",
      "1139/1139 [==============================] - 0s 17us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0146 - val_acc: 0.9921\n",
      "Epoch 413/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 0.9921\n",
      "Epoch 414/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0190 - val_acc: 0.9921\n",
      "Epoch 415/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0215 - val_acc: 0.9921\n",
      "Epoch 416/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9921\n",
      "Epoch 417/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9921\n",
      "Epoch 418/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0157 - val_acc: 0.9921\n",
      "Epoch 419/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0219 - val_acc: 0.9921\n",
      "Epoch 420/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0035 - acc: 0.9982 - val_loss: 0.0148 - val_acc: 0.9921\n",
      "Epoch 421/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9921\n",
      "Epoch 422/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 423/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 424/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0203 - val_acc: 0.9921\n",
      "Epoch 425/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0242 - val_acc: 0.9921\n",
      "Epoch 426/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0034 - acc: 0.9982 - val_loss: 0.0149 - val_acc: 0.9921\n",
      "Epoch 427/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0180 - val_acc: 0.9921\n",
      "Epoch 428/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9921\n",
      "Epoch 429/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0156 - val_acc: 0.9921\n",
      "Epoch 430/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 0.9921\n",
      "Epoch 431/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 432/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0264 - val_acc: 0.9921\n",
      "Epoch 433/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0033 - acc: 0.9982 - val_loss: 0.0170 - val_acc: 0.9921\n",
      "Epoch 434/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0082 - acc: 0.9965 - val_loss: 0.0262 - val_acc: 0.9921\n",
      "Epoch 435/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.0148 - val_acc: 0.9921\n",
      "Epoch 436/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0215 - val_acc: 0.9921\n",
      "Epoch 437/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0191 - val_acc: 0.9921\n",
      "Epoch 438/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 0.9921\n",
      "Epoch 439/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0199 - val_acc: 0.9921\n",
      "Epoch 440/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 0.9921\n",
      "Epoch 441/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0176 - val_acc: 0.9921\n",
      "Epoch 442/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9921\n",
      "Epoch 443/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0033 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9921\n",
      "Epoch 444/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 0.9921\n",
      "Epoch 445/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0143 - val_acc: 0.9921\n",
      "Epoch 446/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 0.9921\n",
      "Epoch 447/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0172 - val_acc: 0.9921\n",
      "Epoch 448/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9921\n",
      "Epoch 449/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 0.9921\n",
      "Epoch 450/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 0.9982 - val_loss: 0.0136 - val_acc: 0.9921\n",
      "Epoch 451/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 0.9921\n",
      "Epoch 452/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0199 - val_acc: 0.9921\n",
      "Epoch 453/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9921\n",
      "Epoch 454/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 455/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0025 - acc: 0.9982 - val_loss: 0.0150 - val_acc: 0.9921\n",
      "Epoch 456/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0174 - val_acc: 0.9921\n",
      "Epoch 457/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0208 - val_acc: 0.9921\n",
      "Epoch 458/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 0.9921\n",
      "Epoch 459/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 0.9921\n",
      "Epoch 460/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 461/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0187 - val_acc: 0.9921\n",
      "Epoch 462/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9921\n",
      "Epoch 463/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9921\n",
      "Epoch 464/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 0.9921\n",
      "Epoch 465/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 0.9921\n",
      "Epoch 466/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9921\n",
      "Epoch 467/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0220 - val_acc: 0.9921\n",
      "Epoch 468/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0129 - val_acc: 0.9921\n",
      "Epoch 469/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 470/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0131 - val_acc: 0.9921\n",
      "Epoch 471/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9921\n",
      "Epoch 472/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0132 - val_acc: 0.9921\n",
      "Epoch 473/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0034 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9921\n",
      "Epoch 474/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0273 - val_acc: 0.9921\n",
      "Epoch 475/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0111 - val_acc: 0.9921\n",
      "Epoch 476/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0204 - val_acc: 0.9921\n",
      "Epoch 477/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0155 - val_acc: 0.9921\n",
      "Epoch 478/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9921\n",
      "Epoch 479/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 480/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0138 - val_acc: 0.9921\n",
      "Epoch 481/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9921\n",
      "Epoch 482/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9921\n",
      "Epoch 483/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0217 - val_acc: 0.9921\n",
      "Epoch 484/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0196 - val_acc: 0.9921\n",
      "Epoch 485/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9921\n",
      "Epoch 486/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0152 - val_acc: 0.9921\n",
      "Epoch 487/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0192 - val_acc: 0.9921\n",
      "Epoch 488/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9921\n",
      "Epoch 489/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0144 - val_acc: 0.9921\n",
      "Epoch 490/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 0.9921\n",
      "Epoch 491/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9921\n",
      "Epoch 492/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0142 - val_acc: 0.9921\n",
      "Epoch 493/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 0.9921\n",
      "Epoch 494/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9921\n",
      "Epoch 495/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 496/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0193 - val_acc: 0.9921\n",
      "Epoch 497/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 0.9921\n",
      "Epoch 498/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9921\n",
      "Epoch 499/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0028 - acc: 0.9982 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 500/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0166 - val_acc: 0.9921\n",
      "Epoch 501/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0143 - val_acc: 0.9921\n",
      "Epoch 502/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0178 - val_acc: 0.9921\n",
      "Epoch 503/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 0.9921\n",
      "Epoch 504/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0105 - val_acc: 0.9921\n",
      "Epoch 505/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9921\n",
      "Epoch 506/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9921\n",
      "Epoch 507/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0122 - val_acc: 0.9921\n",
      "Epoch 508/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0239 - val_acc: 0.9921\n",
      "Epoch 509/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0140 - val_acc: 0.9921\n",
      "Epoch 510/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9921\n",
      "Epoch 511/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9921\n",
      "Epoch 512/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 513/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0175 - val_acc: 0.9921\n",
      "Epoch 514/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 0.9921\n",
      "Epoch 515/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0202 - val_acc: 0.9921\n",
      "Epoch 516/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9921\n",
      "Epoch 517/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9921\n",
      "Epoch 518/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9921\n",
      "Epoch 519/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9921\n",
      "Epoch 520/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 0.9921\n",
      "Epoch 521/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0212 - val_acc: 0.9921\n",
      "Epoch 522/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9921\n",
      "Epoch 523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.0219 - val_acc: 0.9921\n",
      "Epoch 524/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9921\n",
      "Epoch 525/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 0.9921\n",
      "Epoch 526/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 4.8280e-04 - acc: 1.000 - 0s 30us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9921\n",
      "Epoch 527/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9921\n",
      "Epoch 528/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0192 - val_acc: 0.9921\n",
      "Epoch 529/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 5.2884e-04 - acc: 1.000 - 0s 28us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 0.9921\n",
      "Epoch 530/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 0.9921\n",
      "Epoch 531/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.7937e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 532/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 0.9921\n",
      "Epoch 533/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 0.9921\n",
      "Epoch 534/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9921\n",
      "Epoch 535/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 536/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0254 - val_acc: 0.9921\n",
      "Epoch 537/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0179 - val_acc: 0.9921\n",
      "Epoch 538/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9921\n",
      "Epoch 539/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9921\n",
      "Epoch 540/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0029 - acc: 0.9982 - val_loss: 0.0128 - val_acc: 0.9921\n",
      "Epoch 541/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9921\n",
      "Epoch 542/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9921\n",
      "Epoch 543/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0116 - val_acc: 0.9921\n",
      "Epoch 544/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9921\n",
      "Epoch 545/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 0.9921\n",
      "Epoch 546/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0152 - val_acc: 0.9921\n",
      "Epoch 547/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0125 - val_acc: 0.9921\n",
      "Epoch 548/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 0.9921\n",
      "Epoch 549/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0159 - val_acc: 0.9921\n",
      "Epoch 550/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 551/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9921\n",
      "Epoch 552/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 0.9921\n",
      "Epoch 553/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 554/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 555/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 0.9921\n",
      "Epoch 556/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 557/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 0.9921\n",
      "Epoch 558/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9921\n",
      "Epoch 559/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9921\n",
      "Epoch 560/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0017 - acc: 0.9991 - val_loss: 0.0214 - val_acc: 0.9921\n",
      "Epoch 561/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9921\n",
      "Epoch 562/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9921\n",
      "Epoch 563/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9921\n",
      "Epoch 564/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0101 - val_acc: 0.9921\n",
      "Epoch 565/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9921\n",
      "Epoch 566/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9921\n",
      "Epoch 567/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9921\n",
      "Epoch 568/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9921\n",
      "Epoch 569/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.0161 - val_acc: 0.9921\n",
      "Epoch 570/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 8.8945e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 571/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 8.1107e-04 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 0.9921\n",
      "Epoch 572/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9921\n",
      "Epoch 573/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.5249e-04 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 574/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0013 - acc: 0.9991 - val_loss: 0.0173 - val_acc: 0.9921\n",
      "Epoch 575/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9921\n",
      "Epoch 576/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0016 - acc: 0.9991 - val_loss: 0.0162 - val_acc: 0.9921\n",
      "Epoch 577/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 578/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9921\n",
      "Epoch 579/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 0.9921\n",
      "Epoch 580/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 0.9921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9921\n",
      "Epoch 582/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0118 - val_acc: 0.9921\n",
      "Epoch 583/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0210 - val_acc: 0.9921\n",
      "Epoch 584/10000\n",
      "1139/1139 [==============================] - 0s 45us/step - loss: 0.0024 - acc: 0.9991 - val_loss: 0.0139 - val_acc: 0.9921\n",
      "Epoch 585/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9921\n",
      "Epoch 586/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9921\n",
      "Epoch 587/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0140 - val_acc: 0.9921\n",
      "Epoch 588/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0223 - val_acc: 0.9921\n",
      "Epoch 589/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9921\n",
      "Epoch 590/10000\n",
      "1139/1139 [==============================] - 0s 19us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 0.9921\n",
      "Epoch 591/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 592/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0349 - val_acc: 0.9921\n",
      "Epoch 593/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0034 - acc: 0.9982 - val_loss: 0.0115 - val_acc: 0.9921\n",
      "Epoch 594/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 595/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9921\n",
      "Epoch 596/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9921\n",
      "Epoch 597/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9921\n",
      "Epoch 598/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 0.9921\n",
      "Epoch 599/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9921\n",
      "Epoch 600/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9921\n",
      "Epoch 601/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0023 - acc: 0.9982 - val_loss: 0.0136 - val_acc: 0.9921\n",
      "Epoch 602/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9921\n",
      "Epoch 603/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 0.9921\n",
      "Epoch 604/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 605/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0168 - val_acc: 0.9921\n",
      "Epoch 606/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9921\n",
      "Epoch 607/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9843\n",
      "Epoch 608/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0276 - val_acc: 0.9921\n",
      "Epoch 609/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0163 - val_acc: 0.9921\n",
      "Epoch 610/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 611/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0030 - acc: 0.9982 - val_loss: 0.0180 - val_acc: 0.9921\n",
      "Epoch 612/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9921\n",
      "Epoch 613/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.8373e-04 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 614/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 8.0408e-04 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 0.9921\n",
      "Epoch 615/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0173 - val_acc: 0.9921\n",
      "Epoch 616/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0030 - acc: 0.9982 - val_loss: 0.0177 - val_acc: 0.9921\n",
      "Epoch 617/10000\n",
      "1139/1139 [==============================] - 0s 19us/step - loss: 0.0034 - acc: 0.9982 - val_loss: 0.0252 - val_acc: 0.9921\n",
      "Epoch 618/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0039 - acc: 0.9982 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 619/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9843\n",
      "Epoch 620/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0034 - acc: 0.9982 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 621/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9921\n",
      "Epoch 622/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0197 - val_acc: 0.9921\n",
      "Epoch 623/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0207 - val_acc: 0.9921\n",
      "Epoch 624/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9921\n",
      "Epoch 625/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 0.0016 - acc: 0.9991 - val_loss: 0.0168 - val_acc: 0.9921\n",
      "Epoch 626/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9921\n",
      "Epoch 627/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9921\n",
      "Epoch 628/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.0135 - val_acc: 0.9921\n",
      "Epoch 629/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9921\n",
      "Epoch 630/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 0.9921\n",
      "Epoch 631/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 0.9921\n",
      "Epoch 632/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 6.1789e-04 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9921\n",
      "Epoch 633/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9921\n",
      "Epoch 634/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.8261e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9921\n",
      "Epoch 635/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 7.4825e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9921\n",
      "Epoch 636/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 0.9921\n",
      "Epoch 637/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9921\n",
      "Epoch 638/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9921\n",
      "Epoch 639/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9921\n",
      "Epoch 640/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0164 - val_acc: 0.9921\n",
      "Epoch 641/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9921\n",
      "Epoch 642/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.0110 - val_acc: 0.9921\n",
      "Epoch 643/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 7.4630e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9921\n",
      "Epoch 644/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 0.0022 - acc: 0.9982 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 645/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0014 - acc: 0.9991 - val_loss: 0.0100 - val_acc: 0.9921\n",
      "Epoch 646/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 7.4453e-04 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9921\n",
      "Epoch 647/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 8.6445e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9921\n",
      "Epoch 648/10000\n",
      "1139/1139 [==============================] - 0s 47us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9921\n",
      "Epoch 649/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 9.7775e-04 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9921\n",
      "Epoch 650/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 9.0495e-04 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9921\n",
      "Epoch 651/10000\n",
      "1139/1139 [==============================] - 0s 45us/step - loss: 6.3410e-04 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 0.9921\n",
      "Epoch 652/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 8.9937e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 0.9921\n",
      "Epoch 653/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0017 - acc: 0.9991 - val_loss: 0.0110 - val_acc: 0.9921\n",
      "Epoch 654/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 9.9252e-04 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9921\n",
      "Epoch 655/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0017 - acc: 0.9991 - val_loss: 0.0133 - val_acc: 0.9921\n",
      "Epoch 656/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9921\n",
      "Epoch 657/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 5.7498e-04 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9921\n",
      "Epoch 658/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.9657e-04 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 0.9921\n",
      "Epoch 659/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9921\n",
      "Epoch 660/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 2.6556e-04 - acc: 1.000 - 0s 27us/step - loss: 9.0665e-04 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9921\n",
      "Epoch 661/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 4.0588e-04 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9921\n",
      "Epoch 662/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 8.1375e-04 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 0.9921\n",
      "Epoch 663/10000\n",
      "1139/1139 [==============================] - 0s 43us/step - loss: 8.0905e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 0.9921\n",
      "Epoch 664/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9921\n",
      "Epoch 665/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.9312e-04 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 0.9921\n",
      "Epoch 666/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.8137e-04 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 0.9921\n",
      "Epoch 667/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 7.3351e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 0.9921\n",
      "Epoch 668/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 8.0157e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9921\n",
      "Epoch 669/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 8.1805e-04 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9921\n",
      "Epoch 670/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 6.7566e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9921\n",
      "Epoch 671/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 7.5159e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9921\n",
      "Epoch 672/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0012 - acc: 0.9991 - val_loss: 0.0192 - val_acc: 0.9921\n",
      "Epoch 673/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9921\n",
      "Epoch 674/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0015 - acc: 0.9991 - val_loss: 0.0135 - val_acc: 0.9921\n",
      "Epoch 675/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0123 - val_acc: 0.9921\n",
      "Epoch 676/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9921\n",
      "Epoch 677/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 7.8476e-04 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9921\n",
      "Epoch 678/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.8748e-04 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 0.9921\n",
      "Epoch 679/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.9718e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 0.9921\n",
      "Epoch 680/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.9499e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 0.9921\n",
      "Epoch 681/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.3840e-04 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9921\n",
      "Epoch 682/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 8.9424e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9921\n",
      "Epoch 683/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.4419e-04 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9921\n",
      "Epoch 684/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.8553e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9921\n",
      "Epoch 685/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.4276e-04 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9921\n",
      "Epoch 686/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.4280e-04 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 0.9921\n",
      "Epoch 687/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.3570e-04 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9921\n",
      "Epoch 688/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 8.9699e-04 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9921\n",
      "Epoch 689/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9921\n",
      "Epoch 690/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9921\n",
      "Epoch 691/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9921\n",
      "Epoch 692/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.9054e-04 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9921\n",
      "Epoch 693/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 6.6751e-04 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 0.9921\n",
      "Epoch 694/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.9133e-04 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9921\n",
      "Epoch 695/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0107 - val_acc: 0.9921\n",
      "Epoch 696/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9921\n",
      "Epoch 697/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 7.4050e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9921\n",
      "Epoch 698/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9921\n",
      "Epoch 699/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0357 - val_acc: 0.9921\n",
      "Epoch 700/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0098 - val_acc: 0.9921\n",
      "Epoch 701/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9921\n",
      "Epoch 702/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9921\n",
      "Epoch 703/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9921\n",
      "Epoch 704/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0137 - val_acc: 0.9921\n",
      "Epoch 705/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.0585e-04 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 706/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.5496e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9921\n",
      "Epoch 707/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.8192e-04 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9921\n",
      "Epoch 708/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9921\n",
      "Epoch 709/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9921\n",
      "Epoch 710/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.8299e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9921\n",
      "Epoch 711/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 0.9921\n",
      "Epoch 712/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.9295e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9921\n",
      "Epoch 713/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 7.3021e-04 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9921\n",
      "Epoch 714/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.3519e-04 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9921\n",
      "Epoch 715/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.7313e-04 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9921\n",
      "Epoch 716/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.9786e-04 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 0.9921\n",
      "Epoch 717/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 4.4935e-04 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9921\n",
      "Epoch 718/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9921\n",
      "Epoch 00718: early stopping\n"
     ]
    }
   ],
   "source": [
    "#hyper parameters\n",
    "validation_data_split = 0.1\n",
    "num_epochs = 10000\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 32\n",
    "early_patience =100\n",
    "\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "\n",
    "\n",
    "history = model.fit(ConcatenatedTrainingDataMatrix\n",
    "                    , ConcatenatedTrainingTarget\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb,earlystopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x0000023A185878D0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x0000023A1864EBE0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x0000023A1A683DA0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x0000023A1A6A3F60>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 69us/step\n",
      "The Validation Accuracy on the human observed dataset is: 1.0\n",
      "The Validation Loss on the human observed dataset is: 0.0009298874684196862\n",
      "157/157 [==============================] - 0s 57us/step\n",
      "The Test Accuracy on the human observed dataset is: 0.9872611464968153\n",
      "The Test Loss on the human observed dataset is: 0.09416567191339223\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(ConcatenatedValidationDataMatrix, ConcatenatedValidationTarget)\n",
    "print('The Validation Accuracy on the human observed dataset is: ' +str(test_acc))\n",
    "print('The Validation Loss on the human observed dataset is: ' +str(test_loss))\n",
    "test_loss, test_acc = model.evaluate(ConcatenatedTestingDataMatrix, ConcatenatedTestingTarget)\n",
    "print('The Test Accuracy on the human observed dataset is: ' +str(test_acc))\n",
    "print('The Test Loss on the human observed dataset is: ' +str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model on Subtracted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_size = 9\n",
    "drop_out = 0.2   # to remove overfitting we use dropout\n",
    "first_dense_layer_nodes  = 512 \n",
    "second_dense_layer_nodes = 1\n",
    "\n",
    "def get_model_con():\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    \n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('sigmoid')) \n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               5120      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,633\n",
      "Trainable params: 5,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = get_model_con()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1139 samples, validate on 127 samples\n",
      "Epoch 1/10000\n",
      "1139/1139 [==============================] - 0s 373us/step - loss: 0.5899 - acc: 0.8139 - val_loss: 0.5110 - val_acc: 0.9213\n",
      "Epoch 2/10000\n",
      "1139/1139 [==============================] - 0s 57us/step - loss: 0.4712 - acc: 0.9069 - val_loss: 0.4123 - val_acc: 0.9291\n",
      "Epoch 3/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 0.3739 - acc: 0.9377 - val_loss: 0.3313 - val_acc: 0.9291\n",
      "Epoch 4/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 0.3021 - acc: 0.9464 - val_loss: 0.2646 - val_acc: 0.9291\n",
      "Epoch 5/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 0.2441 - acc: 0.9526 - val_loss: 0.2185 - val_acc: 0.9291\n",
      "Epoch 6/10000\n",
      "1139/1139 [==============================] - 0s 49us/step - loss: 0.2024 - acc: 0.9579 - val_loss: 0.1817 - val_acc: 0.9370\n",
      "Epoch 7/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.1730 - acc: 0.9631 - val_loss: 0.1583 - val_acc: 0.9449\n",
      "Epoch 8/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.1498 - acc: 0.9596 - val_loss: 0.1365 - val_acc: 0.9528\n",
      "Epoch 9/10000\n",
      "1139/1139 [==============================] - 0s 43us/step - loss: 0.1341 - acc: 0.9666 - val_loss: 0.1235 - val_acc: 0.9528\n",
      "Epoch 10/10000\n",
      "1139/1139 [==============================] - 0s 45us/step - loss: 0.1195 - acc: 0.9675 - val_loss: 0.1090 - val_acc: 0.9528\n",
      "Epoch 11/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.1095 - acc: 0.9701 - val_loss: 0.0982 - val_acc: 0.9685\n",
      "Epoch 12/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 0.0991 - acc: 0.9745 - val_loss: 0.0909 - val_acc: 0.9685\n",
      "Epoch 13/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0884 - acc: 0.9789 - val_loss: 0.0817 - val_acc: 0.9685\n",
      "Epoch 14/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0844 - acc: 0.9754 - val_loss: 0.0740 - val_acc: 0.9685\n",
      "Epoch 15/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0749 - acc: 0.9824 - val_loss: 0.0685 - val_acc: 0.9764\n",
      "Epoch 16/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0694 - acc: 0.9860 - val_loss: 0.0614 - val_acc: 0.9921\n",
      "Epoch 17/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0645 - acc: 0.9833 - val_loss: 0.0559 - val_acc: 0.9921\n",
      "Epoch 18/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0587 - acc: 0.9851 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 19/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0530 - acc: 0.9903 - val_loss: 0.0476 - val_acc: 1.0000\n",
      "Epoch 20/10000\n",
      "1139/1139 [==============================] - 0s 44us/step - loss: 0.0488 - acc: 0.9912 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 21/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0446 - acc: 0.9921 - val_loss: 0.0406 - val_acc: 1.0000\n",
      "Epoch 22/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0415 - acc: 0.9930 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 23/10000\n",
      "1139/1139 [==============================] - 0s 43us/step - loss: 0.0376 - acc: 0.9947 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 24/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0354 - acc: 0.9956 - val_loss: 0.0302 - val_acc: 1.0000\n",
      "Epoch 25/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0328 - acc: 0.9956 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "Epoch 26/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0301 - acc: 0.9974 - val_loss: 0.0248 - val_acc: 1.0000\n",
      "Epoch 27/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0284 - acc: 0.9974 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 28/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0262 - acc: 0.9965 - val_loss: 0.0213 - val_acc: 1.0000\n",
      "Epoch 29/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0239 - acc: 0.9965 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 30/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0212 - acc: 0.9974 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 31/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0208 - acc: 0.9974 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 32/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0198 - acc: 0.9974 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 33/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0164 - acc: 0.9982 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 34/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0154 - acc: 0.9974 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 35/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0121 - val_acc: 1.0000\n",
      "Epoch 36/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 37/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0133 - acc: 0.9982 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 38/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0115 - acc: 0.9991 - val_loss: 0.0098 - val_acc: 1.0000\n",
      "Epoch 39/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0113 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 1.0000\n",
      "Epoch 40/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 41/10000\n",
      "1139/1139 [==============================] - 0s 44us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 42/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 43/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 44/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 45/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 46/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 47/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 48/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 49/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 50/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 51/10000\n",
      "1139/1139 [==============================] - 0s 47us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 52/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 53/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 54/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 55/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 56/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 57/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 58/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 60/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 61/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 62/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 63/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 64/10000\n",
      "1139/1139 [==============================] - 0s 45us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 65/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 66/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 67/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 68/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 69/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 70/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 71/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 72/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 73/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 74/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 75/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 76/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 77/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 78/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 79/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 80/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 81/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 82/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 83/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 84/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 85/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 86/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 87/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 88/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 89/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 34us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 90/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 91/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 9.7501e-04 - val_acc: 1.0000\n",
      "Epoch 92/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 9.4545e-04 - val_acc: 1.0000\n",
      "Epoch 93/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 9.1550e-04 - val_acc: 1.0000\n",
      "Epoch 94/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 9.0004e-04 - val_acc: 1.0000\n",
      "Epoch 95/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.8447e-04 - val_acc: 1.0000\n",
      "Epoch 96/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.5523e-04 - val_acc: 1.0000\n",
      "Epoch 97/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 9.5084e-04 - acc: 1.0000 - val_loss: 8.3595e-04 - val_acc: 1.0000\n",
      "Epoch 98/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 8.1933e-04 - val_acc: 1.0000\n",
      "Epoch 99/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 9.8525e-04 - acc: 1.0000 - val_loss: 8.0253e-04 - val_acc: 1.0000\n",
      "Epoch 100/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 9.7676e-04 - acc: 1.0000 - val_loss: 7.7155e-04 - val_acc: 1.0000\n",
      "Epoch 101/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 9.6707e-04 - acc: 1.0000 - val_loss: 7.5420e-04 - val_acc: 1.0000\n",
      "Epoch 102/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 9.0831e-04 - acc: 1.0000 - val_loss: 7.4233e-04 - val_acc: 1.0000\n",
      "Epoch 103/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 8.9076e-04 - acc: 1.0000 - val_loss: 7.2540e-04 - val_acc: 1.0000\n",
      "Epoch 104/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 8.3562e-04 - acc: 1.0000 - val_loss: 7.2021e-04 - val_acc: 1.0000\n",
      "Epoch 105/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 9.4728e-04 - acc: 1.0000 - val_loss: 7.0146e-04 - val_acc: 1.0000\n",
      "Epoch 106/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 8.8369e-04 - acc: 1.0000 - val_loss: 6.7496e-04 - val_acc: 1.0000\n",
      "Epoch 107/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 8.1639e-04 - acc: 1.0000 - val_loss: 6.5383e-04 - val_acc: 1.0000\n",
      "Epoch 108/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 8.7924e-04 - acc: 1.0000 - val_loss: 6.4320e-04 - val_acc: 1.0000\n",
      "Epoch 109/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 8.2407e-04 - acc: 1.0000 - val_loss: 6.2750e-04 - val_acc: 1.0000\n",
      "Epoch 110/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 7.4957e-04 - acc: 1.0000 - val_loss: 6.0810e-04 - val_acc: 1.0000\n",
      "Epoch 111/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 7.4583e-04 - acc: 1.0000 - val_loss: 5.9507e-04 - val_acc: 1.0000\n",
      "Epoch 112/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 7.6904e-04 - acc: 1.0000 - val_loss: 5.8082e-04 - val_acc: 1.0000\n",
      "Epoch 113/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 7.0783e-04 - acc: 1.0000 - val_loss: 5.7204e-04 - val_acc: 1.0000\n",
      "Epoch 114/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.9607e-04 - acc: 1.0000 - val_loss: 5.5690e-04 - val_acc: 1.0000\n",
      "Epoch 115/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 7.1442e-04 - acc: 1.0000 - val_loss: 5.4895e-04 - val_acc: 1.0000\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.7685e-04 - acc: 1.0000 - val_loss: 5.4176e-04 - val_acc: 1.0000\n",
      "Epoch 117/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 6.9882e-04 - acc: 1.0000 - val_loss: 5.2307e-04 - val_acc: 1.0000\n",
      "Epoch 118/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 6.6579e-04 - acc: 1.0000 - val_loss: 5.1173e-04 - val_acc: 1.0000\n",
      "Epoch 119/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 6.2940e-04 - acc: 1.0000 - val_loss: 5.0663e-04 - val_acc: 1.0000\n",
      "Epoch 120/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.2514e-04 - acc: 1.0000 - val_loss: 4.9566e-04 - val_acc: 1.0000\n",
      "Epoch 121/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 6.4408e-04 - acc: 1.0000 - val_loss: 4.8774e-04 - val_acc: 1.0000\n",
      "Epoch 122/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 6.2319e-04 - acc: 1.0000 - val_loss: 4.7986e-04 - val_acc: 1.0000\n",
      "Epoch 123/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 5.8105e-04 - acc: 1.0000 - val_loss: 4.7009e-04 - val_acc: 1.0000\n",
      "Epoch 124/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 5.6015e-04 - acc: 1.0000 - val_loss: 4.5653e-04 - val_acc: 1.0000\n",
      "Epoch 125/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 6.0114e-04 - acc: 1.0000 - val_loss: 4.4555e-04 - val_acc: 1.0000\n",
      "Epoch 126/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 5.7427e-04 - acc: 1.0000 - val_loss: 4.3483e-04 - val_acc: 1.0000\n",
      "Epoch 127/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 5.6302e-04 - acc: 1.0000 - val_loss: 4.2631e-04 - val_acc: 1.0000\n",
      "Epoch 128/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 5.5758e-04 - acc: 1.0000 - val_loss: 4.2355e-04 - val_acc: 1.0000\n",
      "Epoch 129/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 5.8635e-04 - acc: 1.0000 - val_loss: 4.1759e-04 - val_acc: 1.0000\n",
      "Epoch 130/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 5.1815e-04 - acc: 1.0000 - val_loss: 4.0693e-04 - val_acc: 1.0000\n",
      "Epoch 131/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 5.8138e-04 - acc: 1.0000 - val_loss: 3.9938e-04 - val_acc: 1.0000\n",
      "Epoch 132/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 5.0805e-04 - acc: 1.0000 - val_loss: 3.9713e-04 - val_acc: 1.0000\n",
      "Epoch 133/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 4.8060e-04 - acc: 1.0000 - val_loss: 3.8914e-04 - val_acc: 1.0000\n",
      "Epoch 134/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 4.3963e-04 - acc: 1.0000 - val_loss: 3.7739e-04 - val_acc: 1.0000\n",
      "Epoch 135/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.8987e-04 - acc: 1.0000 - val_loss: 3.7273e-04 - val_acc: 1.0000\n",
      "Epoch 136/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.5223e-04 - acc: 1.0000 - val_loss: 3.6358e-04 - val_acc: 1.0000\n",
      "Epoch 137/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.6161e-04 - acc: 1.0000 - val_loss: 3.5148e-04 - val_acc: 1.0000\n",
      "Epoch 138/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.5411e-04 - acc: 1.0000 - val_loss: 3.4872e-04 - val_acc: 1.0000\n",
      "Epoch 139/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 4.7709e-04 - acc: 1.0000 - val_loss: 3.4345e-04 - val_acc: 1.0000\n",
      "Epoch 140/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 4.2319e-04 - acc: 1.0000 - val_loss: 3.4031e-04 - val_acc: 1.0000\n",
      "Epoch 141/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 4.1837e-04 - acc: 1.0000 - val_loss: 3.3051e-04 - val_acc: 1.0000\n",
      "Epoch 142/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.5059e-04 - acc: 1.0000 - val_loss: 3.3082e-04 - val_acc: 1.0000\n",
      "Epoch 143/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 4.1869e-04 - acc: 1.0000 - val_loss: 3.2557e-04 - val_acc: 1.0000\n",
      "Epoch 144/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.3816e-04 - acc: 1.0000 - val_loss: 3.1780e-04 - val_acc: 1.0000\n",
      "Epoch 145/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.8967e-04 - acc: 1.0000 - val_loss: 3.1116e-04 - val_acc: 1.0000\n",
      "Epoch 146/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.0399e-04 - acc: 1.0000 - val_loss: 3.0682e-04 - val_acc: 1.0000\n",
      "Epoch 147/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.7006e-04 - acc: 1.0000 - val_loss: 2.9991e-04 - val_acc: 1.0000\n",
      "Epoch 148/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.9264e-04 - acc: 1.0000 - val_loss: 2.9447e-04 - val_acc: 1.0000\n",
      "Epoch 149/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.8399e-04 - acc: 1.0000 - val_loss: 2.9438e-04 - val_acc: 1.0000\n",
      "Epoch 150/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.8993e-04 - acc: 1.0000 - val_loss: 2.8728e-04 - val_acc: 1.0000\n",
      "Epoch 151/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.6408e-04 - acc: 1.0000 - val_loss: 2.7814e-04 - val_acc: 1.0000\n",
      "Epoch 152/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.9955e-04 - acc: 1.0000 - val_loss: 2.7050e-04 - val_acc: 1.0000\n",
      "Epoch 153/10000\n",
      "1139/1139 [==============================] - 0s 16us/step - loss: 3.4603e-04 - acc: 1.0000 - val_loss: 2.7476e-04 - val_acc: 1.0000\n",
      "Epoch 154/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.5033e-04 - acc: 1.0000 - val_loss: 2.7096e-04 - val_acc: 1.0000\n",
      "Epoch 155/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 3.6653e-04 - acc: 1.0000 - val_loss: 2.6304e-04 - val_acc: 1.0000\n",
      "Epoch 156/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.3482e-04 - acc: 1.0000 - val_loss: 2.5606e-04 - val_acc: 1.0000\n",
      "Epoch 157/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.3209e-04 - acc: 1.0000 - val_loss: 2.5492e-04 - val_acc: 1.0000\n",
      "Epoch 158/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.4735e-04 - acc: 1.0000 - val_loss: 2.5257e-04 - val_acc: 1.0000\n",
      "Epoch 159/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 3.1538e-04 - acc: 1.0000 - val_loss: 2.4704e-04 - val_acc: 1.0000\n",
      "Epoch 160/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4862e-04 - acc: 1.0000 - val_loss: 2.4327e-04 - val_acc: 1.0000\n",
      "Epoch 161/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4059e-04 - acc: 1.0000 - val_loss: 2.3873e-04 - val_acc: 1.0000\n",
      "Epoch 162/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.3586e-04 - acc: 1.0000 - val_loss: 2.3332e-04 - val_acc: 1.0000\n",
      "Epoch 163/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.9665e-04 - acc: 1.0000 - val_loss: 2.3202e-04 - val_acc: 1.0000\n",
      "Epoch 164/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.9431e-04 - acc: 1.0000 - val_loss: 2.3001e-04 - val_acc: 1.0000\n",
      "Epoch 165/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.1382e-04 - acc: 1.0000 - val_loss: 2.2564e-04 - val_acc: 1.0000\n",
      "Epoch 166/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 2.8295e-04 - acc: 1.0000 - val_loss: 2.2523e-04 - val_acc: 1.0000\n",
      "Epoch 167/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 3.0268e-04 - acc: 1.0000 - val_loss: 2.2307e-04 - val_acc: 1.0000\n",
      "Epoch 168/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.7173e-04 - acc: 1.0000 - val_loss: 2.1707e-04 - val_acc: 1.0000\n",
      "Epoch 169/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.6735e-04 - acc: 1.0000 - val_loss: 2.1157e-04 - val_acc: 1.0000\n",
      "Epoch 170/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 3.0219e-04 - acc: 1.0000 - val_loss: 2.0887e-04 - val_acc: 1.0000\n",
      "Epoch 171/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.6538e-04 - acc: 1.0000 - val_loss: 2.0662e-04 - val_acc: 1.0000\n",
      "Epoch 172/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.9348e-04 - acc: 1.0000 - val_loss: 2.0306e-04 - val_acc: 1.0000\n",
      "Epoch 173/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.8349e-04 - acc: 1.0000 - val_loss: 2.0075e-04 - val_acc: 1.0000\n",
      "Epoch 174/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.7404e-04 - acc: 1.0000 - val_loss: 1.9959e-04 - val_acc: 1.0000\n",
      "Epoch 175/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.5180e-04 - acc: 1.0000 - val_loss: 1.9687e-04 - val_acc: 1.0000\n",
      "Epoch 176/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.4937e-04 - acc: 1.0000 - val_loss: 1.9182e-04 - val_acc: 1.0000\n",
      "Epoch 177/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.5484e-04 - acc: 1.0000 - val_loss: 1.8992e-04 - val_acc: 1.0000\n",
      "Epoch 178/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.4478e-04 - acc: 1.0000 - val_loss: 1.8763e-04 - val_acc: 1.0000\n",
      "Epoch 179/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 2.3707e-04 - acc: 1.0000 - val_loss: 1.8498e-04 - val_acc: 1.0000\n",
      "Epoch 180/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.2204e-04 - acc: 1.0000 - val_loss: 1.8281e-04 - val_acc: 1.0000\n",
      "Epoch 181/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.3213e-04 - acc: 1.0000 - val_loss: 1.8106e-04 - val_acc: 1.0000\n",
      "Epoch 182/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.4264e-04 - acc: 1.0000 - val_loss: 1.7793e-04 - val_acc: 1.0000\n",
      "Epoch 183/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 2.3317e-04 - acc: 1.0000 - val_loss: 1.7608e-04 - val_acc: 1.0000\n",
      "Epoch 184/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.2323e-04 - acc: 1.0000 - val_loss: 1.7278e-04 - val_acc: 1.0000\n",
      "Epoch 185/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 2.5197e-04 - acc: 1.0000 - val_loss: 1.6992e-04 - val_acc: 1.0000\n",
      "Epoch 186/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.3406e-04 - acc: 1.0000 - val_loss: 1.6820e-04 - val_acc: 1.0000\n",
      "Epoch 187/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.1519e-04 - acc: 1.0000 - val_loss: 1.6720e-04 - val_acc: 1.0000\n",
      "Epoch 188/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.2156e-04 - acc: 1.0000 - val_loss: 1.6436e-04 - val_acc: 1.0000\n",
      "Epoch 189/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.1359e-04 - acc: 1.0000 - val_loss: 1.6210e-04 - val_acc: 1.0000\n",
      "Epoch 190/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.2175e-04 - acc: 1.0000 - val_loss: 1.5999e-04 - val_acc: 1.0000\n",
      "Epoch 191/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.1150e-04 - acc: 1.0000 - val_loss: 1.5750e-04 - val_acc: 1.0000\n",
      "Epoch 192/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.0790e-04 - acc: 1.0000 - val_loss: 1.5370e-04 - val_acc: 1.0000\n",
      "Epoch 193/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 2.1159e-04 - acc: 1.0000 - val_loss: 1.5150e-04 - val_acc: 1.0000\n",
      "Epoch 194/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.9447e-04 - acc: 1.0000 - val_loss: 1.5123e-04 - val_acc: 1.0000\n",
      "Epoch 195/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 2.0165e-04 - acc: 1.0000 - val_loss: 1.5048e-04 - val_acc: 1.0000\n",
      "Epoch 196/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.9407e-04 - acc: 1.0000 - val_loss: 1.4970e-04 - val_acc: 1.0000\n",
      "Epoch 197/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 1.9969e-04 - acc: 1.0000 - val_loss: 1.4797e-04 - val_acc: 1.0000\n",
      "Epoch 198/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.0155e-04 - acc: 1.0000 - val_loss: 1.4458e-04 - val_acc: 1.0000\n",
      "Epoch 199/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.9697e-04 - acc: 1.0000 - val_loss: 1.4079e-04 - val_acc: 1.0000\n",
      "Epoch 200/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 1.8463e-04 - acc: 1.0000 - val_loss: 1.3890e-04 - val_acc: 1.0000\n",
      "Epoch 201/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.8236e-04 - acc: 1.0000 - val_loss: 1.3806e-04 - val_acc: 1.0000\n",
      "Epoch 202/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.9272e-04 - acc: 1.0000 - val_loss: 1.3620e-04 - val_acc: 1.0000\n",
      "Epoch 203/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 2.0065e-04 - acc: 1.0000 - val_loss: 1.3444e-04 - val_acc: 1.0000\n",
      "Epoch 204/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.9364e-04 - acc: 1.0000 - val_loss: 1.3421e-04 - val_acc: 1.0000\n",
      "Epoch 205/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.9811e-04 - acc: 1.0000 - val_loss: 1.3330e-04 - val_acc: 1.0000\n",
      "Epoch 206/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.8611e-04 - acc: 1.0000 - val_loss: 1.3215e-04 - val_acc: 1.0000\n",
      "Epoch 207/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.7896e-04 - acc: 1.0000 - val_loss: 1.3044e-04 - val_acc: 1.0000\n",
      "Epoch 208/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.6955e-04 - acc: 1.0000 - val_loss: 1.2838e-04 - val_acc: 1.0000\n",
      "Epoch 209/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.6670e-04 - acc: 1.0000 - val_loss: 1.2610e-04 - val_acc: 1.0000\n",
      "Epoch 210/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.6024e-04 - acc: 1.0000 - val_loss: 1.2464e-04 - val_acc: 1.0000\n",
      "Epoch 211/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.7862e-04 - acc: 1.0000 - val_loss: 1.2350e-04 - val_acc: 1.0000\n",
      "Epoch 212/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.5619e-04 - acc: 1.0000 - val_loss: 1.2326e-04 - val_acc: 1.0000\n",
      "Epoch 213/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.6878e-04 - acc: 1.0000 - val_loss: 1.2108e-04 - val_acc: 1.0000\n",
      "Epoch 214/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.5748e-04 - acc: 1.0000 - val_loss: 1.1846e-04 - val_acc: 1.0000\n",
      "Epoch 215/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 1.7022e-04 - acc: 1.0000 - val_loss: 1.1648e-04 - val_acc: 1.0000\n",
      "Epoch 216/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5415e-04 - acc: 1.0000 - val_loss: 1.1596e-04 - val_acc: 1.0000\n",
      "Epoch 217/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.6163e-04 - acc: 1.0000 - val_loss: 1.1481e-04 - val_acc: 1.0000\n",
      "Epoch 218/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.6547e-04 - acc: 1.0000 - val_loss: 1.1380e-04 - val_acc: 1.0000\n",
      "Epoch 219/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.6110e-04 - acc: 1.0000 - val_loss: 1.1246e-04 - val_acc: 1.0000\n",
      "Epoch 220/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.4663e-04 - acc: 1.0000 - val_loss: 1.1187e-04 - val_acc: 1.0000\n",
      "Epoch 221/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.4894e-04 - acc: 1.0000 - val_loss: 1.1050e-04 - val_acc: 1.0000\n",
      "Epoch 222/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5952e-04 - acc: 1.0000 - val_loss: 1.0955e-04 - val_acc: 1.0000\n",
      "Epoch 223/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4889e-04 - acc: 1.0000 - val_loss: 1.0773e-04 - val_acc: 1.0000\n",
      "Epoch 224/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.5851e-04 - acc: 1.0000 - val_loss: 1.0575e-04 - val_acc: 1.0000\n",
      "Epoch 225/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.3679e-04 - acc: 1.0000 - val_loss: 1.0401e-04 - val_acc: 1.0000\n",
      "Epoch 226/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.3467e-04 - acc: 1.0000 - val_loss: 1.0270e-04 - val_acc: 1.0000\n",
      "Epoch 227/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3363e-04 - acc: 1.0000 - val_loss: 1.0169e-04 - val_acc: 1.0000\n",
      "Epoch 228/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5541e-04 - acc: 1.0000 - val_loss: 1.0078e-04 - val_acc: 1.0000\n",
      "Epoch 229/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4151e-04 - acc: 1.0000 - val_loss: 1.0134e-04 - val_acc: 1.0000\n",
      "Epoch 230/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2908e-04 - acc: 1.0000 - val_loss: 1.0092e-04 - val_acc: 1.0000\n",
      "Epoch 231/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3735e-04 - acc: 1.0000 - val_loss: 9.8433e-05 - val_acc: 1.0000\n",
      "Epoch 232/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.3958e-04 - acc: 1.0000 - val_loss: 9.6372e-05 - val_acc: 1.0000\n",
      "Epoch 233/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.3591e-04 - acc: 1.0000 - val_loss: 9.5058e-05 - val_acc: 1.0000\n",
      "Epoch 234/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3347e-04 - acc: 1.0000 - val_loss: 9.5032e-05 - val_acc: 1.0000\n",
      "Epoch 235/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.2053e-04 - acc: 1.0000 - val_loss: 9.4226e-05 - val_acc: 1.0000\n",
      "Epoch 236/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3121e-04 - acc: 1.0000 - val_loss: 9.3164e-05 - val_acc: 1.0000\n",
      "Epoch 237/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2906e-04 - acc: 1.0000 - val_loss: 9.2493e-05 - val_acc: 1.0000\n",
      "Epoch 238/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 1.2038e-04 - acc: 1.0000 - val_loss: 9.1797e-05 - val_acc: 1.0000\n",
      "Epoch 239/10000\n",
      "1139/1139 [==============================] - 0s 44us/step - loss: 1.3039e-04 - acc: 1.0000 - val_loss: 9.0078e-05 - val_acc: 1.0000\n",
      "Epoch 240/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.2308e-04 - acc: 1.0000 - val_loss: 8.8518e-05 - val_acc: 1.0000\n",
      "Epoch 241/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.0849e-04 - acc: 1.0000 - val_loss: 8.7715e-05 - val_acc: 1.0000\n",
      "Epoch 242/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2929e-04 - acc: 1.0000 - val_loss: 8.6604e-05 - val_acc: 1.0000\n",
      "Epoch 243/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2247e-04 - acc: 1.0000 - val_loss: 8.5724e-05 - val_acc: 1.0000\n",
      "Epoch 244/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.2102e-04 - acc: 1.0000 - val_loss: 8.5169e-05 - val_acc: 1.0000\n",
      "Epoch 245/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.0815e-04 - acc: 1.0000 - val_loss: 8.4716e-05 - val_acc: 1.0000\n",
      "Epoch 246/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1126e-04 - acc: 1.0000 - val_loss: 8.3300e-05 - val_acc: 1.0000\n",
      "Epoch 247/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1360e-04 - acc: 1.0000 - val_loss: 8.2788e-05 - val_acc: 1.0000\n",
      "Epoch 248/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.1336e-04 - acc: 1.0000 - val_loss: 8.2674e-05 - val_acc: 1.0000\n",
      "Epoch 249/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.2417e-04 - acc: 1.0000 - val_loss: 8.1783e-05 - val_acc: 1.0000\n",
      "Epoch 250/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1315e-04 - acc: 1.0000 - val_loss: 8.0360e-05 - val_acc: 1.0000\n",
      "Epoch 251/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.0948e-04 - acc: 1.0000 - val_loss: 7.9315e-05 - val_acc: 1.0000\n",
      "Epoch 252/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.0333e-04 - acc: 1.0000 - val_loss: 7.8471e-05 - val_acc: 1.0000\n",
      "Epoch 253/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.0377e-04 - acc: 1.0000 - val_loss: 7.7511e-05 - val_acc: 1.0000\n",
      "Epoch 254/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.1133e-04 - acc: 1.0000 - val_loss: 7.6906e-05 - val_acc: 1.0000\n",
      "Epoch 255/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.6051e-05 - acc: 1.0000 - val_loss: 7.6896e-05 - val_acc: 1.0000\n",
      "Epoch 256/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2127e-04 - acc: 1.0000 - val_loss: 7.6082e-05 - val_acc: 1.0000\n",
      "Epoch 257/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.0817e-04 - acc: 1.0000 - val_loss: 7.4599e-05 - val_acc: 1.0000\n",
      "Epoch 258/10000\n",
      "1139/1139 [==============================] - 0s 20us/step - loss: 1.0428e-04 - acc: 1.0000 - val_loss: 7.3683e-05 - val_acc: 1.0000\n",
      "Epoch 259/10000\n",
      "1139/1139 [==============================] - 0s 15us/step - loss: 1.0908e-04 - acc: 1.0000 - val_loss: 7.3008e-05 - val_acc: 1.0000\n",
      "Epoch 260/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 9.4086e-05 - acc: 1.0000 - val_loss: 7.2381e-05 - val_acc: 1.0000\n",
      "Epoch 261/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.0146e-04 - acc: 1.0000 - val_loss: 7.2343e-05 - val_acc: 1.0000\n",
      "Epoch 262/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.0101e-04 - acc: 1.0000 - val_loss: 7.1823e-05 - val_acc: 1.0000\n",
      "Epoch 263/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 9.2408e-05 - acc: 1.0000 - val_loss: 7.0346e-05 - val_acc: 1.0000\n",
      "Epoch 264/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.1326e-04 - acc: 1.0000 - val_loss: 6.8993e-05 - val_acc: 1.0000\n",
      "Epoch 265/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.0345e-04 - acc: 1.0000 - val_loss: 6.8290e-05 - val_acc: 1.0000\n",
      "Epoch 266/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 8.6172e-05 - acc: 1.0000 - val_loss: 6.7475e-05 - val_acc: 1.0000\n",
      "Epoch 267/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 9.9994e-05 - acc: 1.0000 - val_loss: 6.6955e-05 - val_acc: 1.0000\n",
      "Epoch 268/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 9.0809e-05 - acc: 1.0000 - val_loss: 6.6732e-05 - val_acc: 1.0000\n",
      "Epoch 269/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 8.7337e-05 - acc: 1.0000 - val_loss: 6.6503e-05 - val_acc: 1.0000\n",
      "Epoch 270/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.0351e-04 - acc: 1.0000 - val_loss: 6.6211e-05 - val_acc: 1.0000\n",
      "Epoch 271/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 8.8942e-05 - acc: 1.0000 - val_loss: 6.6083e-05 - val_acc: 1.0000\n",
      "Epoch 272/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 8.6535e-05 - acc: 1.0000 - val_loss: 6.5173e-05 - val_acc: 1.0000\n",
      "Epoch 273/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 8.4578e-05 - acc: 1.0000 - val_loss: 6.4251e-05 - val_acc: 1.0000\n",
      "Epoch 274/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.7193e-05 - acc: 1.0000 - val_loss: 6.3442e-05 - val_acc: 1.0000\n",
      "Epoch 275/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.0896e-05 - acc: 1.0000 - val_loss: 6.2059e-05 - val_acc: 1.0000\n",
      "Epoch 276/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 8.3004e-05 - acc: 1.0000 - val_loss: 6.1326e-05 - val_acc: 1.0000\n",
      "Epoch 277/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.0744e-05 - acc: 1.0000 - val_loss: 6.0313e-05 - val_acc: 1.0000\n",
      "Epoch 278/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.2742e-05 - acc: 1.0000 - val_loss: 5.9713e-05 - val_acc: 1.0000\n",
      "Epoch 279/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.3680e-05 - acc: 1.0000 - val_loss: 5.9365e-05 - val_acc: 1.0000\n",
      "Epoch 280/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 7.9938e-05 - acc: 1.0000 - val_loss: 5.9079e-05 - val_acc: 1.0000\n",
      "Epoch 281/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.0100e-05 - acc: 1.0000 - val_loss: 5.8434e-05 - val_acc: 1.0000\n",
      "Epoch 282/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.6356e-05 - acc: 1.0000 - val_loss: 5.7616e-05 - val_acc: 1.0000\n",
      "Epoch 283/10000\n",
      "1139/1139 [==============================] - 0s 11us/step - loss: 7.9963e-05 - acc: 1.0000 - val_loss: 5.7740e-05 - val_acc: 1.0000\n",
      "Epoch 284/10000\n",
      "1139/1139 [==============================] - 0s 47us/step - loss: 8.4063e-05 - acc: 1.0000 - val_loss: 5.7418e-05 - val_acc: 1.0000\n",
      "Epoch 285/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.3603e-05 - acc: 1.0000 - val_loss: 5.6636e-05 - val_acc: 1.0000\n",
      "Epoch 286/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 7.3347e-05 - acc: 1.0000 - val_loss: 5.6198e-05 - val_acc: 1.0000\n",
      "Epoch 287/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.1306e-05 - acc: 1.0000 - val_loss: 5.5961e-05 - val_acc: 1.0000\n",
      "Epoch 288/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 7.5483e-05 - acc: 1.0000 - val_loss: 5.5593e-05 - val_acc: 1.0000\n",
      "Epoch 289/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.6097e-05 - acc: 1.0000 - val_loss: 5.5352e-05 - val_acc: 1.0000\n",
      "Epoch 290/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 7.8190e-05 - acc: 1.0000 - val_loss: 5.4474e-05 - val_acc: 1.0000\n",
      "Epoch 291/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 6.7814e-05 - acc: 1.0000 - val_loss: 5.3755e-05 - val_acc: 1.0000\n",
      "Epoch 292/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.4891e-05 - acc: 1.0000 - val_loss: 5.3104e-05 - val_acc: 1.0000\n",
      "Epoch 293/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.3326e-05 - acc: 1.0000 - val_loss: 5.2314e-05 - val_acc: 1.0000\n",
      "Epoch 294/10000\n",
      "1139/1139 [==============================] - 0s 15us/step - loss: 7.5478e-05 - acc: 1.0000 - val_loss: 5.1612e-05 - val_acc: 1.0000\n",
      "Epoch 295/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 7.3199e-05 - acc: 1.0000 - val_loss: 5.1304e-05 - val_acc: 1.0000\n",
      "Epoch 296/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 7.1903e-05 - acc: 1.0000 - val_loss: 5.1122e-05 - val_acc: 1.0000\n",
      "Epoch 297/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 6.7481e-05 - acc: 1.0000 - val_loss: 5.0817e-05 - val_acc: 1.0000\n",
      "Epoch 298/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.2687e-05 - acc: 1.0000 - val_loss: 5.0203e-05 - val_acc: 1.0000\n",
      "Epoch 299/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 7.2424e-05 - acc: 1.0000 - val_loss: 4.9821e-05 - val_acc: 1.0000\n",
      "Epoch 300/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.3047e-05 - acc: 1.0000 - val_loss: 4.9579e-05 - val_acc: 1.0000\n",
      "Epoch 301/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 7.1018e-05 - acc: 1.0000 - val_loss: 4.9263e-05 - val_acc: 1.0000\n",
      "Epoch 302/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 6.7719e-05 - acc: 1.0000 - val_loss: 4.8640e-05 - val_acc: 1.0000\n",
      "Epoch 303/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 6.9441e-05 - acc: 1.0000 - val_loss: 4.8244e-05 - val_acc: 1.0000\n",
      "Epoch 304/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.1698e-05 - acc: 1.0000 - val_loss: 4.7812e-05 - val_acc: 1.0000\n",
      "Epoch 305/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 6.2424e-05 - acc: 1.0000 - val_loss: 4.7490e-05 - val_acc: 1.0000\n",
      "Epoch 306/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 8.1822e-05 - acc: 1.0000 - val_loss: 4.8210e-05 - val_acc: 1.0000\n",
      "Epoch 307/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.7836e-05 - acc: 1.0000 - val_loss: 4.8191e-05 - val_acc: 1.0000\n",
      "Epoch 308/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.6038e-05 - acc: 1.0000 - val_loss: 4.7195e-05 - val_acc: 1.0000\n",
      "Epoch 309/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.2342e-05 - acc: 1.0000 - val_loss: 4.6708e-05 - val_acc: 1.0000\n",
      "Epoch 310/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 6.2121e-05 - acc: 1.0000 - val_loss: 4.6214e-05 - val_acc: 1.0000\n",
      "Epoch 311/10000\n",
      "1139/1139 [==============================] - 0s 47us/step - loss: 6.2282e-05 - acc: 1.0000 - val_loss: 4.5909e-05 - val_acc: 1.0000\n",
      "Epoch 312/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.7687e-05 - acc: 1.0000 - val_loss: 4.5609e-05 - val_acc: 1.0000\n",
      "Epoch 313/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 6.0094e-05 - acc: 1.0000 - val_loss: 4.5256e-05 - val_acc: 1.0000\n",
      "Epoch 314/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 6.1548e-05 - acc: 1.0000 - val_loss: 4.4528e-05 - val_acc: 1.0000\n",
      "Epoch 315/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 6.3563e-05 - acc: 1.0000 - val_loss: 4.3571e-05 - val_acc: 1.0000\n",
      "Epoch 316/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.6442e-05 - acc: 1.0000 - val_loss: 4.2780e-05 - val_acc: 1.0000\n",
      "Epoch 317/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 6.1911e-05 - acc: 1.0000 - val_loss: 4.2296e-05 - val_acc: 1.0000\n",
      "Epoch 318/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.0047e-05 - acc: 1.0000 - val_loss: 4.1710e-05 - val_acc: 1.0000\n",
      "Epoch 319/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 5.4248e-05 - acc: 1.0000 - val_loss: 4.1592e-05 - val_acc: 1.0000\n",
      "Epoch 320/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 6.2021e-05 - acc: 1.0000 - val_loss: 4.1357e-05 - val_acc: 1.0000\n",
      "Epoch 321/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 5.7011e-05 - acc: 1.0000 - val_loss: 4.0928e-05 - val_acc: 1.0000\n",
      "Epoch 322/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 5.7275e-05 - acc: 1.0000 - val_loss: 4.0411e-05 - val_acc: 1.0000\n",
      "Epoch 323/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.1624e-05 - acc: 1.0000 - val_loss: 4.0511e-05 - val_acc: 1.0000\n",
      "Epoch 324/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.2872e-05 - acc: 1.0000 - val_loss: 4.0760e-05 - val_acc: 1.0000\n",
      "Epoch 325/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.7147e-05 - acc: 1.0000 - val_loss: 4.0676e-05 - val_acc: 1.0000\n",
      "Epoch 326/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.1212e-05 - acc: 1.0000 - val_loss: 3.9920e-05 - val_acc: 1.0000\n",
      "Epoch 327/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.3632e-05 - acc: 1.0000 - val_loss: 3.9237e-05 - val_acc: 1.0000\n",
      "Epoch 328/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.8432e-05 - acc: 1.0000 - val_loss: 3.9250e-05 - val_acc: 1.0000\n",
      "Epoch 329/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 5.5634e-05 - acc: 1.0000 - val_loss: 3.9058e-05 - val_acc: 1.0000\n",
      "Epoch 330/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.7281e-05 - acc: 1.0000 - val_loss: 3.8701e-05 - val_acc: 1.0000\n",
      "Epoch 331/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.7916e-05 - acc: 1.0000 - val_loss: 3.8103e-05 - val_acc: 1.0000\n",
      "Epoch 332/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 5.2214e-05 - acc: 1.0000 - val_loss: 3.7712e-05 - val_acc: 1.0000\n",
      "Epoch 333/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.8326e-05 - acc: 1.0000 - val_loss: 3.7378e-05 - val_acc: 1.0000\n",
      "Epoch 334/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 5.1172e-05 - acc: 1.0000 - val_loss: 3.7011e-05 - val_acc: 1.0000\n",
      "Epoch 335/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 6.5580e-05 - acc: 1.0000 - val_loss: 3.6612e-05 - val_acc: 1.0000\n",
      "Epoch 336/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 31us/step - loss: 5.9152e-05 - acc: 1.0000 - val_loss: 3.6047e-05 - val_acc: 1.0000\n",
      "Epoch 337/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 5.6026e-05 - acc: 1.0000 - val_loss: 3.5916e-05 - val_acc: 1.0000\n",
      "Epoch 338/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.9120e-05 - acc: 1.0000 - val_loss: 3.5815e-05 - val_acc: 1.0000\n",
      "Epoch 339/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 5.2162e-05 - acc: 1.0000 - val_loss: 3.5698e-05 - val_acc: 1.0000\n",
      "Epoch 340/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 4.8845e-05 - acc: 1.0000 - val_loss: 3.5573e-05 - val_acc: 1.0000\n",
      "Epoch 341/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 5.1512e-05 - acc: 1.0000 - val_loss: 3.5218e-05 - val_acc: 1.0000\n",
      "Epoch 342/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.0045e-05 - acc: 1.0000 - val_loss: 3.4507e-05 - val_acc: 1.0000\n",
      "Epoch 343/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.2943e-05 - acc: 1.0000 - val_loss: 3.3991e-05 - val_acc: 1.0000\n",
      "Epoch 344/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 4.4139e-05 - acc: 1.0000 - val_loss: 3.3661e-05 - val_acc: 1.0000\n",
      "Epoch 345/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 5.0627e-05 - acc: 1.0000 - val_loss: 3.3348e-05 - val_acc: 1.0000\n",
      "Epoch 346/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 4.9258e-05 - acc: 1.0000 - val_loss: 3.3084e-05 - val_acc: 1.0000\n",
      "Epoch 347/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.5844e-05 - acc: 1.0000 - val_loss: 3.2760e-05 - val_acc: 1.0000\n",
      "Epoch 348/10000\n",
      "1139/1139 [==============================] - 0s 55us/step - loss: 4.5445e-05 - acc: 1.0000 - val_loss: 3.2473e-05 - val_acc: 1.0000\n",
      "Epoch 349/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 5.1960e-05 - acc: 1.0000 - val_loss: 3.2174e-05 - val_acc: 1.0000\n",
      "Epoch 350/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 4.6445e-05 - acc: 1.0000 - val_loss: 3.1872e-05 - val_acc: 1.0000\n",
      "Epoch 351/10000\n",
      "1139/1139 [==============================] - 0s 50us/step - loss: 4.4349e-05 - acc: 1.0000 - val_loss: 3.1637e-05 - val_acc: 1.0000\n",
      "Epoch 352/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 4.3448e-05 - acc: 1.0000 - val_loss: 3.1625e-05 - val_acc: 1.0000\n",
      "Epoch 353/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 4.3779e-05 - acc: 1.0000 - val_loss: 3.1666e-05 - val_acc: 1.0000\n",
      "Epoch 354/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.4024e-05 - acc: 1.0000 - val_loss: 3.1608e-05 - val_acc: 1.0000\n",
      "Epoch 355/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 4.2140e-05 - acc: 1.0000 - val_loss: 3.1530e-05 - val_acc: 1.0000\n",
      "Epoch 356/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 4.2117e-05 - acc: 1.0000 - val_loss: 3.1069e-05 - val_acc: 1.0000\n",
      "Epoch 357/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 4.4181e-05 - acc: 1.0000 - val_loss: 3.0664e-05 - val_acc: 1.0000\n",
      "Epoch 358/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.4211e-05 - acc: 1.0000 - val_loss: 3.0305e-05 - val_acc: 1.0000\n",
      "Epoch 359/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.4198e-05 - acc: 1.0000 - val_loss: 3.0010e-05 - val_acc: 1.0000\n",
      "Epoch 360/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 4.4606e-05 - acc: 1.0000 - val_loss: 2.9647e-05 - val_acc: 1.0000\n",
      "Epoch 361/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 4.4689e-05 - acc: 1.0000 - val_loss: 2.9526e-05 - val_acc: 1.0000\n",
      "Epoch 362/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 4.6549e-05 - acc: 1.0000 - val_loss: 2.9276e-05 - val_acc: 1.0000\n",
      "Epoch 363/10000\n",
      "1139/1139 [==============================] - 0s 44us/step - loss: 4.8211e-05 - acc: 1.0000 - val_loss: 2.9144e-05 - val_acc: 1.0000\n",
      "Epoch 364/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.1281e-05 - acc: 1.0000 - val_loss: 2.9020e-05 - val_acc: 1.0000\n",
      "Epoch 365/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 4.3563e-05 - acc: 1.0000 - val_loss: 2.9056e-05 - val_acc: 1.0000\n",
      "Epoch 366/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.0748e-05 - acc: 1.0000 - val_loss: 2.8693e-05 - val_acc: 1.0000\n",
      "Epoch 367/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.0124e-05 - acc: 1.0000 - val_loss: 2.8457e-05 - val_acc: 1.0000\n",
      "Epoch 368/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 3.9517e-05 - acc: 1.0000 - val_loss: 2.8000e-05 - val_acc: 1.0000\n",
      "Epoch 369/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.9748e-05 - acc: 1.0000 - val_loss: 2.7842e-05 - val_acc: 1.0000\n",
      "Epoch 370/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.2772e-05 - acc: 1.0000 - val_loss: 2.7664e-05 - val_acc: 1.0000\n",
      "Epoch 371/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 3.8868e-05 - acc: 1.0000 - val_loss: 2.7264e-05 - val_acc: 1.0000\n",
      "Epoch 372/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 3.9241e-05 - acc: 1.0000 - val_loss: 2.6909e-05 - val_acc: 1.0000\n",
      "Epoch 373/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6799e-05 - acc: 1.0000 - val_loss: 2.6594e-05 - val_acc: 1.0000\n",
      "Epoch 374/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 4.0946e-05 - acc: 1.0000 - val_loss: 2.6508e-05 - val_acc: 1.0000\n",
      "Epoch 375/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.6559e-05 - acc: 1.0000 - val_loss: 2.6393e-05 - val_acc: 1.0000\n",
      "Epoch 376/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.9972e-05 - acc: 1.0000 - val_loss: 2.6135e-05 - val_acc: 1.0000\n",
      "Epoch 377/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 3.4865e-05 - acc: 1.0000 - val_loss: 2.5889e-05 - val_acc: 1.0000\n",
      "Epoch 378/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 3.5352e-05 - acc: 1.0000 - val_loss: 2.5587e-05 - val_acc: 1.0000\n",
      "Epoch 379/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 3.6372e-05 - acc: 1.0000 - val_loss: 2.5487e-05 - val_acc: 1.0000\n",
      "Epoch 380/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.2074e-05 - acc: 1.0000 - val_loss: 2.5204e-05 - val_acc: 1.0000\n",
      "Epoch 381/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.5851e-05 - acc: 1.0000 - val_loss: 2.5155e-05 - val_acc: 1.0000\n",
      "Epoch 382/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.7907e-05 - acc: 1.0000 - val_loss: 2.5059e-05 - val_acc: 1.0000\n",
      "Epoch 383/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 3.7621e-05 - acc: 1.0000 - val_loss: 2.4701e-05 - val_acc: 1.0000\n",
      "Epoch 384/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.0829e-05 - acc: 1.0000 - val_loss: 2.4279e-05 - val_acc: 1.0000\n",
      "Epoch 385/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 3.6429e-05 - acc: 1.0000 - val_loss: 2.3987e-05 - val_acc: 1.0000\n",
      "Epoch 386/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 3.8407e-05 - acc: 1.0000 - val_loss: 2.3819e-05 - val_acc: 1.0000\n",
      "Epoch 387/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.6225e-05 - acc: 1.0000 - val_loss: 2.3838e-05 - val_acc: 1.0000\n",
      "Epoch 388/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.3569e-05 - acc: 1.0000 - val_loss: 2.3806e-05 - val_acc: 1.0000\n",
      "Epoch 389/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.2528e-05 - acc: 1.0000 - val_loss: 2.3592e-05 - val_acc: 1.0000\n",
      "Epoch 390/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3021e-05 - acc: 1.0000 - val_loss: 2.3357e-05 - val_acc: 1.0000\n",
      "Epoch 391/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 69us/step - loss: 3.3694e-05 - acc: 1.0000 - val_loss: 2.3265e-05 - val_acc: 1.0000\n",
      "Epoch 392/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 3.4237e-05 - acc: 1.0000 - val_loss: 2.3178e-05 - val_acc: 1.0000\n",
      "Epoch 393/10000\n",
      "1139/1139 [==============================] - 0s 54us/step - loss: 3.3673e-05 - acc: 1.0000 - val_loss: 2.3153e-05 - val_acc: 1.0000\n",
      "Epoch 394/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.7483e-05 - acc: 1.0000 - val_loss: 2.2771e-05 - val_acc: 1.0000\n",
      "Epoch 395/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.1208e-05 - acc: 1.0000 - val_loss: 2.2441e-05 - val_acc: 1.0000\n",
      "Epoch 396/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 3.2485e-05 - acc: 1.0000 - val_loss: 2.2248e-05 - val_acc: 1.0000\n",
      "Epoch 397/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3595e-05 - acc: 1.0000 - val_loss: 2.2057e-05 - val_acc: 1.0000\n",
      "Epoch 398/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.5839e-05 - acc: 1.0000 - val_loss: 2.1880e-05 - val_acc: 1.0000\n",
      "Epoch 399/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4607e-05 - acc: 1.0000 - val_loss: 2.1772e-05 - val_acc: 1.0000\n",
      "Epoch 400/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 3.1229e-05 - acc: 1.0000 - val_loss: 2.1709e-05 - val_acc: 1.0000\n",
      "Epoch 401/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 3.4067e-05 - acc: 1.0000 - val_loss: 2.1701e-05 - val_acc: 1.0000\n",
      "Epoch 402/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8396e-05 - acc: 1.0000 - val_loss: 2.1573e-05 - val_acc: 1.0000\n",
      "Epoch 403/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.0236e-05 - acc: 1.0000 - val_loss: 2.1439e-05 - val_acc: 1.0000\n",
      "Epoch 404/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.9939e-05 - acc: 1.0000 - val_loss: 2.1284e-05 - val_acc: 1.0000\n",
      "Epoch 405/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 3.0342e-05 - acc: 1.0000 - val_loss: 2.1201e-05 - val_acc: 1.0000\n",
      "Epoch 406/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.9392e-05 - acc: 1.0000 - val_loss: 2.1038e-05 - val_acc: 1.0000\n",
      "Epoch 407/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.5086e-05 - acc: 1.0000 - val_loss: 2.0532e-05 - val_acc: 1.0000\n",
      "Epoch 408/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.1915e-05 - acc: 1.0000 - val_loss: 2.0174e-05 - val_acc: 1.0000\n",
      "Epoch 409/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.2512e-05 - acc: 1.0000 - val_loss: 2.0068e-05 - val_acc: 1.0000\n",
      "Epoch 410/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.8088e-05 - acc: 1.0000 - val_loss: 1.9998e-05 - val_acc: 1.0000\n",
      "Epoch 411/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.9622e-05 - acc: 1.0000 - val_loss: 1.9904e-05 - val_acc: 1.0000\n",
      "Epoch 412/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8742e-05 - acc: 1.0000 - val_loss: 1.9684e-05 - val_acc: 1.0000\n",
      "Epoch 413/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.2493e-05 - acc: 1.0000 - val_loss: 1.9724e-05 - val_acc: 1.0000\n",
      "Epoch 414/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.0986e-05 - acc: 1.0000 - val_loss: 1.9671e-05 - val_acc: 1.0000\n",
      "Epoch 415/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.8950e-05 - acc: 1.0000 - val_loss: 1.9351e-05 - val_acc: 1.0000\n",
      "Epoch 416/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 2.5532e-05 - acc: 1.0000 - val_loss: 1.9145e-05 - val_acc: 1.0000\n",
      "Epoch 417/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.5155e-05 - acc: 1.0000 - val_loss: 1.8877e-05 - val_acc: 1.0000\n",
      "Epoch 418/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 2.8299e-05 - acc: 1.0000 - val_loss: 1.8567e-05 - val_acc: 1.0000\n",
      "Epoch 419/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.8922e-05 - acc: 1.0000 - val_loss: 1.8423e-05 - val_acc: 1.0000\n",
      "Epoch 420/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.6795e-05 - acc: 1.0000 - val_loss: 1.8303e-05 - val_acc: 1.0000\n",
      "Epoch 421/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.6713e-05 - acc: 1.0000 - val_loss: 1.8329e-05 - val_acc: 1.0000\n",
      "Epoch 422/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.7801e-05 - acc: 1.0000 - val_loss: 1.8144e-05 - val_acc: 1.0000\n",
      "Epoch 423/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.5596e-05 - acc: 1.0000 - val_loss: 1.7988e-05 - val_acc: 1.0000\n",
      "Epoch 424/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.7642e-05 - acc: 1.0000 - val_loss: 1.7869e-05 - val_acc: 1.0000\n",
      "Epoch 425/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.6211e-05 - acc: 1.0000 - val_loss: 1.7707e-05 - val_acc: 1.0000\n",
      "Epoch 426/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.7383e-05 - acc: 1.0000 - val_loss: 1.7524e-05 - val_acc: 1.0000\n",
      "Epoch 427/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 2.4181e-05 - acc: 1.0000 - val_loss: 1.7341e-05 - val_acc: 1.0000\n",
      "Epoch 428/10000\n",
      "1139/1139 [==============================] - 0s 17us/step - loss: 2.3373e-05 - acc: 1.0000 - val_loss: 1.7234e-05 - val_acc: 1.0000\n",
      "Epoch 429/10000\n",
      "1139/1139 [==============================] - 0s 44us/step - loss: 2.5050e-05 - acc: 1.0000 - val_loss: 1.7164e-05 - val_acc: 1.0000\n",
      "Epoch 430/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.8039e-05 - acc: 1.0000 - val_loss: 1.7000e-05 - val_acc: 1.0000\n",
      "Epoch 431/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 2.8078e-05 - acc: 1.0000 - val_loss: 1.6777e-05 - val_acc: 1.0000\n",
      "Epoch 432/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 2.4837e-05 - acc: 1.0000 - val_loss: 1.6617e-05 - val_acc: 1.0000\n",
      "Epoch 433/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 2.9037e-05 - acc: 1.0000 - val_loss: 1.6731e-05 - val_acc: 1.0000\n",
      "Epoch 434/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.6569e-05 - acc: 1.0000 - val_loss: 1.6821e-05 - val_acc: 1.0000\n",
      "Epoch 435/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 2.4124e-05 - acc: 1.0000 - val_loss: 1.6731e-05 - val_acc: 1.0000\n",
      "Epoch 436/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 3.0602e-05 - acc: 1.0000 - val_loss: 1.6529e-05 - val_acc: 1.0000\n",
      "Epoch 437/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.6409e-05 - acc: 1.0000 - val_loss: 1.6516e-05 - val_acc: 1.0000\n",
      "Epoch 438/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.7435e-05 - acc: 1.0000 - val_loss: 1.6237e-05 - val_acc: 1.0000\n",
      "Epoch 439/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.4636e-05 - acc: 1.0000 - val_loss: 1.6066e-05 - val_acc: 1.0000\n",
      "Epoch 440/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 2.2259e-05 - acc: 1.0000 - val_loss: 1.5920e-05 - val_acc: 1.0000\n",
      "Epoch 441/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.3548e-05 - acc: 1.0000 - val_loss: 1.5787e-05 - val_acc: 1.0000\n",
      "Epoch 442/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 2.3219e-05 - acc: 1.0000 - val_loss: 1.5612e-05 - val_acc: 1.0000\n",
      "Epoch 443/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.9943e-05 - acc: 1.0000 - val_loss: 1.5461e-05 - val_acc: 1.0000\n",
      "Epoch 444/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 2.3547e-05 - acc: 1.0000 - val_loss: 1.5336e-05 - val_acc: 1.0000\n",
      "Epoch 445/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.4182e-05 - acc: 1.0000 - val_loss: 1.5161e-05 - val_acc: 1.0000\n",
      "Epoch 446/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 30us/step - loss: 2.1968e-05 - acc: 1.0000 - val_loss: 1.5077e-05 - val_acc: 1.0000\n",
      "Epoch 447/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 2.2548e-05 - acc: 1.0000 - val_loss: 1.5113e-05 - val_acc: 1.0000\n",
      "Epoch 448/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.0674e-05 - acc: 1.0000 - val_loss: 1.5175e-05 - val_acc: 1.0000\n",
      "Epoch 449/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.1414e-05 - acc: 1.0000 - val_loss: 1.5112e-05 - val_acc: 1.0000\n",
      "Epoch 450/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.2709e-05 - acc: 1.0000 - val_loss: 1.5067e-05 - val_acc: 1.0000\n",
      "Epoch 451/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 2.1732e-05 - acc: 1.0000 - val_loss: 1.4991e-05 - val_acc: 1.0000\n",
      "Epoch 452/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.2759e-05 - acc: 1.0000 - val_loss: 1.4774e-05 - val_acc: 1.0000\n",
      "Epoch 453/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.2116e-05 - acc: 1.0000 - val_loss: 1.4648e-05 - val_acc: 1.0000\n",
      "Epoch 454/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.1229e-05 - acc: 1.0000 - val_loss: 1.4464e-05 - val_acc: 1.0000\n",
      "Epoch 455/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.0635e-05 - acc: 1.0000 - val_loss: 1.4272e-05 - val_acc: 1.0000\n",
      "Epoch 456/10000\n",
      "1139/1139 [==============================] - 0s 44us/step - loss: 2.1259e-05 - acc: 1.0000 - val_loss: 1.4222e-05 - val_acc: 1.0000\n",
      "Epoch 457/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.1567e-05 - acc: 1.0000 - val_loss: 1.4138e-05 - val_acc: 1.0000\n",
      "Epoch 458/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 2.2006e-05 - acc: 1.0000 - val_loss: 1.3997e-05 - val_acc: 1.0000\n",
      "Epoch 459/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 2.9717e-05 - acc: 1.000 - 0s 31us/step - loss: 1.8138e-05 - acc: 1.0000 - val_loss: 1.3838e-05 - val_acc: 1.0000\n",
      "Epoch 460/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.9299e-05 - acc: 1.0000 - val_loss: 1.3786e-05 - val_acc: 1.0000\n",
      "Epoch 461/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.0479e-05 - acc: 1.0000 - val_loss: 1.3691e-05 - val_acc: 1.0000\n",
      "Epoch 462/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.0164e-05 - acc: 1.0000 - val_loss: 1.3592e-05 - val_acc: 1.0000\n",
      "Epoch 463/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.4452e-05 - acc: 1.0000 - val_loss: 1.3498e-05 - val_acc: 1.0000\n",
      "Epoch 464/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.1836e-05 - acc: 1.0000 - val_loss: 1.3393e-05 - val_acc: 1.0000\n",
      "Epoch 465/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.9558e-05 - acc: 1.0000 - val_loss: 1.3338e-05 - val_acc: 1.0000\n",
      "Epoch 466/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 2.1426e-05 - acc: 1.0000 - val_loss: 1.3273e-05 - val_acc: 1.0000\n",
      "Epoch 467/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.0124e-05 - acc: 1.0000 - val_loss: 1.3170e-05 - val_acc: 1.0000\n",
      "Epoch 468/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.9334e-05 - acc: 1.0000 - val_loss: 1.3044e-05 - val_acc: 1.0000\n",
      "Epoch 469/10000\n",
      "1139/1139 [==============================] - 0s 56us/step - loss: 2.0033e-05 - acc: 1.0000 - val_loss: 1.2958e-05 - val_acc: 1.0000\n",
      "Epoch 470/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.8341e-05 - acc: 1.0000 - val_loss: 1.2885e-05 - val_acc: 1.0000\n",
      "Epoch 471/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.8898e-05 - acc: 1.0000 - val_loss: 1.2767e-05 - val_acc: 1.0000\n",
      "Epoch 472/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.8706e-05 - acc: 1.0000 - val_loss: 1.2559e-05 - val_acc: 1.0000\n",
      "Epoch 473/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.9449e-05 - acc: 1.0000 - val_loss: 1.2454e-05 - val_acc: 1.0000\n",
      "Epoch 474/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.8047e-05 - acc: 1.0000 - val_loss: 1.2360e-05 - val_acc: 1.0000\n",
      "Epoch 475/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 2.0825e-05 - acc: 1.0000 - val_loss: 1.2282e-05 - val_acc: 1.0000\n",
      "Epoch 476/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.1615e-05 - acc: 1.0000 - val_loss: 1.2233e-05 - val_acc: 1.0000\n",
      "Epoch 477/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.0470e-05 - acc: 1.0000 - val_loss: 1.2183e-05 - val_acc: 1.0000\n",
      "Epoch 478/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.9567e-05 - acc: 1.0000 - val_loss: 1.2120e-05 - val_acc: 1.0000\n",
      "Epoch 479/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 1.7391e-05 - acc: 1.0000 - val_loss: 1.2102e-05 - val_acc: 1.0000\n",
      "Epoch 480/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.8689e-05 - acc: 1.0000 - val_loss: 1.2127e-05 - val_acc: 1.0000\n",
      "Epoch 481/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.8826e-05 - acc: 1.0000 - val_loss: 1.2036e-05 - val_acc: 1.0000\n",
      "Epoch 482/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.7137e-05 - acc: 1.0000 - val_loss: 1.1951e-05 - val_acc: 1.0000\n",
      "Epoch 483/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.8598e-05 - acc: 1.0000 - val_loss: 1.1782e-05 - val_acc: 1.0000\n",
      "Epoch 484/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.7841e-05 - acc: 1.0000 - val_loss: 1.1665e-05 - val_acc: 1.0000\n",
      "Epoch 485/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.9103e-05 - acc: 1.0000 - val_loss: 1.1581e-05 - val_acc: 1.0000\n",
      "Epoch 486/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.8829e-05 - acc: 1.0000 - val_loss: 1.1506e-05 - val_acc: 1.0000\n",
      "Epoch 487/10000\n",
      "1139/1139 [==============================] - 0s 52us/step - loss: 1.9265e-05 - acc: 1.0000 - val_loss: 1.1487e-05 - val_acc: 1.0000\n",
      "Epoch 488/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5903e-05 - acc: 1.0000 - val_loss: 1.1419e-05 - val_acc: 1.0000\n",
      "Epoch 489/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.5018e-05 - acc: 1.0000 - val_loss: 1.1317e-05 - val_acc: 1.0000\n",
      "Epoch 490/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.7628e-05 - acc: 1.0000 - val_loss: 1.1172e-05 - val_acc: 1.0000\n",
      "Epoch 491/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.6670e-05 - acc: 1.0000 - val_loss: 1.0983e-05 - val_acc: 1.0000\n",
      "Epoch 492/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 2.0206e-05 - acc: 1.0000 - val_loss: 1.0833e-05 - val_acc: 1.0000\n",
      "Epoch 493/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.8245e-05 - acc: 1.0000 - val_loss: 1.0819e-05 - val_acc: 1.0000\n",
      "Epoch 494/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.7584e-05 - acc: 1.0000 - val_loss: 1.0808e-05 - val_acc: 1.0000\n",
      "Epoch 495/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 1.6210e-05 - acc: 1.0000 - val_loss: 1.0739e-05 - val_acc: 1.0000\n",
      "Epoch 496/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.7949e-05 - acc: 1.0000 - val_loss: 1.0727e-05 - val_acc: 1.0000\n",
      "Epoch 497/10000\n",
      "1139/1139 [==============================] - 0s 43us/step - loss: 1.6999e-05 - acc: 1.0000 - val_loss: 1.0639e-05 - val_acc: 1.0000\n",
      "Epoch 498/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 1.7909e-05 - acc: 1.0000 - val_loss: 1.0666e-05 - val_acc: 1.0000\n",
      "Epoch 499/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.6048e-05 - acc: 1.0000 - val_loss: 1.0783e-05 - val_acc: 1.0000\n",
      "Epoch 500/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.7255e-05 - acc: 1.0000 - val_loss: 1.0727e-05 - val_acc: 1.0000\n",
      "Epoch 501/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5358e-05 - acc: 1.0000 - val_loss: 1.0581e-05 - val_acc: 1.0000\n",
      "Epoch 502/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5728e-05 - acc: 1.0000 - val_loss: 1.0413e-05 - val_acc: 1.0000\n",
      "Epoch 503/10000\n",
      "1139/1139 [==============================] - 0s 43us/step - loss: 1.6687e-05 - acc: 1.0000 - val_loss: 1.0348e-05 - val_acc: 1.0000\n",
      "Epoch 504/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.4739e-05 - acc: 1.0000 - val_loss: 1.0280e-05 - val_acc: 1.0000\n",
      "Epoch 505/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.5368e-05 - acc: 1.0000 - val_loss: 1.0155e-05 - val_acc: 1.0000\n",
      "Epoch 506/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 1.4755e-05 - acc: 1.0000 - val_loss: 1.0062e-05 - val_acc: 1.0000\n",
      "Epoch 507/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.6046e-05 - acc: 1.0000 - val_loss: 9.9233e-06 - val_acc: 1.0000\n",
      "Epoch 508/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.5535e-05 - acc: 1.0000 - val_loss: 9.8147e-06 - val_acc: 1.0000\n",
      "Epoch 509/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 1.4195e-05 - acc: 1.0000 - val_loss: 9.7574e-06 - val_acc: 1.0000\n",
      "Epoch 510/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.3581e-05 - acc: 1.0000 - val_loss: 9.7117e-06 - val_acc: 1.0000\n",
      "Epoch 511/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.9763e-05 - acc: 1.0000 - val_loss: 9.8596e-06 - val_acc: 1.0000\n",
      "Epoch 512/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5426e-05 - acc: 1.0000 - val_loss: 1.0360e-05 - val_acc: 1.0000\n",
      "Epoch 513/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.4928e-05 - acc: 1.0000 - val_loss: 1.0286e-05 - val_acc: 1.0000\n",
      "Epoch 514/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.4237e-05 - acc: 1.0000 - val_loss: 1.0050e-05 - val_acc: 1.0000\n",
      "Epoch 515/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.3840e-05 - acc: 1.0000 - val_loss: 9.8195e-06 - val_acc: 1.0000\n",
      "Epoch 516/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 1.4775e-05 - acc: 1.0000 - val_loss: 9.6211e-06 - val_acc: 1.0000\n",
      "Epoch 517/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.5237e-05 - acc: 1.0000 - val_loss: 9.5046e-06 - val_acc: 1.0000\n",
      "Epoch 518/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 1.3880e-05 - acc: 1.0000 - val_loss: 9.3871e-06 - val_acc: 1.0000\n",
      "Epoch 519/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.4363e-05 - acc: 1.0000 - val_loss: 9.3372e-06 - val_acc: 1.0000\n",
      "Epoch 520/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5691e-05 - acc: 1.0000 - val_loss: 9.2326e-06 - val_acc: 1.0000\n",
      "Epoch 521/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.3048e-05 - acc: 1.0000 - val_loss: 9.1215e-06 - val_acc: 1.0000\n",
      "Epoch 522/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.4325e-05 - acc: 1.0000 - val_loss: 9.0246e-06 - val_acc: 1.0000\n",
      "Epoch 523/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 1.4839e-05 - acc: 1.0000 - val_loss: 8.9799e-06 - val_acc: 1.0000\n",
      "Epoch 524/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.5106e-05 - acc: 1.0000 - val_loss: 8.9642e-06 - val_acc: 1.0000\n",
      "Epoch 525/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.4317e-05 - acc: 1.0000 - val_loss: 8.9221e-06 - val_acc: 1.0000\n",
      "Epoch 526/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5200e-05 - acc: 1.0000 - val_loss: 8.9100e-06 - val_acc: 1.0000\n",
      "Epoch 527/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.2869e-05 - acc: 1.0000 - val_loss: 8.8580e-06 - val_acc: 1.0000\n",
      "Epoch 528/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.2309e-05 - acc: 1.0000 - val_loss: 8.7717e-06 - val_acc: 1.0000\n",
      "Epoch 529/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.3691e-05 - acc: 1.0000 - val_loss: 8.6826e-06 - val_acc: 1.0000\n",
      "Epoch 530/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.3638e-05 - acc: 1.0000 - val_loss: 8.6058e-06 - val_acc: 1.0000\n",
      "Epoch 531/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.3052e-05 - acc: 1.0000 - val_loss: 8.5092e-06 - val_acc: 1.0000\n",
      "Epoch 532/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.4077e-05 - acc: 1.0000 - val_loss: 8.3776e-06 - val_acc: 1.0000\n",
      "Epoch 533/10000\n",
      "1139/1139 [==============================] - 0s 53us/step - loss: 1.3824e-05 - acc: 1.0000 - val_loss: 8.3380e-06 - val_acc: 1.0000\n",
      "Epoch 534/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.2348e-05 - acc: 1.0000 - val_loss: 8.2867e-06 - val_acc: 1.0000\n",
      "Epoch 535/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.2660e-05 - acc: 1.0000 - val_loss: 8.2201e-06 - val_acc: 1.0000\n",
      "Epoch 536/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2257e-05 - acc: 1.0000 - val_loss: 8.1686e-06 - val_acc: 1.0000\n",
      "Epoch 537/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 1.0569e-05 - acc: 1.000 - 0s 38us/step - loss: 1.3277e-05 - acc: 1.0000 - val_loss: 8.1078e-06 - val_acc: 1.0000\n",
      "Epoch 538/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.1737e-05 - acc: 1.0000 - val_loss: 8.0830e-06 - val_acc: 1.0000\n",
      "Epoch 539/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.2051e-05 - acc: 1.0000 - val_loss: 8.0894e-06 - val_acc: 1.0000\n",
      "Epoch 540/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.3361e-05 - acc: 1.0000 - val_loss: 8.0658e-06 - val_acc: 1.0000\n",
      "Epoch 541/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.1680e-05 - acc: 1.0000 - val_loss: 8.0205e-06 - val_acc: 1.0000\n",
      "Epoch 542/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.3646e-05 - acc: 1.0000 - val_loss: 8.0310e-06 - val_acc: 1.0000\n",
      "Epoch 543/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.1929e-05 - acc: 1.0000 - val_loss: 7.9677e-06 - val_acc: 1.0000\n",
      "Epoch 544/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.2497e-05 - acc: 1.0000 - val_loss: 7.8970e-06 - val_acc: 1.0000\n",
      "Epoch 545/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.1016e-05 - acc: 1.0000 - val_loss: 7.7657e-06 - val_acc: 1.0000\n",
      "Epoch 546/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.0634e-05 - acc: 1.0000 - val_loss: 7.6698e-06 - val_acc: 1.0000\n",
      "Epoch 547/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.2040e-05 - acc: 1.0000 - val_loss: 7.5614e-06 - val_acc: 1.0000\n",
      "Epoch 548/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 1.1688e-05 - acc: 1.0000 - val_loss: 7.4882e-06 - val_acc: 1.0000\n",
      "Epoch 549/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.0853e-05 - acc: 1.0000 - val_loss: 7.4854e-06 - val_acc: 1.0000\n",
      "Epoch 550/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.1567e-05 - acc: 1.0000 - val_loss: 7.4943e-06 - val_acc: 1.0000\n",
      "Epoch 551/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.1949e-05 - acc: 1.0000 - val_loss: 7.4641e-06 - val_acc: 1.0000\n",
      "Epoch 552/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.2642e-05 - acc: 1.0000 - val_loss: 7.4055e-06 - val_acc: 1.0000\n",
      "Epoch 553/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.1713e-05 - acc: 1.0000 - val_loss: 7.3644e-06 - val_acc: 1.0000\n",
      "Epoch 554/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.1193e-05 - acc: 1.0000 - val_loss: 7.2973e-06 - val_acc: 1.0000\n",
      "Epoch 555/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.1178e-05 - acc: 1.0000 - val_loss: 7.1994e-06 - val_acc: 1.0000\n",
      "Epoch 556/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.2724e-05 - acc: 1.0000 - val_loss: 7.0917e-06 - val_acc: 1.0000\n",
      "Epoch 557/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 1.1124e-05 - acc: 1.0000 - val_loss: 7.0091e-06 - val_acc: 1.0000\n",
      "Epoch 558/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 1.0956e-05 - acc: 1.0000 - val_loss: 6.9364e-06 - val_acc: 1.0000\n",
      "Epoch 559/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.1806e-05 - acc: 1.0000 - val_loss: 6.9068e-06 - val_acc: 1.0000\n",
      "Epoch 560/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.0221e-05 - acc: 1.0000 - val_loss: 6.9162e-06 - val_acc: 1.0000\n",
      "Epoch 561/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.1843e-05 - acc: 1.0000 - val_loss: 6.9344e-06 - val_acc: 1.0000\n",
      "Epoch 562/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.2215e-05 - acc: 1.0000 - val_loss: 6.9419e-06 - val_acc: 1.0000\n",
      "Epoch 563/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.0354e-05 - acc: 1.0000 - val_loss: 6.9094e-06 - val_acc: 1.0000\n",
      "Epoch 564/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.0495e-05 - acc: 1.0000 - val_loss: 6.8739e-06 - val_acc: 1.0000\n",
      "Epoch 565/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.0940e-06 - acc: 1.0000 - val_loss: 6.8141e-06 - val_acc: 1.0000\n",
      "Epoch 566/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.1086e-05 - acc: 1.0000 - val_loss: 6.7422e-06 - val_acc: 1.0000\n",
      "Epoch 567/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.0555e-05 - acc: 1.0000 - val_loss: 6.7107e-06 - val_acc: 1.0000\n",
      "Epoch 568/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.0524e-05 - acc: 1.0000 - val_loss: 6.6271e-06 - val_acc: 1.0000\n",
      "Epoch 569/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 1.0080e-05 - acc: 1.0000 - val_loss: 6.5424e-06 - val_acc: 1.0000\n",
      "Epoch 570/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 1.0689e-05 - acc: 1.0000 - val_loss: 6.4798e-06 - val_acc: 1.0000\n",
      "Epoch 571/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.0048e-05 - acc: 1.0000 - val_loss: 6.4460e-06 - val_acc: 1.0000\n",
      "Epoch 572/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.3620e-05 - acc: 1.0000 - val_loss: 6.4075e-06 - val_acc: 1.0000\n",
      "Epoch 573/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.0066e-05 - acc: 1.0000 - val_loss: 6.3586e-06 - val_acc: 1.0000\n",
      "Epoch 574/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.1063e-05 - acc: 1.0000 - val_loss: 6.2909e-06 - val_acc: 1.0000\n",
      "Epoch 575/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.0597e-05 - acc: 1.0000 - val_loss: 6.2760e-06 - val_acc: 1.0000\n",
      "Epoch 576/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.8505e-06 - acc: 1.0000 - val_loss: 6.2604e-06 - val_acc: 1.0000\n",
      "Epoch 577/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.9057e-06 - acc: 1.0000 - val_loss: 6.2583e-06 - val_acc: 1.0000\n",
      "Epoch 578/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.0700e-05 - acc: 1.0000 - val_loss: 6.2407e-06 - val_acc: 1.0000\n",
      "Epoch 579/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.7560e-06 - acc: 1.0000 - val_loss: 6.2065e-06 - val_acc: 1.0000\n",
      "Epoch 580/10000\n",
      "1139/1139 [==============================] - 0s 43us/step - loss: 1.1210e-05 - acc: 1.0000 - val_loss: 6.1953e-06 - val_acc: 1.0000\n",
      "Epoch 581/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 9.7480e-06 - acc: 1.0000 - val_loss: 6.1492e-06 - val_acc: 1.0000\n",
      "Epoch 582/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.0089e-05 - acc: 1.0000 - val_loss: 6.1420e-06 - val_acc: 1.0000\n",
      "Epoch 583/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 9.3454e-06 - acc: 1.0000 - val_loss: 6.0598e-06 - val_acc: 1.0000\n",
      "Epoch 584/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.6332e-06 - acc: 1.0000 - val_loss: 5.9654e-06 - val_acc: 1.0000\n",
      "Epoch 585/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 9.7128e-06 - acc: 1.0000 - val_loss: 5.8677e-06 - val_acc: 1.0000\n",
      "Epoch 586/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 9.8553e-06 - acc: 1.0000 - val_loss: 5.8010e-06 - val_acc: 1.0000\n",
      "Epoch 587/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.3723e-06 - acc: 1.0000 - val_loss: 5.7777e-06 - val_acc: 1.0000\n",
      "Epoch 588/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.0518e-05 - acc: 1.0000 - val_loss: 5.7645e-06 - val_acc: 1.0000\n",
      "Epoch 589/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 9.2547e-06 - acc: 1.0000 - val_loss: 5.7675e-06 - val_acc: 1.0000\n",
      "Epoch 590/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 8.8770e-06 - acc: 1.0000 - val_loss: 5.7774e-06 - val_acc: 1.0000\n",
      "Epoch 591/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 9.2430e-06 - acc: 1.0000 - val_loss: 5.7501e-06 - val_acc: 1.0000\n",
      "Epoch 592/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 9.6651e-06 - acc: 1.0000 - val_loss: 5.6832e-06 - val_acc: 1.0000\n",
      "Epoch 593/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 8.4254e-06 - acc: 1.0000 - val_loss: 5.6369e-06 - val_acc: 1.0000\n",
      "Epoch 594/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 8.5073e-06 - acc: 1.0000 - val_loss: 5.6099e-06 - val_acc: 1.0000\n",
      "Epoch 595/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.0373e-06 - acc: 1.0000 - val_loss: 5.5996e-06 - val_acc: 1.0000\n",
      "Epoch 596/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 8.0431e-06 - acc: 1.0000 - val_loss: 5.5811e-06 - val_acc: 1.0000\n",
      "Epoch 597/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 8.2988e-06 - acc: 1.0000 - val_loss: 5.5592e-06 - val_acc: 1.0000\n",
      "Epoch 598/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 7.5008e-06 - acc: 1.0000 - val_loss: 5.5130e-06 - val_acc: 1.0000\n",
      "Epoch 599/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 9.2712e-06 - acc: 1.0000 - val_loss: 5.4430e-06 - val_acc: 1.0000\n",
      "Epoch 600/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 9.3484e-06 - acc: 1.0000 - val_loss: 5.3499e-06 - val_acc: 1.0000\n",
      "Epoch 601/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 9.2563e-06 - acc: 1.0000 - val_loss: 5.2854e-06 - val_acc: 1.0000\n",
      "Epoch 602/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 8.0860e-06 - acc: 1.0000 - val_loss: 5.2478e-06 - val_acc: 1.0000\n",
      "Epoch 603/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.0187e-05 - acc: 1.0000 - val_loss: 5.2675e-06 - val_acc: 1.0000\n",
      "Epoch 604/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 8.9285e-06 - acc: 1.0000 - val_loss: 5.2852e-06 - val_acc: 1.0000\n",
      "Epoch 605/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 7.3130e-06 - acc: 1.0000 - val_loss: 5.2805e-06 - val_acc: 1.0000\n",
      "Epoch 606/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 8.8509e-06 - acc: 1.0000 - val_loss: 5.2251e-06 - val_acc: 1.0000\n",
      "Epoch 607/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 8.8542e-06 - acc: 1.0000 - val_loss: 5.1825e-06 - val_acc: 1.0000\n",
      "Epoch 608/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.7161e-06 - acc: 1.0000 - val_loss: 5.1146e-06 - val_acc: 1.0000\n",
      "Epoch 609/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 9.2501e-06 - acc: 1.0000 - val_loss: 5.0773e-06 - val_acc: 1.0000\n",
      "Epoch 610/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 7.8067e-06 - acc: 1.0000 - val_loss: 5.0419e-06 - val_acc: 1.0000\n",
      "Epoch 611/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 36us/step - loss: 7.6863e-06 - acc: 1.0000 - val_loss: 5.0234e-06 - val_acc: 1.0000\n",
      "Epoch 612/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 7.9999e-06 - acc: 1.0000 - val_loss: 4.9951e-06 - val_acc: 1.0000\n",
      "Epoch 613/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 7.4407e-06 - acc: 1.0000 - val_loss: 4.9490e-06 - val_acc: 1.0000\n",
      "Epoch 614/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.5151e-06 - acc: 1.0000 - val_loss: 4.9048e-06 - val_acc: 1.0000\n",
      "Epoch 615/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 8.4212e-06 - acc: 1.0000 - val_loss: 4.8858e-06 - val_acc: 1.0000\n",
      "Epoch 616/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 7.7367e-06 - acc: 1.0000 - val_loss: 4.8712e-06 - val_acc: 1.0000\n",
      "Epoch 617/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.5634e-06 - acc: 1.0000 - val_loss: 4.8442e-06 - val_acc: 1.0000\n",
      "Epoch 618/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.4668e-06 - acc: 1.0000 - val_loss: 4.8670e-06 - val_acc: 1.0000\n",
      "Epoch 619/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 7.8991e-06 - acc: 1.0000 - val_loss: 4.8465e-06 - val_acc: 1.0000\n",
      "Epoch 620/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.3152e-06 - acc: 1.0000 - val_loss: 4.7982e-06 - val_acc: 1.0000\n",
      "Epoch 621/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 6.9251e-06 - acc: 1.0000 - val_loss: 4.7282e-06 - val_acc: 1.0000\n",
      "Epoch 622/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 7.9966e-06 - acc: 1.0000 - val_loss: 4.7220e-06 - val_acc: 1.0000\n",
      "Epoch 623/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 8.0845e-06 - acc: 1.0000 - val_loss: 4.7128e-06 - val_acc: 1.0000\n",
      "Epoch 624/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 7.2585e-06 - acc: 1.0000 - val_loss: 4.6683e-06 - val_acc: 1.0000\n",
      "Epoch 625/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 7.9762e-06 - acc: 1.0000 - val_loss: 4.6314e-06 - val_acc: 1.0000\n",
      "Epoch 626/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 8.4326e-06 - acc: 1.0000 - val_loss: 4.6143e-06 - val_acc: 1.0000\n",
      "Epoch 627/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.2330e-06 - acc: 1.0000 - val_loss: 4.5785e-06 - val_acc: 1.0000\n",
      "Epoch 628/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 7.1873e-06 - acc: 1.0000 - val_loss: 4.5403e-06 - val_acc: 1.0000\n",
      "Epoch 629/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 7.2532e-06 - acc: 1.0000 - val_loss: 4.5045e-06 - val_acc: 1.0000\n",
      "Epoch 630/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 6.8738e-06 - acc: 1.0000 - val_loss: 4.4573e-06 - val_acc: 1.0000\n",
      "Epoch 631/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 6.7037e-06 - acc: 1.0000 - val_loss: 4.4278e-06 - val_acc: 1.0000\n",
      "Epoch 632/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 6.8132e-06 - acc: 1.0000 - val_loss: 4.3910e-06 - val_acc: 1.0000\n",
      "Epoch 633/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 8.1050e-06 - acc: 1.0000 - val_loss: 4.4206e-06 - val_acc: 1.0000\n",
      "Epoch 634/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 6.9536e-06 - acc: 1.0000 - val_loss: 4.4294e-06 - val_acc: 1.0000\n",
      "Epoch 635/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 7.1025e-06 - acc: 1.0000 - val_loss: 4.4131e-06 - val_acc: 1.0000\n",
      "Epoch 636/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 7.7715e-06 - acc: 1.0000 - val_loss: 4.3918e-06 - val_acc: 1.0000\n",
      "Epoch 637/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 7.8133e-06 - acc: 1.0000 - val_loss: 4.3200e-06 - val_acc: 1.0000\n",
      "Epoch 638/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.7990e-06 - acc: 1.0000 - val_loss: 4.2855e-06 - val_acc: 1.0000\n",
      "Epoch 639/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 7.1059e-06 - acc: 1.0000 - val_loss: 4.2898e-06 - val_acc: 1.0000\n",
      "Epoch 640/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.7288e-06 - acc: 1.0000 - val_loss: 4.2844e-06 - val_acc: 1.0000\n",
      "Epoch 641/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 8.1427e-06 - acc: 1.0000 - val_loss: 4.2669e-06 - val_acc: 1.0000\n",
      "Epoch 642/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.0871e-06 - acc: 1.0000 - val_loss: 4.2190e-06 - val_acc: 1.0000\n",
      "Epoch 643/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.1811e-06 - acc: 1.0000 - val_loss: 4.1584e-06 - val_acc: 1.0000\n",
      "Epoch 644/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.3197e-06 - acc: 1.0000 - val_loss: 4.1367e-06 - val_acc: 1.0000\n",
      "Epoch 645/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.4938e-06 - acc: 1.0000 - val_loss: 4.1168e-06 - val_acc: 1.0000\n",
      "Epoch 646/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.6990e-06 - acc: 1.0000 - val_loss: 4.1111e-06 - val_acc: 1.0000\n",
      "Epoch 647/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.6755e-06 - acc: 1.0000 - val_loss: 4.0871e-06 - val_acc: 1.0000\n",
      "Epoch 648/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.7353e-06 - acc: 1.0000 - val_loss: 4.0554e-06 - val_acc: 1.0000\n",
      "Epoch 649/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.4800e-06 - acc: 1.0000 - val_loss: 4.0200e-06 - val_acc: 1.0000\n",
      "Epoch 650/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.4213e-06 - acc: 1.0000 - val_loss: 3.9956e-06 - val_acc: 1.0000\n",
      "Epoch 651/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 6.5389e-06 - acc: 1.0000 - val_loss: 3.9527e-06 - val_acc: 1.0000\n",
      "Epoch 652/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 6.5502e-06 - acc: 1.0000 - val_loss: 3.9378e-06 - val_acc: 1.0000\n",
      "Epoch 653/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 6.5491e-06 - acc: 1.0000 - val_loss: 3.9132e-06 - val_acc: 1.0000\n",
      "Epoch 654/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 6.7014e-06 - acc: 1.0000 - val_loss: 3.8809e-06 - val_acc: 1.0000\n",
      "Epoch 655/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.1347e-06 - acc: 1.0000 - val_loss: 3.8838e-06 - val_acc: 1.0000\n",
      "Epoch 656/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 6.3128e-06 - acc: 1.0000 - val_loss: 3.8634e-06 - val_acc: 1.0000\n",
      "Epoch 657/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 5.9955e-06 - acc: 1.0000 - val_loss: 3.8568e-06 - val_acc: 1.0000\n",
      "Epoch 658/10000\n",
      "1139/1139 [==============================] - 0s 48us/step - loss: 5.8801e-06 - acc: 1.0000 - val_loss: 3.8333e-06 - val_acc: 1.0000\n",
      "Epoch 659/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 6.3360e-06 - acc: 1.0000 - val_loss: 3.7706e-06 - val_acc: 1.0000\n",
      "Epoch 660/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 6.4001e-06 - acc: 1.0000 - val_loss: 3.7175e-06 - val_acc: 1.0000\n",
      "Epoch 661/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.5002e-06 - acc: 1.0000 - val_loss: 3.7295e-06 - val_acc: 1.0000\n",
      "Epoch 662/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.1242e-06 - acc: 1.0000 - val_loss: 3.7197e-06 - val_acc: 1.0000\n",
      "Epoch 663/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.8337e-06 - acc: 1.0000 - val_loss: 3.6938e-06 - val_acc: 1.0000\n",
      "Epoch 664/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.2062e-06 - acc: 1.0000 - val_loss: 3.6605e-06 - val_acc: 1.0000\n",
      "Epoch 665/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 3.7079e-06 - acc: 1.000 - 0s 32us/step - loss: 6.2578e-06 - acc: 1.0000 - val_loss: 3.6189e-06 - val_acc: 1.0000\n",
      "Epoch 666/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 41us/step - loss: 5.1007e-06 - acc: 1.0000 - val_loss: 3.5828e-06 - val_acc: 1.0000\n",
      "Epoch 667/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.4994e-06 - acc: 1.0000 - val_loss: 3.5596e-06 - val_acc: 1.0000\n",
      "Epoch 668/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.6087e-06 - acc: 1.0000 - val_loss: 3.5451e-06 - val_acc: 1.0000\n",
      "Epoch 669/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.9948e-06 - acc: 1.0000 - val_loss: 3.5011e-06 - val_acc: 1.0000\n",
      "Epoch 670/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 5.4590e-06 - acc: 1.0000 - val_loss: 3.4948e-06 - val_acc: 1.0000\n",
      "Epoch 671/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 5.4196e-06 - acc: 1.0000 - val_loss: 3.4884e-06 - val_acc: 1.0000\n",
      "Epoch 672/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.3407e-06 - acc: 1.0000 - val_loss: 3.4580e-06 - val_acc: 1.0000\n",
      "Epoch 673/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.7961e-06 - acc: 1.0000 - val_loss: 3.4477e-06 - val_acc: 1.0000\n",
      "Epoch 674/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 5.5213e-06 - acc: 1.0000 - val_loss: 3.4385e-06 - val_acc: 1.0000\n",
      "Epoch 675/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 6.0769e-06 - acc: 1.0000 - val_loss: 3.4141e-06 - val_acc: 1.0000\n",
      "Epoch 676/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 6.9987e-06 - acc: 1.0000 - val_loss: 3.3770e-06 - val_acc: 1.0000\n",
      "Epoch 677/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.4416e-06 - acc: 1.0000 - val_loss: 3.3335e-06 - val_acc: 1.0000\n",
      "Epoch 678/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.7160e-06 - acc: 1.0000 - val_loss: 3.3443e-06 - val_acc: 1.0000\n",
      "Epoch 679/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.2170e-06 - acc: 1.0000 - val_loss: 3.3440e-06 - val_acc: 1.0000\n",
      "Epoch 680/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.0987e-06 - acc: 1.0000 - val_loss: 3.3570e-06 - val_acc: 1.0000\n",
      "Epoch 681/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.9194e-06 - acc: 1.0000 - val_loss: 3.3395e-06 - val_acc: 1.0000\n",
      "Epoch 682/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 5.7518e-06 - acc: 1.0000 - val_loss: 3.3240e-06 - val_acc: 1.0000\n",
      "Epoch 683/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 5.1456e-06 - acc: 1.0000 - val_loss: 3.2769e-06 - val_acc: 1.0000\n",
      "Epoch 684/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.7459e-06 - acc: 1.0000 - val_loss: 3.2295e-06 - val_acc: 1.0000\n",
      "Epoch 685/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 5.5095e-06 - acc: 1.0000 - val_loss: 3.2084e-06 - val_acc: 1.0000\n",
      "Epoch 686/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.4521e-06 - acc: 1.0000 - val_loss: 3.1934e-06 - val_acc: 1.0000\n",
      "Epoch 687/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 5.1171e-06 - acc: 1.0000 - val_loss: 3.1966e-06 - val_acc: 1.0000\n",
      "Epoch 688/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.5817e-06 - acc: 1.0000 - val_loss: 3.1544e-06 - val_acc: 1.0000\n",
      "Epoch 689/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 4.8656e-06 - acc: 1.0000 - val_loss: 3.1253e-06 - val_acc: 1.0000\n",
      "Epoch 690/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.8803e-06 - acc: 1.0000 - val_loss: 3.1028e-06 - val_acc: 1.0000\n",
      "Epoch 691/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.2338e-06 - acc: 1.0000 - val_loss: 3.0895e-06 - val_acc: 1.0000\n",
      "Epoch 692/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.9175e-06 - acc: 1.0000 - val_loss: 3.0739e-06 - val_acc: 1.0000\n",
      "Epoch 693/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.3116e-06 - acc: 1.0000 - val_loss: 3.0467e-06 - val_acc: 1.0000\n",
      "Epoch 694/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.4736e-06 - acc: 1.0000 - val_loss: 3.0477e-06 - val_acc: 1.0000\n",
      "Epoch 695/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 5.3637e-06 - acc: 1.0000 - val_loss: 3.0232e-06 - val_acc: 1.0000\n",
      "Epoch 696/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 4.9848e-06 - acc: 1.0000 - val_loss: 2.9974e-06 - val_acc: 1.0000\n",
      "Epoch 697/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.4195e-06 - acc: 1.0000 - val_loss: 2.9836e-06 - val_acc: 1.0000\n",
      "Epoch 698/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.2121e-06 - acc: 1.0000 - val_loss: 2.9511e-06 - val_acc: 1.0000\n",
      "Epoch 699/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.9975e-06 - acc: 1.0000 - val_loss: 2.9202e-06 - val_acc: 1.0000\n",
      "Epoch 700/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 4.8002e-06 - acc: 1.0000 - val_loss: 2.9115e-06 - val_acc: 1.0000\n",
      "Epoch 701/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.3248e-06 - acc: 1.0000 - val_loss: 2.8888e-06 - val_acc: 1.0000\n",
      "Epoch 702/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.7483e-06 - acc: 1.0000 - val_loss: 2.8619e-06 - val_acc: 1.0000\n",
      "Epoch 703/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 4.7548e-06 - acc: 1.0000 - val_loss: 2.8325e-06 - val_acc: 1.0000\n",
      "Epoch 704/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 4.4541e-06 - acc: 1.0000 - val_loss: 2.8276e-06 - val_acc: 1.0000\n",
      "Epoch 705/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.3534e-06 - acc: 1.0000 - val_loss: 2.8128e-06 - val_acc: 1.0000\n",
      "Epoch 706/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 5.3425e-06 - acc: 1.0000 - val_loss: 2.8118e-06 - val_acc: 1.0000\n",
      "Epoch 707/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 4.6015e-06 - acc: 1.0000 - val_loss: 2.8268e-06 - val_acc: 1.0000\n",
      "Epoch 708/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.6107e-06 - acc: 1.0000 - val_loss: 2.7983e-06 - val_acc: 1.0000\n",
      "Epoch 709/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.1820e-06 - acc: 1.0000 - val_loss: 2.7726e-06 - val_acc: 1.0000\n",
      "Epoch 710/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 4.3874e-06 - acc: 1.0000 - val_loss: 2.7491e-06 - val_acc: 1.0000\n",
      "Epoch 711/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.0972e-06 - acc: 1.0000 - val_loss: 2.7286e-06 - val_acc: 1.0000\n",
      "Epoch 712/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 4.4856e-06 - acc: 1.0000 - val_loss: 2.7230e-06 - val_acc: 1.0000\n",
      "Epoch 713/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 5.0789e-06 - acc: 1.0000 - val_loss: 2.7148e-06 - val_acc: 1.0000\n",
      "Epoch 714/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 4.5057e-06 - acc: 1.0000 - val_loss: 2.6850e-06 - val_acc: 1.0000\n",
      "Epoch 715/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.8819e-06 - acc: 1.0000 - val_loss: 2.6762e-06 - val_acc: 1.0000\n",
      "Epoch 716/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.4215e-06 - acc: 1.0000 - val_loss: 2.6562e-06 - val_acc: 1.0000\n",
      "Epoch 717/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.8844e-06 - acc: 1.0000 - val_loss: 2.6290e-06 - val_acc: 1.0000\n",
      "Epoch 718/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.6669e-06 - acc: 1.0000 - val_loss: 2.6089e-06 - val_acc: 1.0000\n",
      "Epoch 719/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.2052e-06 - acc: 1.0000 - val_loss: 2.5890e-06 - val_acc: 1.0000\n",
      "Epoch 720/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.9343e-06 - acc: 1.0000 - val_loss: 2.5648e-06 - val_acc: 1.0000\n",
      "Epoch 721/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.5583e-06 - acc: 1.0000 - val_loss: 2.5689e-06 - val_acc: 1.0000\n",
      "Epoch 722/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 4.3321e-06 - acc: 1.0000 - val_loss: 2.5761e-06 - val_acc: 1.0000\n",
      "Epoch 723/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.3078e-06 - acc: 1.0000 - val_loss: 2.5733e-06 - val_acc: 1.0000\n",
      "Epoch 724/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.6699e-06 - acc: 1.0000 - val_loss: 2.5819e-06 - val_acc: 1.0000\n",
      "Epoch 725/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.5425e-06 - acc: 1.0000 - val_loss: 2.5618e-06 - val_acc: 1.0000\n",
      "Epoch 726/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.0390e-06 - acc: 1.0000 - val_loss: 2.5325e-06 - val_acc: 1.0000\n",
      "Epoch 727/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.9967e-06 - acc: 1.0000 - val_loss: 2.5044e-06 - val_acc: 1.0000\n",
      "Epoch 728/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.6522e-06 - acc: 1.0000 - val_loss: 2.4853e-06 - val_acc: 1.0000\n",
      "Epoch 729/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.8363e-06 - acc: 1.0000 - val_loss: 2.4579e-06 - val_acc: 1.0000\n",
      "Epoch 730/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 4.1249e-06 - acc: 1.0000 - val_loss: 2.4331e-06 - val_acc: 1.0000\n",
      "Epoch 731/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 3.8098e-06 - acc: 1.0000 - val_loss: 2.4174e-06 - val_acc: 1.0000\n",
      "Epoch 732/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.7836e-06 - acc: 1.0000 - val_loss: 2.4136e-06 - val_acc: 1.0000\n",
      "Epoch 733/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.6075e-06 - acc: 1.0000 - val_loss: 2.4337e-06 - val_acc: 1.0000\n",
      "Epoch 734/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 4.0066e-06 - acc: 1.0000 - val_loss: 2.4313e-06 - val_acc: 1.0000\n",
      "Epoch 735/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.7143e-06 - acc: 1.0000 - val_loss: 2.4032e-06 - val_acc: 1.0000\n",
      "Epoch 736/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.2119e-06 - acc: 1.0000 - val_loss: 2.3805e-06 - val_acc: 1.0000\n",
      "Epoch 737/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 4.1358e-06 - acc: 1.0000 - val_loss: 2.3446e-06 - val_acc: 1.0000\n",
      "Epoch 738/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 4.4757e-06 - acc: 1.0000 - val_loss: 2.3265e-06 - val_acc: 1.0000\n",
      "Epoch 739/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 4.0258e-06 - acc: 1.0000 - val_loss: 2.3102e-06 - val_acc: 1.0000\n",
      "Epoch 740/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 3.5418e-06 - acc: 1.0000 - val_loss: 2.3004e-06 - val_acc: 1.0000\n",
      "Epoch 741/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.0218e-06 - acc: 1.0000 - val_loss: 2.2917e-06 - val_acc: 1.0000\n",
      "Epoch 742/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.2622e-06 - acc: 1.0000 - val_loss: 2.2776e-06 - val_acc: 1.0000\n",
      "Epoch 743/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5130e-06 - acc: 1.0000 - val_loss: 2.2584e-06 - val_acc: 1.0000\n",
      "Epoch 744/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 3.5336e-06 - acc: 1.0000 - val_loss: 2.2481e-06 - val_acc: 1.0000\n",
      "Epoch 745/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 4.0948e-06 - acc: 1.0000 - val_loss: 2.2289e-06 - val_acc: 1.0000\n",
      "Epoch 746/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.6895e-06 - acc: 1.0000 - val_loss: 2.2101e-06 - val_acc: 1.0000\n",
      "Epoch 747/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6384e-06 - acc: 1.0000 - val_loss: 2.2052e-06 - val_acc: 1.0000\n",
      "Epoch 748/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.3732e-06 - acc: 1.0000 - val_loss: 2.1965e-06 - val_acc: 1.0000\n",
      "Epoch 749/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.5905e-06 - acc: 1.0000 - val_loss: 2.1755e-06 - val_acc: 1.0000\n",
      "Epoch 750/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.2515e-06 - acc: 1.0000 - val_loss: 2.1889e-06 - val_acc: 1.0000\n",
      "Epoch 751/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.7139e-06 - acc: 1.0000 - val_loss: 2.1826e-06 - val_acc: 1.0000\n",
      "Epoch 752/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.6383e-06 - acc: 1.0000 - val_loss: 2.1621e-06 - val_acc: 1.0000\n",
      "Epoch 753/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.6003e-06 - acc: 1.0000 - val_loss: 2.1472e-06 - val_acc: 1.0000\n",
      "Epoch 754/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.7873e-06 - acc: 1.0000 - val_loss: 2.1247e-06 - val_acc: 1.0000\n",
      "Epoch 755/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.7784e-06 - acc: 1.0000 - val_loss: 2.0986e-06 - val_acc: 1.0000\n",
      "Epoch 756/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.5159e-06 - acc: 1.0000 - val_loss: 2.0773e-06 - val_acc: 1.0000\n",
      "Epoch 757/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 3.2832e-06 - acc: 1.0000 - val_loss: 2.0543e-06 - val_acc: 1.0000\n",
      "Epoch 758/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.9835e-06 - acc: 1.0000 - val_loss: 2.0397e-06 - val_acc: 1.0000\n",
      "Epoch 759/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.6092e-06 - acc: 1.0000 - val_loss: 2.0341e-06 - val_acc: 1.0000\n",
      "Epoch 760/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.4185e-06 - acc: 1.0000 - val_loss: 2.0192e-06 - val_acc: 1.0000\n",
      "Epoch 761/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.8162e-06 - acc: 1.0000 - val_loss: 2.0055e-06 - val_acc: 1.0000\n",
      "Epoch 762/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 3.3452e-06 - acc: 1.0000 - val_loss: 1.9983e-06 - val_acc: 1.0000\n",
      "Epoch 763/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 3.6065e-06 - acc: 1.0000 - val_loss: 1.9944e-06 - val_acc: 1.0000\n",
      "Epoch 764/10000\n",
      "1139/1139 [==============================] - 0s 52us/step - loss: 3.1309e-06 - acc: 1.0000 - val_loss: 1.9877e-06 - val_acc: 1.0000\n",
      "Epoch 765/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.2938e-06 - acc: 1.0000 - val_loss: 1.9849e-06 - val_acc: 1.0000\n",
      "Epoch 766/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 3.6477e-06 - acc: 1.0000 - val_loss: 1.9826e-06 - val_acc: 1.0000\n",
      "Epoch 767/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.3739e-06 - acc: 1.0000 - val_loss: 1.9592e-06 - val_acc: 1.0000\n",
      "Epoch 768/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.3772e-06 - acc: 1.0000 - val_loss: 1.9542e-06 - val_acc: 1.0000\n",
      "Epoch 769/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.8029e-06 - acc: 1.0000 - val_loss: 1.9417e-06 - val_acc: 1.0000\n",
      "Epoch 770/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.3491e-06 - acc: 1.0000 - val_loss: 1.9249e-06 - val_acc: 1.0000\n",
      "Epoch 771/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8519e-06 - acc: 1.0000 - val_loss: 1.9010e-06 - val_acc: 1.0000\n",
      "Epoch 772/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.9333e-06 - acc: 1.0000 - val_loss: 1.8889e-06 - val_acc: 1.0000\n",
      "Epoch 773/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.4305e-06 - acc: 1.0000 - val_loss: 1.8884e-06 - val_acc: 1.0000\n",
      "Epoch 774/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.0050e-06 - acc: 1.0000 - val_loss: 1.8841e-06 - val_acc: 1.0000\n",
      "Epoch 775/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.6026e-06 - acc: 1.0000 - val_loss: 1.8808e-06 - val_acc: 1.0000\n",
      "Epoch 776/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.1709e-06 - acc: 1.0000 - val_loss: 1.8981e-06 - val_acc: 1.0000\n",
      "Epoch 777/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.7884e-06 - acc: 1.0000 - val_loss: 1.8910e-06 - val_acc: 1.0000\n",
      "Epoch 778/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.0778e-06 - acc: 1.0000 - val_loss: 1.8764e-06 - val_acc: 1.0000\n",
      "Epoch 779/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.2902e-06 - acc: 1.0000 - val_loss: 1.8637e-06 - val_acc: 1.0000\n",
      "Epoch 780/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.0556e-06 - acc: 1.0000 - val_loss: 1.8480e-06 - val_acc: 1.0000\n",
      "Epoch 781/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.3901e-06 - acc: 1.0000 - val_loss: 1.8543e-06 - val_acc: 1.0000\n",
      "Epoch 782/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.7746e-06 - acc: 1.0000 - val_loss: 1.8475e-06 - val_acc: 1.0000\n",
      "Epoch 783/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.3797e-06 - acc: 1.0000 - val_loss: 1.8346e-06 - val_acc: 1.0000\n",
      "Epoch 784/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.1034e-06 - acc: 1.0000 - val_loss: 1.8138e-06 - val_acc: 1.0000\n",
      "Epoch 785/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.0677e-06 - acc: 1.0000 - val_loss: 1.8063e-06 - val_acc: 1.0000\n",
      "Epoch 786/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 3.4462e-06 - acc: 1.0000 - val_loss: 1.7980e-06 - val_acc: 1.0000\n",
      "Epoch 787/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.0575e-06 - acc: 1.0000 - val_loss: 1.7845e-06 - val_acc: 1.0000\n",
      "Epoch 788/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 3.1079e-06 - acc: 1.0000 - val_loss: 1.7905e-06 - val_acc: 1.0000\n",
      "Epoch 789/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.6794e-06 - acc: 1.0000 - val_loss: 1.7921e-06 - val_acc: 1.0000\n",
      "Epoch 790/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.0171e-06 - acc: 1.0000 - val_loss: 1.7683e-06 - val_acc: 1.0000\n",
      "Epoch 791/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.4149e-06 - acc: 1.0000 - val_loss: 1.7529e-06 - val_acc: 1.0000\n",
      "Epoch 792/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.0102e-06 - acc: 1.0000 - val_loss: 1.7239e-06 - val_acc: 1.0000\n",
      "Epoch 793/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.8114e-06 - acc: 1.0000 - val_loss: 1.7041e-06 - val_acc: 1.0000\n",
      "Epoch 794/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 2.9756e-06 - acc: 1.0000 - val_loss: 1.6880e-06 - val_acc: 1.0000\n",
      "Epoch 795/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.0539e-06 - acc: 1.0000 - val_loss: 1.6647e-06 - val_acc: 1.0000\n",
      "Epoch 796/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.3125e-06 - acc: 1.0000 - val_loss: 1.6490e-06 - val_acc: 1.0000\n",
      "Epoch 797/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.5654e-06 - acc: 1.0000 - val_loss: 1.6496e-06 - val_acc: 1.0000\n",
      "Epoch 798/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.5673e-06 - acc: 1.0000 - val_loss: 1.6464e-06 - val_acc: 1.0000\n",
      "Epoch 799/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 3.0503e-06 - acc: 1.0000 - val_loss: 1.6323e-06 - val_acc: 1.0000\n",
      "Epoch 800/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.5402e-06 - acc: 1.0000 - val_loss: 1.6243e-06 - val_acc: 1.0000\n",
      "Epoch 801/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 3.0883e-06 - acc: 1.0000 - val_loss: 1.6109e-06 - val_acc: 1.0000\n",
      "Epoch 802/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 2.9510e-06 - acc: 1.0000 - val_loss: 1.6000e-06 - val_acc: 1.0000\n",
      "Epoch 803/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 1.6680e-06 - acc: 1.000 - 0s 31us/step - loss: 2.8287e-06 - acc: 1.0000 - val_loss: 1.5938e-06 - val_acc: 1.0000\n",
      "Epoch 804/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 2.6742e-06 - acc: 1.0000 - val_loss: 1.5888e-06 - val_acc: 1.0000\n",
      "Epoch 805/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.7663e-06 - acc: 1.0000 - val_loss: 1.5844e-06 - val_acc: 1.0000\n",
      "Epoch 806/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.8547e-06 - acc: 1.0000 - val_loss: 1.5663e-06 - val_acc: 1.0000\n",
      "Epoch 807/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 3.0142e-06 - acc: 1.0000 - val_loss: 1.5437e-06 - val_acc: 1.0000\n",
      "Epoch 808/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.0048e-06 - acc: 1.0000 - val_loss: 1.5253e-06 - val_acc: 1.0000\n",
      "Epoch 809/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.5541e-06 - acc: 1.0000 - val_loss: 1.5203e-06 - val_acc: 1.0000\n",
      "Epoch 810/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.8049e-06 - acc: 1.0000 - val_loss: 1.5225e-06 - val_acc: 1.0000\n",
      "Epoch 811/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.4669e-06 - acc: 1.0000 - val_loss: 1.5525e-06 - val_acc: 1.0000\n",
      "Epoch 812/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.7150e-06 - acc: 1.0000 - val_loss: 1.5615e-06 - val_acc: 1.0000\n",
      "Epoch 813/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.1818e-06 - acc: 1.0000 - val_loss: 1.5344e-06 - val_acc: 1.0000\n",
      "Epoch 814/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 2.5376e-06 - acc: 1.0000 - val_loss: 1.5062e-06 - val_acc: 1.0000\n",
      "Epoch 815/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 2.8464e-06 - acc: 1.0000 - val_loss: 1.4976e-06 - val_acc: 1.0000\n",
      "Epoch 816/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.5780e-06 - acc: 1.0000 - val_loss: 1.4937e-06 - val_acc: 1.0000\n",
      "Epoch 817/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.2145e-06 - acc: 1.0000 - val_loss: 1.4818e-06 - val_acc: 1.0000\n",
      "Epoch 818/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.4540e-06 - acc: 1.0000 - val_loss: 1.4698e-06 - val_acc: 1.0000\n",
      "Epoch 819/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.3362e-06 - acc: 1.0000 - val_loss: 1.4618e-06 - val_acc: 1.0000\n",
      "Epoch 820/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.3499e-06 - acc: 1.0000 - val_loss: 1.4535e-06 - val_acc: 1.0000\n",
      "Epoch 821/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3172e-06 - acc: 1.0000 - val_loss: 1.4488e-06 - val_acc: 1.0000\n",
      "Epoch 822/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.7610e-06 - acc: 1.0000 - val_loss: 1.4507e-06 - val_acc: 1.0000\n",
      "Epoch 823/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.5524e-06 - acc: 1.0000 - val_loss: 1.4610e-06 - val_acc: 1.0000\n",
      "Epoch 824/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.8028e-06 - acc: 1.0000 - val_loss: 1.4389e-06 - val_acc: 1.0000\n",
      "Epoch 825/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.3595e-06 - acc: 1.0000 - val_loss: 1.4203e-06 - val_acc: 1.0000\n",
      "Epoch 826/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2524e-06 - acc: 1.0000 - val_loss: 1.4070e-06 - val_acc: 1.0000\n",
      "Epoch 827/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 2.3914e-06 - acc: 1.0000 - val_loss: 1.3958e-06 - val_acc: 1.0000\n",
      "Epoch 828/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.5187e-06 - acc: 1.0000 - val_loss: 1.3842e-06 - val_acc: 1.0000\n",
      "Epoch 829/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.5511e-06 - acc: 1.0000 - val_loss: 1.3846e-06 - val_acc: 1.0000\n",
      "Epoch 830/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.5187e-06 - acc: 1.0000 - val_loss: 1.3886e-06 - val_acc: 1.0000\n",
      "Epoch 831/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.4551e-06 - acc: 1.0000 - val_loss: 1.3845e-06 - val_acc: 1.0000\n",
      "Epoch 832/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3545e-06 - acc: 1.0000 - val_loss: 1.3823e-06 - val_acc: 1.0000\n",
      "Epoch 833/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.3427e-06 - acc: 1.0000 - val_loss: 1.3728e-06 - val_acc: 1.0000\n",
      "Epoch 834/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.1237e-06 - acc: 1.0000 - val_loss: 1.3660e-06 - val_acc: 1.0000\n",
      "Epoch 835/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.1076e-06 - acc: 1.0000 - val_loss: 1.3536e-06 - val_acc: 1.0000\n",
      "Epoch 836/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2776e-06 - acc: 1.0000 - val_loss: 1.3395e-06 - val_acc: 1.0000\n",
      "Epoch 837/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.4298e-06 - acc: 1.0000 - val_loss: 1.3200e-06 - val_acc: 1.0000\n",
      "Epoch 838/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.0009e-06 - acc: 1.0000 - val_loss: 1.3106e-06 - val_acc: 1.0000\n",
      "Epoch 839/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.9389e-06 - acc: 1.0000 - val_loss: 1.2946e-06 - val_acc: 1.0000\n",
      "Epoch 840/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.2338e-06 - acc: 1.0000 - val_loss: 1.2879e-06 - val_acc: 1.0000\n",
      "Epoch 841/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.2576e-06 - acc: 1.0000 - val_loss: 1.2792e-06 - val_acc: 1.0000\n",
      "Epoch 842/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.0125e-06 - acc: 1.0000 - val_loss: 1.2738e-06 - val_acc: 1.0000\n",
      "Epoch 843/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.5352e-06 - acc: 1.0000 - val_loss: 1.2736e-06 - val_acc: 1.0000\n",
      "Epoch 844/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.0992e-06 - acc: 1.0000 - val_loss: 1.2732e-06 - val_acc: 1.0000\n",
      "Epoch 845/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.0175e-06 - acc: 1.0000 - val_loss: 1.2774e-06 - val_acc: 1.0000\n",
      "Epoch 846/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.5006e-06 - acc: 1.0000 - val_loss: 1.2666e-06 - val_acc: 1.0000\n",
      "Epoch 847/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.2505e-06 - acc: 1.0000 - val_loss: 1.2570e-06 - val_acc: 1.0000\n",
      "Epoch 848/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 2.0999e-06 - acc: 1.0000 - val_loss: 1.2384e-06 - val_acc: 1.0000\n",
      "Epoch 849/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.1100e-06 - acc: 1.0000 - val_loss: 1.2304e-06 - val_acc: 1.0000\n",
      "Epoch 850/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0680e-06 - acc: 1.0000 - val_loss: 1.2146e-06 - val_acc: 1.0000\n",
      "Epoch 851/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.2130e-06 - acc: 1.0000 - val_loss: 1.2125e-06 - val_acc: 1.0000\n",
      "Epoch 852/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.8573e-06 - acc: 1.0000 - val_loss: 1.2142e-06 - val_acc: 1.0000\n",
      "Epoch 853/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.2664e-06 - acc: 1.0000 - val_loss: 1.2056e-06 - val_acc: 1.0000\n",
      "Epoch 854/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.8447e-06 - acc: 1.0000 - val_loss: 1.2041e-06 - val_acc: 1.0000\n",
      "Epoch 855/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.9653e-06 - acc: 1.0000 - val_loss: 1.1948e-06 - val_acc: 1.0000\n",
      "Epoch 856/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.9734e-06 - acc: 1.0000 - val_loss: 1.1870e-06 - val_acc: 1.0000\n",
      "Epoch 857/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.8654e-06 - acc: 1.0000 - val_loss: 1.1802e-06 - val_acc: 1.0000\n",
      "Epoch 858/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 2.1270e-06 - acc: 1.0000 - val_loss: 1.1717e-06 - val_acc: 1.0000\n",
      "Epoch 859/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.8957e-06 - acc: 1.0000 - val_loss: 1.1559e-06 - val_acc: 1.0000\n",
      "Epoch 860/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.8067e-06 - acc: 1.0000 - val_loss: 1.1475e-06 - val_acc: 1.0000\n",
      "Epoch 861/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.0072e-06 - acc: 1.0000 - val_loss: 1.1414e-06 - val_acc: 1.0000\n",
      "Epoch 862/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.0791e-06 - acc: 1.0000 - val_loss: 1.1364e-06 - val_acc: 1.0000\n",
      "Epoch 863/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.8976e-06 - acc: 1.0000 - val_loss: 1.1265e-06 - val_acc: 1.0000\n",
      "Epoch 864/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9858e-06 - acc: 1.0000 - val_loss: 1.1182e-06 - val_acc: 1.0000\n",
      "Epoch 865/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 2.0752e-06 - acc: 1.0000 - val_loss: 1.1152e-06 - val_acc: 1.0000\n",
      "Epoch 866/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 2.1159e-06 - acc: 1.0000 - val_loss: 1.1070e-06 - val_acc: 1.0000\n",
      "Epoch 867/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1389e-06 - acc: 1.0000 - val_loss: 1.0990e-06 - val_acc: 1.0000\n",
      "Epoch 868/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 1.3526e-06 - acc: 1.000 - 0s 27us/step - loss: 1.8701e-06 - acc: 1.0000 - val_loss: 1.0995e-06 - val_acc: 1.0000\n",
      "Epoch 869/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.9768e-06 - acc: 1.0000 - val_loss: 1.0926e-06 - val_acc: 1.0000\n",
      "Epoch 870/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.6749e-06 - acc: 1.0000 - val_loss: 1.0856e-06 - val_acc: 1.0000\n",
      "Epoch 871/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.9198e-06 - acc: 1.0000 - val_loss: 1.0809e-06 - val_acc: 1.0000\n",
      "Epoch 872/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.9344e-06 - acc: 1.0000 - val_loss: 1.0806e-06 - val_acc: 1.0000\n",
      "Epoch 873/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.8547e-06 - acc: 1.0000 - val_loss: 1.0796e-06 - val_acc: 1.0000\n",
      "Epoch 874/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.8491e-06 - acc: 1.0000 - val_loss: 1.0794e-06 - val_acc: 1.0000\n",
      "Epoch 875/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7927e-06 - acc: 1.0000 - val_loss: 1.0767e-06 - val_acc: 1.0000\n",
      "Epoch 876/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.9148e-06 - acc: 1.0000 - val_loss: 1.0618e-06 - val_acc: 1.0000\n",
      "Epoch 877/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5951e-06 - acc: 1.0000 - val_loss: 1.0505e-06 - val_acc: 1.0000\n",
      "Epoch 878/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.9864e-06 - acc: 1.0000 - val_loss: 1.0499e-06 - val_acc: 1.0000\n",
      "Epoch 879/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.0652e-06 - acc: 1.0000 - val_loss: 1.0460e-06 - val_acc: 1.0000\n",
      "Epoch 880/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.0051e-06 - acc: 1.0000 - val_loss: 1.0296e-06 - val_acc: 1.0000\n",
      "Epoch 881/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.7107e-06 - acc: 1.0000 - val_loss: 1.0217e-06 - val_acc: 1.0000\n",
      "Epoch 882/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.0306e-06 - acc: 1.0000 - val_loss: 1.0196e-06 - val_acc: 1.0000\n",
      "Epoch 883/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.9794e-06 - acc: 1.0000 - val_loss: 1.0082e-06 - val_acc: 1.0000\n",
      "Epoch 884/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.6633e-06 - acc: 1.0000 - val_loss: 9.9619e-07 - val_acc: 1.0000\n",
      "Epoch 885/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.6491e-06 - acc: 1.0000 - val_loss: 9.8790e-07 - val_acc: 1.0000\n",
      "Epoch 886/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.9376e-06 - acc: 1.0000 - val_loss: 9.8218e-07 - val_acc: 1.0000\n",
      "Epoch 887/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.5880e-06 - acc: 1.0000 - val_loss: 9.7724e-07 - val_acc: 1.0000\n",
      "Epoch 888/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.6085e-06 - acc: 1.0000 - val_loss: 9.7544e-07 - val_acc: 1.0000\n",
      "Epoch 889/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.7032e-06 - acc: 1.0000 - val_loss: 9.7479e-07 - val_acc: 1.0000\n",
      "Epoch 890/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.9528e-06 - acc: 1.0000 - val_loss: 9.7103e-07 - val_acc: 1.0000\n",
      "Epoch 891/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5902e-06 - acc: 1.0000 - val_loss: 9.6471e-07 - val_acc: 1.0000\n",
      "Epoch 892/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.8228e-06 - acc: 1.0000 - val_loss: 9.6164e-07 - val_acc: 1.0000\n",
      "Epoch 893/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.9073e-06 - acc: 1.0000 - val_loss: 9.5026e-07 - val_acc: 1.0000\n",
      "Epoch 894/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.8063e-06 - acc: 1.0000 - val_loss: 9.4320e-07 - val_acc: 1.0000\n",
      "Epoch 895/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6278e-06 - acc: 1.0000 - val_loss: 9.4233e-07 - val_acc: 1.0000\n",
      "Epoch 896/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.5994e-06 - acc: 1.0000 - val_loss: 9.3730e-07 - val_acc: 1.0000\n",
      "Epoch 897/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.4331e-06 - acc: 1.0000 - val_loss: 9.3466e-07 - val_acc: 1.0000\n",
      "Epoch 898/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.6357e-06 - acc: 1.0000 - val_loss: 9.3268e-07 - val_acc: 1.0000\n",
      "Epoch 899/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.0920e-06 - acc: 1.0000 - val_loss: 9.2569e-07 - val_acc: 1.0000\n",
      "Epoch 900/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 2.0264e-06 - acc: 1.0000 - val_loss: 9.1642e-07 - val_acc: 1.0000\n",
      "Epoch 901/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.6696e-06 - acc: 1.0000 - val_loss: 9.1096e-07 - val_acc: 1.0000\n",
      "Epoch 902/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4344e-06 - acc: 1.0000 - val_loss: 9.0741e-07 - val_acc: 1.0000\n",
      "Epoch 903/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.6509e-06 - acc: 1.0000 - val_loss: 9.0262e-07 - val_acc: 1.0000\n",
      "Epoch 904/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5620e-06 - acc: 1.0000 - val_loss: 8.9745e-07 - val_acc: 1.0000\n",
      "Epoch 905/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.5271e-06 - acc: 1.0000 - val_loss: 8.8797e-07 - val_acc: 1.0000\n",
      "Epoch 906/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.5714e-06 - acc: 1.0000 - val_loss: 8.7754e-07 - val_acc: 1.0000\n",
      "Epoch 907/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.3723e-06 - acc: 1.0000 - val_loss: 8.7330e-07 - val_acc: 1.0000\n",
      "Epoch 908/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5424e-06 - acc: 1.0000 - val_loss: 8.7362e-07 - val_acc: 1.0000\n",
      "Epoch 909/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.8028e-06 - acc: 1.0000 - val_loss: 8.7251e-07 - val_acc: 1.0000\n",
      "Epoch 910/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3444e-06 - acc: 1.0000 - val_loss: 8.7028e-07 - val_acc: 1.0000\n",
      "Epoch 911/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.5959e-06 - acc: 1.0000 - val_loss: 8.6761e-07 - val_acc: 1.0000\n",
      "Epoch 912/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3626e-06 - acc: 1.0000 - val_loss: 8.6579e-07 - val_acc: 1.0000\n",
      "Epoch 913/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.8155e-06 - acc: 1.0000 - val_loss: 8.7183e-07 - val_acc: 1.0000\n",
      "Epoch 914/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3701e-06 - acc: 1.0000 - val_loss: 8.7380e-07 - val_acc: 1.0000\n",
      "Epoch 915/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.6563e-06 - acc: 1.0000 - val_loss: 8.6307e-07 - val_acc: 1.0000\n",
      "Epoch 916/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4986e-06 - acc: 1.0000 - val_loss: 8.5607e-07 - val_acc: 1.0000\n",
      "Epoch 917/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4772e-06 - acc: 1.0000 - val_loss: 8.4982e-07 - val_acc: 1.0000\n",
      "Epoch 918/10000\n",
      "1139/1139 [==============================] - 0s 50us/step - loss: 1.2638e-06 - acc: 1.0000 - val_loss: 8.3673e-07 - val_acc: 1.0000\n",
      "Epoch 919/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4331e-06 - acc: 1.0000 - val_loss: 8.2654e-07 - val_acc: 1.0000\n",
      "Epoch 920/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3179e-06 - acc: 1.0000 - val_loss: 8.2416e-07 - val_acc: 1.0000\n",
      "Epoch 921/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3873e-06 - acc: 1.0000 - val_loss: 8.2198e-07 - val_acc: 1.0000\n",
      "Epoch 922/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5063e-06 - acc: 1.0000 - val_loss: 8.0959e-07 - val_acc: 1.0000\n",
      "Epoch 923/10000\n",
      "1139/1139 [==============================] - 0s 16us/step - loss: 1.5574e-06 - acc: 1.0000 - val_loss: 8.0458e-07 - val_acc: 1.0000\n",
      "Epoch 924/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 1.5301e-06 - acc: 1.0000 - val_loss: 8.0201e-07 - val_acc: 1.0000\n",
      "Epoch 925/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4970e-06 - acc: 1.0000 - val_loss: 7.9867e-07 - val_acc: 1.0000\n",
      "Epoch 926/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.4260e-06 - acc: 1.0000 - val_loss: 7.9539e-07 - val_acc: 1.0000\n",
      "Epoch 927/10000\n",
      "1139/1139 [==============================] - 0s 20us/step - loss: 1.1344e-06 - acc: 1.0000 - val_loss: 7.9716e-07 - val_acc: 1.0000\n",
      "Epoch 928/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3457e-06 - acc: 1.0000 - val_loss: 7.9616e-07 - val_acc: 1.0000\n",
      "Epoch 929/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.4573e-06 - acc: 1.0000 - val_loss: 7.9128e-07 - val_acc: 1.0000\n",
      "Epoch 930/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3116e-06 - acc: 1.0000 - val_loss: 7.8362e-07 - val_acc: 1.0000\n",
      "Epoch 931/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.7624e-06 - acc: 1.0000 - val_loss: 7.7701e-07 - val_acc: 1.0000\n",
      "Epoch 932/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 1.4909e-06 - acc: 1.0000 - val_loss: 7.7518e-07 - val_acc: 1.0000\n",
      "Epoch 933/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6082e-06 - acc: 1.0000 - val_loss: 7.8056e-07 - val_acc: 1.0000\n",
      "Epoch 934/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2693e-06 - acc: 1.0000 - val_loss: 7.8224e-07 - val_acc: 1.0000\n",
      "Epoch 935/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4278e-06 - acc: 1.0000 - val_loss: 7.8136e-07 - val_acc: 1.0000\n",
      "Epoch 936/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.1210e-06 - acc: 1.0000 - val_loss: 7.7374e-07 - val_acc: 1.0000\n",
      "Epoch 937/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1492e-06 - acc: 1.0000 - val_loss: 7.7068e-07 - val_acc: 1.0000\n",
      "Epoch 938/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4218e-06 - acc: 1.0000 - val_loss: 7.5853e-07 - val_acc: 1.0000\n",
      "Epoch 939/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.5304e-06 - acc: 1.0000 - val_loss: 7.4954e-07 - val_acc: 1.0000\n",
      "Epoch 940/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.1803e-06 - acc: 1.0000 - val_loss: 7.3835e-07 - val_acc: 1.0000\n",
      "Epoch 941/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 24us/step - loss: 1.5979e-06 - acc: 1.0000 - val_loss: 7.3146e-07 - val_acc: 1.0000\n",
      "Epoch 942/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3409e-06 - acc: 1.0000 - val_loss: 7.2861e-07 - val_acc: 1.0000\n",
      "Epoch 943/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3437e-06 - acc: 1.0000 - val_loss: 7.2761e-07 - val_acc: 1.0000\n",
      "Epoch 944/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.4614e-06 - acc: 1.0000 - val_loss: 7.2328e-07 - val_acc: 1.0000\n",
      "Epoch 945/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.2438e-06 - acc: 1.0000 - val_loss: 7.2350e-07 - val_acc: 1.0000\n",
      "Epoch 946/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 1.4785e-06 - acc: 1.0000 - val_loss: 7.1845e-07 - val_acc: 1.0000\n",
      "Epoch 947/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3042e-06 - acc: 1.0000 - val_loss: 7.1579e-07 - val_acc: 1.0000\n",
      "Epoch 948/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.2444e-06 - acc: 1.0000 - val_loss: 7.0997e-07 - val_acc: 1.0000\n",
      "Epoch 949/10000\n",
      "1139/1139 [==============================] - 0s 45us/step - loss: 1.3508e-06 - acc: 1.0000 - val_loss: 7.0371e-07 - val_acc: 1.0000\n",
      "Epoch 950/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1482e-06 - acc: 1.0000 - val_loss: 7.0148e-07 - val_acc: 1.0000\n",
      "Epoch 951/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.1572e-06 - acc: 1.0000 - val_loss: 6.9882e-07 - val_acc: 1.0000\n",
      "Epoch 952/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1195e-06 - acc: 1.0000 - val_loss: 6.9720e-07 - val_acc: 1.0000\n",
      "Epoch 953/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.3037e-06 - acc: 1.0000 - val_loss: 6.9388e-07 - val_acc: 1.0000\n",
      "Epoch 954/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.5374e-06 - acc: 1.0000 - val_loss: 6.9591e-07 - val_acc: 1.0000\n",
      "Epoch 955/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.8647e-07 - acc: 1.0000 - val_loss: 6.9943e-07 - val_acc: 1.0000\n",
      "Epoch 956/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.2081e-06 - acc: 1.0000 - val_loss: 6.9550e-07 - val_acc: 1.0000\n",
      "Epoch 957/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.2355e-06 - acc: 1.0000 - val_loss: 6.8789e-07 - val_acc: 1.0000\n",
      "Epoch 958/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3338e-06 - acc: 1.0000 - val_loss: 6.7813e-07 - val_acc: 1.0000\n",
      "Epoch 959/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.6382e-06 - acc: 1.0000 - val_loss: 6.6981e-07 - val_acc: 1.0000\n",
      "Epoch 960/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 1.4839e-06 - acc: 1.0000 - val_loss: 6.6346e-07 - val_acc: 1.0000\n",
      "Epoch 961/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.1953e-06 - acc: 1.0000 - val_loss: 6.4728e-07 - val_acc: 1.0000\n",
      "Epoch 962/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.1218e-06 - acc: 1.0000 - val_loss: 6.4225e-07 - val_acc: 1.0000\n",
      "Epoch 963/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1389e-06 - acc: 1.0000 - val_loss: 6.4222e-07 - val_acc: 1.0000\n",
      "Epoch 964/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.4327e-06 - acc: 1.0000 - val_loss: 6.5033e-07 - val_acc: 1.0000\n",
      "Epoch 965/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 1.1501e-06 - acc: 1.0000 - val_loss: 6.5052e-07 - val_acc: 1.0000\n",
      "Epoch 966/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1230e-06 - acc: 1.0000 - val_loss: 6.4970e-07 - val_acc: 1.0000\n",
      "Epoch 967/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.1097e-06 - acc: 1.0000 - val_loss: 6.4490e-07 - val_acc: 1.0000\n",
      "Epoch 968/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2735e-06 - acc: 1.0000 - val_loss: 6.3847e-07 - val_acc: 1.0000\n",
      "Epoch 969/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3884e-06 - acc: 1.0000 - val_loss: 6.3490e-07 - val_acc: 1.0000\n",
      "Epoch 970/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2496e-06 - acc: 1.0000 - val_loss: 6.2955e-07 - val_acc: 1.0000\n",
      "Epoch 971/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 1.2407e-06 - acc: 1.0000 - val_loss: 6.2685e-07 - val_acc: 1.0000\n",
      "Epoch 972/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.1492e-06 - acc: 1.0000 - val_loss: 6.2018e-07 - val_acc: 1.0000\n",
      "Epoch 973/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.2716e-06 - acc: 1.0000 - val_loss: 6.1101e-07 - val_acc: 1.0000\n",
      "Epoch 974/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1912e-06 - acc: 1.0000 - val_loss: 6.0676e-07 - val_acc: 1.0000\n",
      "Epoch 975/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1129e-06 - acc: 1.0000 - val_loss: 6.0324e-07 - val_acc: 1.0000\n",
      "Epoch 976/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.0891e-06 - acc: 1.0000 - val_loss: 6.0043e-07 - val_acc: 1.0000\n",
      "Epoch 977/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3649e-06 - acc: 1.0000 - val_loss: 5.9674e-07 - val_acc: 1.0000\n",
      "Epoch 978/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.0688e-06 - acc: 1.0000 - val_loss: 5.9429e-07 - val_acc: 1.0000\n",
      "Epoch 979/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1931e-06 - acc: 1.0000 - val_loss: 5.9564e-07 - val_acc: 1.0000\n",
      "Epoch 980/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.0500e-06 - acc: 1.0000 - val_loss: 5.9287e-07 - val_acc: 1.0000\n",
      "Epoch 981/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1203e-06 - acc: 1.0000 - val_loss: 5.8980e-07 - val_acc: 1.0000\n",
      "Epoch 982/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.2840e-06 - acc: 1.0000 - val_loss: 5.8790e-07 - val_acc: 1.0000\n",
      "Epoch 983/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.1555e-06 - acc: 1.0000 - val_loss: 5.7967e-07 - val_acc: 1.0000\n",
      "Epoch 984/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.0709e-06 - acc: 1.0000 - val_loss: 5.7811e-07 - val_acc: 1.0000\n",
      "Epoch 985/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3285e-06 - acc: 1.0000 - val_loss: 5.7811e-07 - val_acc: 1.0000\n",
      "Epoch 986/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.1144e-06 - acc: 1.0000 - val_loss: 5.7856e-07 - val_acc: 1.0000\n",
      "Epoch 987/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 9.8848e-07 - acc: 1.0000 - val_loss: 5.7582e-07 - val_acc: 1.0000\n",
      "Epoch 988/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3783e-06 - acc: 1.0000 - val_loss: 5.6780e-07 - val_acc: 1.0000\n",
      "Epoch 989/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 1.3717e-06 - acc: 1.0000 - val_loss: 5.6052e-07 - val_acc: 1.0000\n",
      "Epoch 990/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1438e-06 - acc: 1.0000 - val_loss: 5.7070e-07 - val_acc: 1.0000\n",
      "Epoch 991/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 9.9838e-07 - acc: 1.0000 - val_loss: 5.7095e-07 - val_acc: 1.0000\n",
      "Epoch 992/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.0717e-07 - acc: 1.0000 - val_loss: 5.6274e-07 - val_acc: 1.0000\n",
      "Epoch 993/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 1.0507e-06 - acc: 1.0000 - val_loss: 5.6093e-07 - val_acc: 1.0000\n",
      "Epoch 994/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 1.1475e-06 - acc: 1.0000 - val_loss: 5.6579e-07 - val_acc: 1.0000\n",
      "Epoch 995/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.1369e-06 - acc: 1.0000 - val_loss: 5.6802e-07 - val_acc: 1.0000\n",
      "Epoch 996/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.4609e-07 - acc: 1.0000 - val_loss: 5.5426e-07 - val_acc: 1.0000\n",
      "Epoch 997/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.0293e-06 - acc: 1.0000 - val_loss: 5.4782e-07 - val_acc: 1.0000\n",
      "Epoch 998/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 1.0816e-06 - acc: 1.0000 - val_loss: 5.4237e-07 - val_acc: 1.0000\n",
      "Epoch 999/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.1309e-06 - acc: 1.0000 - val_loss: 5.3703e-07 - val_acc: 1.0000\n",
      "Epoch 1000/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 1.0121e-06 - acc: 1.0000 - val_loss: 5.3511e-07 - val_acc: 1.0000\n",
      "Epoch 1001/10000\n",
      "1139/1139 [==============================] - 0s 19us/step - loss: 1.0909e-06 - acc: 1.0000 - val_loss: 5.3249e-07 - val_acc: 1.0000\n",
      "Epoch 1002/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.2688e-07 - acc: 1.0000 - val_loss: 5.2932e-07 - val_acc: 1.0000\n",
      "Epoch 1003/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 9.4673e-07 - acc: 1.0000 - val_loss: 5.2774e-07 - val_acc: 1.0000\n",
      "Epoch 1004/10000\n",
      "1139/1139 [==============================] - 0s 20us/step - loss: 9.0640e-07 - acc: 1.0000 - val_loss: 5.2477e-07 - val_acc: 1.0000\n",
      "Epoch 1005/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.1115e-06 - acc: 1.0000 - val_loss: 5.2415e-07 - val_acc: 1.0000\n",
      "Epoch 1006/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.3335e-07 - acc: 1.0000 - val_loss: 5.1910e-07 - val_acc: 1.0000\n",
      "Epoch 1007/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.1904e-07 - acc: 1.0000 - val_loss: 5.1334e-07 - val_acc: 1.0000\n",
      "Epoch 1008/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 9.9979e-07 - acc: 1.0000 - val_loss: 5.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1009/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.0688e-06 - acc: 1.0000 - val_loss: 5.0731e-07 - val_acc: 1.0000\n",
      "Epoch 1010/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 8.4985e-07 - acc: 1.0000 - val_loss: 5.0061e-07 - val_acc: 1.0000\n",
      "Epoch 1011/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.3469e-07 - acc: 1.0000 - val_loss: 5.0339e-07 - val_acc: 1.0000\n",
      "Epoch 1012/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.8431e-07 - acc: 1.0000 - val_loss: 5.0290e-07 - val_acc: 1.0000\n",
      "Epoch 1013/10000\n",
      "1139/1139 [==============================] - 0s 15us/step - loss: 9.3729e-07 - acc: 1.0000 - val_loss: 5.0185e-07 - val_acc: 1.0000\n",
      "Epoch 1014/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 1.0008e-06 - acc: 1.0000 - val_loss: 4.9768e-07 - val_acc: 1.0000\n",
      "Epoch 1015/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 9.7670e-07 - acc: 1.0000 - val_loss: 4.9910e-07 - val_acc: 1.0000\n",
      "Epoch 1016/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.6634e-07 - acc: 1.0000 - val_loss: 4.9682e-07 - val_acc: 1.0000\n",
      "Epoch 1017/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.7779e-07 - acc: 1.0000 - val_loss: 4.9407e-07 - val_acc: 1.0000\n",
      "Epoch 1018/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 8.9713e-07 - acc: 1.0000 - val_loss: 4.8407e-07 - val_acc: 1.0000\n",
      "Epoch 1019/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.0793e-06 - acc: 1.0000 - val_loss: 4.8241e-07 - val_acc: 1.0000\n",
      "Epoch 1020/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.2767e-07 - acc: 1.0000 - val_loss: 4.7855e-07 - val_acc: 1.0000\n",
      "Epoch 1021/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.9502e-07 - acc: 1.0000 - val_loss: 4.7633e-07 - val_acc: 1.0000\n",
      "Epoch 1022/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.7025e-07 - acc: 1.0000 - val_loss: 4.7502e-07 - val_acc: 1.0000\n",
      "Epoch 1023/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.7272e-07 - acc: 1.0000 - val_loss: 4.7491e-07 - val_acc: 1.0000\n",
      "Epoch 1024/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 8.4801e-07 - acc: 1.0000 - val_loss: 4.7219e-07 - val_acc: 1.0000\n",
      "Epoch 1025/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.5959e-07 - acc: 1.0000 - val_loss: 4.6679e-07 - val_acc: 1.0000\n",
      "Epoch 1026/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 8.0144e-07 - acc: 1.0000 - val_loss: 4.6521e-07 - val_acc: 1.0000\n",
      "Epoch 1027/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 8.1496e-07 - acc: 1.0000 - val_loss: 4.6272e-07 - val_acc: 1.0000\n",
      "Epoch 1028/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.8106e-07 - acc: 1.0000 - val_loss: 4.6176e-07 - val_acc: 1.0000\n",
      "Epoch 1029/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 8.0785e-07 - acc: 1.0000 - val_loss: 4.5474e-07 - val_acc: 1.0000\n",
      "Epoch 1030/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 9.7442e-07 - acc: 1.0000 - val_loss: 4.5110e-07 - val_acc: 1.0000\n",
      "Epoch 1031/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 9.5290e-07 - acc: 1.0000 - val_loss: 4.4792e-07 - val_acc: 1.0000\n",
      "Epoch 1032/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 7.9728e-07 - acc: 1.0000 - val_loss: 4.4658e-07 - val_acc: 1.0000\n",
      "Epoch 1033/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 8.6376e-07 - acc: 1.0000 - val_loss: 4.4479e-07 - val_acc: 1.0000\n",
      "Epoch 1034/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 8.0010e-07 - acc: 1.0000 - val_loss: 4.4261e-07 - val_acc: 1.0000\n",
      "Epoch 1035/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 8.0812e-07 - acc: 1.0000 - val_loss: 4.4147e-07 - val_acc: 1.0000\n",
      "Epoch 1036/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 9.1169e-07 - acc: 1.0000 - val_loss: 4.3866e-07 - val_acc: 1.0000\n",
      "Epoch 1037/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 8.7507e-07 - acc: 1.0000 - val_loss: 4.4120e-07 - val_acc: 1.0000\n",
      "Epoch 1038/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 9.2781e-07 - acc: 1.0000 - val_loss: 4.4005e-07 - val_acc: 1.0000\n",
      "Epoch 1039/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.9131e-07 - acc: 1.0000 - val_loss: 4.4000e-07 - val_acc: 1.0000\n",
      "Epoch 1040/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 7.9782e-07 - acc: 1.0000 - val_loss: 4.3743e-07 - val_acc: 1.0000\n",
      "Epoch 1041/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 7.4422e-07 - acc: 1.0000 - val_loss: 4.3195e-07 - val_acc: 1.0000\n",
      "Epoch 1042/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 7.7078e-07 - acc: 1.0000 - val_loss: 4.2832e-07 - val_acc: 1.0000\n",
      "Epoch 1043/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.3976e-07 - acc: 1.0000 - val_loss: 4.2631e-07 - val_acc: 1.0000\n",
      "Epoch 1044/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.5555e-07 - acc: 1.0000 - val_loss: 4.2730e-07 - val_acc: 1.0000\n",
      "Epoch 1045/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.7981e-07 - acc: 1.0000 - val_loss: 4.2338e-07 - val_acc: 1.0000\n",
      "Epoch 1046/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 7.0495e-07 - acc: 1.0000 - val_loss: 4.2149e-07 - val_acc: 1.0000\n",
      "Epoch 1047/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 6.0541e-07 - acc: 1.0000 - val_loss: 4.2164e-07 - val_acc: 1.0000\n",
      "Epoch 1048/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 8.3181e-07 - acc: 1.0000 - val_loss: 4.1920e-07 - val_acc: 1.0000\n",
      "Epoch 1049/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 7.6224e-07 - acc: 1.0000 - val_loss: 4.1771e-07 - val_acc: 1.0000\n",
      "Epoch 1050/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.8730e-07 - acc: 1.0000 - val_loss: 4.1562e-07 - val_acc: 1.0000\n",
      "Epoch 1051/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 20us/step - loss: 6.4467e-07 - acc: 1.0000 - val_loss: 4.1127e-07 - val_acc: 1.0000\n",
      "Epoch 1052/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 7.9009e-07 - acc: 1.0000 - val_loss: 4.0435e-07 - val_acc: 1.0000\n",
      "Epoch 1053/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 7.0557e-07 - acc: 1.0000 - val_loss: 4.0290e-07 - val_acc: 1.0000\n",
      "Epoch 1054/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 7.2781e-07 - acc: 1.0000 - val_loss: 3.9627e-07 - val_acc: 1.0000\n",
      "Epoch 1055/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 7.5110e-07 - acc: 1.0000 - val_loss: 3.9545e-07 - val_acc: 1.0000\n",
      "Epoch 1056/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 6.3280e-07 - acc: 1.0000 - val_loss: 3.9522e-07 - val_acc: 1.0000\n",
      "Epoch 1057/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 7.1742e-07 - acc: 1.0000 - val_loss: 3.9362e-07 - val_acc: 1.0000\n",
      "Epoch 1058/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 8.4218e-07 - acc: 1.0000 - val_loss: 3.9247e-07 - val_acc: 1.0000\n",
      "Epoch 1059/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.1392e-07 - acc: 1.0000 - val_loss: 3.8831e-07 - val_acc: 1.0000\n",
      "Epoch 1060/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 6.1879e-07 - acc: 1.0000 - val_loss: 3.8658e-07 - val_acc: 1.0000\n",
      "Epoch 1061/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.1882e-07 - acc: 1.0000 - val_loss: 3.8531e-07 - val_acc: 1.0000\n",
      "Epoch 1062/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.8663e-07 - acc: 1.0000 - val_loss: 3.8465e-07 - val_acc: 1.0000\n",
      "Epoch 1063/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.7786e-07 - acc: 1.0000 - val_loss: 3.8423e-07 - val_acc: 1.0000\n",
      "Epoch 1064/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 6.6534e-07 - acc: 1.0000 - val_loss: 3.8613e-07 - val_acc: 1.0000\n",
      "Epoch 1065/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 8.5305e-07 - acc: 1.0000 - val_loss: 3.9011e-07 - val_acc: 1.0000\n",
      "Epoch 1066/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.5497e-07 - acc: 1.0000 - val_loss: 3.8847e-07 - val_acc: 1.0000\n",
      "Epoch 1067/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.0188e-07 - acc: 1.0000 - val_loss: 3.8396e-07 - val_acc: 1.0000\n",
      "Epoch 1068/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 6.5507e-07 - acc: 1.0000 - val_loss: 3.8085e-07 - val_acc: 1.0000\n",
      "Epoch 1069/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 9.3464e-07 - acc: 1.0000 - val_loss: 3.8467e-07 - val_acc: 1.0000\n",
      "Epoch 1070/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 8.0671e-07 - acc: 1.0000 - val_loss: 3.8774e-07 - val_acc: 1.0000\n",
      "Epoch 1071/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 5.7440e-07 - acc: 1.0000 - val_loss: 3.8197e-07 - val_acc: 1.0000\n",
      "Epoch 1072/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.4455e-07 - acc: 1.0000 - val_loss: 3.7506e-07 - val_acc: 1.0000\n",
      "Epoch 1073/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.0352e-07 - acc: 1.0000 - val_loss: 3.7360e-07 - val_acc: 1.0000\n",
      "Epoch 1074/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 6.7951e-07 - acc: 1.0000 - val_loss: 3.7053e-07 - val_acc: 1.0000\n",
      "Epoch 1075/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.5596e-07 - acc: 1.0000 - val_loss: 3.6898e-07 - val_acc: 1.0000\n",
      "Epoch 1076/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 7.1280e-07 - acc: 1.0000 - val_loss: 3.6447e-07 - val_acc: 1.0000\n",
      "Epoch 1077/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.9699e-07 - acc: 1.0000 - val_loss: 3.6112e-07 - val_acc: 1.0000\n",
      "Epoch 1078/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.6394e-07 - acc: 1.0000 - val_loss: 3.5925e-07 - val_acc: 1.0000\n",
      "Epoch 1079/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 7.9409e-07 - acc: 1.0000 - val_loss: 3.5632e-07 - val_acc: 1.0000\n",
      "Epoch 1080/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 5.9183e-07 - acc: 1.0000 - val_loss: 3.6540e-07 - val_acc: 1.0000\n",
      "Epoch 1081/10000\n",
      "1139/1139 [==============================] - 0s 23us/step - loss: 7.8026e-07 - acc: 1.0000 - val_loss: 3.5986e-07 - val_acc: 1.0000\n",
      "Epoch 1082/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 8.1924e-07 - acc: 1.0000 - val_loss: 3.5449e-07 - val_acc: 1.0000\n",
      "Epoch 1083/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 6.0857e-07 - acc: 1.0000 - val_loss: 3.5167e-07 - val_acc: 1.0000\n",
      "Epoch 1084/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 5.4167e-07 - acc: 1.0000 - val_loss: 3.4684e-07 - val_acc: 1.0000\n",
      "Epoch 1085/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 6.6305e-07 - acc: 1.0000 - val_loss: 3.4473e-07 - val_acc: 1.0000\n",
      "Epoch 1086/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.4501e-07 - acc: 1.0000 - val_loss: 3.3976e-07 - val_acc: 1.0000\n",
      "Epoch 1087/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.6251e-07 - acc: 1.0000 - val_loss: 3.3914e-07 - val_acc: 1.0000\n",
      "Epoch 1088/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.9501e-07 - acc: 1.0000 - val_loss: 3.3793e-07 - val_acc: 1.0000\n",
      "Epoch 1089/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.3731e-07 - acc: 1.0000 - val_loss: 3.3918e-07 - val_acc: 1.0000\n",
      "Epoch 1090/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.5173e-07 - acc: 1.0000 - val_loss: 3.3622e-07 - val_acc: 1.0000\n",
      "Epoch 1091/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 7.4310e-07 - acc: 1.0000 - val_loss: 3.3193e-07 - val_acc: 1.0000\n",
      "Epoch 1092/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 6.4442e-07 - acc: 1.0000 - val_loss: 3.3161e-07 - val_acc: 1.0000\n",
      "Epoch 1093/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.9322e-07 - acc: 1.0000 - val_loss: 3.3115e-07 - val_acc: 1.0000\n",
      "Epoch 1094/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 6.7205e-07 - acc: 1.0000 - val_loss: 3.3021e-07 - val_acc: 1.0000\n",
      "Epoch 1095/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.5521e-07 - acc: 1.0000 - val_loss: 3.2520e-07 - val_acc: 1.0000\n",
      "Epoch 1096/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.5655e-07 - acc: 1.0000 - val_loss: 3.2539e-07 - val_acc: 1.0000\n",
      "Epoch 1097/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.7732e-07 - acc: 1.0000 - val_loss: 3.2307e-07 - val_acc: 1.0000\n",
      "Epoch 1098/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.5595e-07 - acc: 1.0000 - val_loss: 3.2203e-07 - val_acc: 1.0000\n",
      "Epoch 1099/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 6.6620e-07 - acc: 1.0000 - val_loss: 3.2306e-07 - val_acc: 1.0000\n",
      "Epoch 1100/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 6.6812e-07 - acc: 1.0000 - val_loss: 3.2230e-07 - val_acc: 1.0000\n",
      "Epoch 1101/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 6.1991e-07 - acc: 1.0000 - val_loss: 3.2540e-07 - val_acc: 1.0000\n",
      "Epoch 1102/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 6.1382e-07 - acc: 1.0000 - val_loss: 3.2197e-07 - val_acc: 1.0000\n",
      "Epoch 1103/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 6.5892e-07 - acc: 1.0000 - val_loss: 3.1985e-07 - val_acc: 1.0000\n",
      "Epoch 1104/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.8615e-07 - acc: 1.0000 - val_loss: 3.1846e-07 - val_acc: 1.0000\n",
      "Epoch 1105/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.7851e-07 - acc: 1.0000 - val_loss: 3.1677e-07 - val_acc: 1.0000\n",
      "Epoch 1106/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.5983e-07 - acc: 1.0000 - val_loss: 3.1730e-07 - val_acc: 1.0000\n",
      "Epoch 1107/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 6.1713e-07 - acc: 1.0000 - val_loss: 3.1324e-07 - val_acc: 1.0000\n",
      "Epoch 1108/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 5.6934e-07 - acc: 1.0000 - val_loss: 3.1206e-07 - val_acc: 1.0000\n",
      "Epoch 1109/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 6.6347e-07 - acc: 1.0000 - val_loss: 3.0969e-07 - val_acc: 1.0000\n",
      "Epoch 1110/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 5.7123e-07 - acc: 1.0000 - val_loss: 3.0911e-07 - val_acc: 1.0000\n",
      "Epoch 1111/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.9322e-07 - acc: 1.0000 - val_loss: 3.0450e-07 - val_acc: 1.0000\n",
      "Epoch 1112/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 6.5575e-07 - acc: 1.0000 - val_loss: 3.0275e-07 - val_acc: 1.0000\n",
      "Epoch 1113/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.7671e-07 - acc: 1.0000 - val_loss: 3.0708e-07 - val_acc: 1.0000\n",
      "Epoch 1114/10000\n",
      "1139/1139 [==============================] - 0s 57us/step - loss: 5.8217e-07 - acc: 1.0000 - val_loss: 3.0595e-07 - val_acc: 1.0000\n",
      "Epoch 1115/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 5.7424e-07 - acc: 1.0000 - val_loss: 3.0479e-07 - val_acc: 1.0000\n",
      "Epoch 1116/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 7.1280e-07 - acc: 1.0000 - val_loss: 3.0262e-07 - val_acc: 1.0000\n",
      "Epoch 1117/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 5.2012e-07 - acc: 1.0000 - val_loss: 2.9716e-07 - val_acc: 1.0000\n",
      "Epoch 1118/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 5.3443e-07 - acc: 1.0000 - val_loss: 2.9566e-07 - val_acc: 1.0000\n",
      "Epoch 1119/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 6.6218e-07 - acc: 1.0000 - val_loss: 2.9273e-07 - val_acc: 1.0000\n",
      "Epoch 1120/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.1523e-07 - acc: 1.0000 - val_loss: 2.9220e-07 - val_acc: 1.0000\n",
      "Epoch 1121/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 6.6098e-07 - acc: 1.0000 - val_loss: 2.9296e-07 - val_acc: 1.0000\n",
      "Epoch 1122/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.8467e-07 - acc: 1.0000 - val_loss: 2.9228e-07 - val_acc: 1.0000\n",
      "Epoch 1123/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.6059e-07 - acc: 1.0000 - val_loss: 2.9031e-07 - val_acc: 1.0000\n",
      "Epoch 1124/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.1400e-07 - acc: 1.0000 - val_loss: 2.8799e-07 - val_acc: 1.0000\n",
      "Epoch 1125/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 5.0284e-07 - acc: 1.0000 - val_loss: 2.8772e-07 - val_acc: 1.0000\n",
      "Epoch 1126/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.7168e-07 - acc: 1.0000 - val_loss: 2.8571e-07 - val_acc: 1.0000\n",
      "Epoch 1127/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 5.1092e-07 - acc: 1.0000 - val_loss: 2.8415e-07 - val_acc: 1.0000\n",
      "Epoch 1128/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 5.4498e-07 - acc: 1.0000 - val_loss: 2.8346e-07 - val_acc: 1.0000\n",
      "Epoch 1129/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 5.9052e-07 - acc: 1.0000 - val_loss: 2.8217e-07 - val_acc: 1.0000\n",
      "Epoch 1130/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 5.3253e-07 - acc: 1.0000 - val_loss: 2.8399e-07 - val_acc: 1.0000\n",
      "Epoch 1131/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 6.2594e-07 - acc: 1.0000 - val_loss: 2.8144e-07 - val_acc: 1.0000\n",
      "Epoch 1132/10000\n",
      "1139/1139 [==============================] - 0s 43us/step - loss: 4.5934e-07 - acc: 1.0000 - val_loss: 2.7903e-07 - val_acc: 1.0000\n",
      "Epoch 1133/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 5.5016e-07 - acc: 1.0000 - val_loss: 2.7734e-07 - val_acc: 1.0000\n",
      "Epoch 1134/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 6.7226e-07 - acc: 1.0000 - val_loss: 2.7705e-07 - val_acc: 1.0000\n",
      "Epoch 1135/10000\n",
      "1139/1139 [==============================] - 0s 40us/step - loss: 5.4127e-07 - acc: 1.0000 - val_loss: 2.7727e-07 - val_acc: 1.0000\n",
      "Epoch 1136/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 4.7954e-07 - acc: 1.0000 - val_loss: 2.7687e-07 - val_acc: 1.0000\n",
      "Epoch 1137/10000\n",
      "1139/1139 [==============================] - 0s 46us/step - loss: 4.8578e-07 - acc: 1.0000 - val_loss: 2.7567e-07 - val_acc: 1.0000\n",
      "Epoch 1138/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.8377e-07 - acc: 1.0000 - val_loss: 2.7269e-07 - val_acc: 1.0000\n",
      "Epoch 1139/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 5.1553e-07 - acc: 1.0000 - val_loss: 2.7144e-07 - val_acc: 1.0000\n",
      "Epoch 1140/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.2624e-07 - acc: 1.0000 - val_loss: 2.7053e-07 - val_acc: 1.0000\n",
      "Epoch 1141/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.4218e-07 - acc: 1.0000 - val_loss: 2.7003e-07 - val_acc: 1.0000\n",
      "Epoch 1142/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.1335e-07 - acc: 1.0000 - val_loss: 2.6999e-07 - val_acc: 1.0000\n",
      "Epoch 1143/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.6528e-07 - acc: 1.0000 - val_loss: 2.6958e-07 - val_acc: 1.0000\n",
      "Epoch 1144/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 5.8124e-07 - acc: 1.0000 - val_loss: 2.6517e-07 - val_acc: 1.0000\n",
      "Epoch 1145/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 5.1052e-07 - acc: 1.0000 - val_loss: 2.6193e-07 - val_acc: 1.0000\n",
      "Epoch 1146/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 6.2772e-07 - acc: 1.0000 - val_loss: 2.5934e-07 - val_acc: 1.0000\n",
      "Epoch 1147/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 5.0400e-07 - acc: 1.0000 - val_loss: 2.5843e-07 - val_acc: 1.0000\n",
      "Epoch 1148/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 5.3844e-07 - acc: 1.0000 - val_loss: 2.6029e-07 - val_acc: 1.0000\n",
      "Epoch 1149/10000\n",
      "1139/1139 [==============================] - 0s 42us/step - loss: 5.0856e-07 - acc: 1.0000 - val_loss: 2.6043e-07 - val_acc: 1.0000\n",
      "Epoch 1150/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 5.2993e-07 - acc: 1.0000 - val_loss: 2.6246e-07 - val_acc: 1.0000\n",
      "Epoch 1151/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 4.4524e-07 - acc: 1.0000 - val_loss: 2.6295e-07 - val_acc: 1.0000\n",
      "Epoch 1152/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 5.0249e-07 - acc: 1.0000 - val_loss: 2.6059e-07 - val_acc: 1.0000\n",
      "Epoch 1153/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 5.1429e-07 - acc: 1.0000 - val_loss: 2.5776e-07 - val_acc: 1.0000\n",
      "Epoch 1154/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 5.0540e-07 - acc: 1.0000 - val_loss: 2.5652e-07 - val_acc: 1.0000\n",
      "Epoch 1155/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.6495e-07 - acc: 1.0000 - val_loss: 2.5365e-07 - val_acc: 1.0000\n",
      "Epoch 1156/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 5.0800e-07 - acc: 1.0000 - val_loss: 2.5256e-07 - val_acc: 1.0000\n",
      "Epoch 1157/10000\n",
      "1139/1139 [==============================] - 0s 17us/step - loss: 4.0196e-07 - acc: 1.0000 - val_loss: 2.4781e-07 - val_acc: 1.0000\n",
      "Epoch 1158/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.0337e-07 - acc: 1.0000 - val_loss: 2.4583e-07 - val_acc: 1.0000\n",
      "Epoch 1159/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.5675e-07 - acc: 1.0000 - val_loss: 2.4445e-07 - val_acc: 1.0000\n",
      "Epoch 1160/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.0900e-07 - acc: 1.0000 - val_loss: 2.4658e-07 - val_acc: 1.0000\n",
      "Epoch 1161/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.1610e-07 - acc: 1.0000 - val_loss: 2.4652e-07 - val_acc: 1.0000\n",
      "Epoch 1162/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.7673e-07 - acc: 1.0000 - val_loss: 2.4702e-07 - val_acc: 1.0000\n",
      "Epoch 1163/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 5.1517e-07 - acc: 1.0000 - val_loss: 2.4646e-07 - val_acc: 1.0000\n",
      "Epoch 1164/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.8613e-07 - acc: 1.0000 - val_loss: 2.4709e-07 - val_acc: 1.0000\n",
      "Epoch 1165/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.4467e-07 - acc: 1.0000 - val_loss: 2.4400e-07 - val_acc: 1.0000\n",
      "Epoch 1166/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 4.5698e-07 - acc: 1.0000 - val_loss: 2.4149e-07 - val_acc: 1.0000\n",
      "Epoch 1167/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 4.9775e-07 - acc: 1.0000 - val_loss: 2.3882e-07 - val_acc: 1.0000\n",
      "Epoch 1168/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 4.6280e-07 - acc: 1.0000 - val_loss: 2.3754e-07 - val_acc: 1.0000\n",
      "Epoch 1169/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 4.9279e-07 - acc: 1.000 - 0s 39us/step - loss: 4.7194e-07 - acc: 1.0000 - val_loss: 2.3709e-07 - val_acc: 1.0000\n",
      "Epoch 1170/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 4.9533e-07 - acc: 1.0000 - val_loss: 2.3466e-07 - val_acc: 1.0000\n",
      "Epoch 1171/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 4.4718e-07 - acc: 1.0000 - val_loss: 2.3330e-07 - val_acc: 1.0000\n",
      "Epoch 1172/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 5.8523e-07 - acc: 1.0000 - val_loss: 2.3172e-07 - val_acc: 1.0000\n",
      "Epoch 1173/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 5.3594e-07 - acc: 1.0000 - val_loss: 2.3393e-07 - val_acc: 1.0000\n",
      "Epoch 1174/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 4.9997e-07 - acc: 1.0000 - val_loss: 2.3446e-07 - val_acc: 1.0000\n",
      "Epoch 1175/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 4.6559e-07 - acc: 1.0000 - val_loss: 2.3622e-07 - val_acc: 1.0000\n",
      "Epoch 1176/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 4.9890e-07 - acc: 1.0000 - val_loss: 2.3210e-07 - val_acc: 1.0000\n",
      "Epoch 1177/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 5.2928e-07 - acc: 1.0000 - val_loss: 2.3194e-07 - val_acc: 1.0000\n",
      "Epoch 1178/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 4.7452e-07 - acc: 1.0000 - val_loss: 2.3212e-07 - val_acc: 1.0000\n",
      "Epoch 1179/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 4.0381e-07 - acc: 1.0000 - val_loss: 2.2878e-07 - val_acc: 1.0000\n",
      "Epoch 1180/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.3219e-07 - acc: 1.0000 - val_loss: 2.2839e-07 - val_acc: 1.0000\n",
      "Epoch 1181/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.5878e-07 - acc: 1.0000 - val_loss: 2.2570e-07 - val_acc: 1.0000\n",
      "Epoch 1182/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.7718e-07 - acc: 1.0000 - val_loss: 2.2305e-07 - val_acc: 1.0000\n",
      "Epoch 1183/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 4.0774e-07 - acc: 1.0000 - val_loss: 2.2344e-07 - val_acc: 1.0000\n",
      "Epoch 1184/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 4.1393e-07 - acc: 1.0000 - val_loss: 2.2224e-07 - val_acc: 1.0000\n",
      "Epoch 1185/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.7576e-07 - acc: 1.0000 - val_loss: 2.2170e-07 - val_acc: 1.0000\n",
      "Epoch 1186/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 4.2386e-07 - acc: 1.0000 - val_loss: 2.2137e-07 - val_acc: 1.0000\n",
      "Epoch 1187/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 4.9686e-07 - acc: 1.0000 - val_loss: 2.2049e-07 - val_acc: 1.0000\n",
      "Epoch 1188/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 4.4370e-07 - acc: 1.0000 - val_loss: 2.2126e-07 - val_acc: 1.0000\n",
      "Epoch 1189/10000\n",
      "1139/1139 [==============================] - 0s 39us/step - loss: 4.4541e-07 - acc: 1.0000 - val_loss: 2.2112e-07 - val_acc: 1.0000\n",
      "Epoch 1190/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.2187e-07 - acc: 1.0000 - val_loss: 2.1747e-07 - val_acc: 1.0000\n",
      "Epoch 1191/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.7525e-07 - acc: 1.0000 - val_loss: 2.1575e-07 - val_acc: 1.0000\n",
      "Epoch 1192/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.9537e-07 - acc: 1.0000 - val_loss: 2.1561e-07 - val_acc: 1.0000\n",
      "Epoch 1193/10000\n",
      "1139/1139 [==============================] - 0s 15us/step - loss: 4.3631e-07 - acc: 1.0000 - val_loss: 2.1358e-07 - val_acc: 1.0000\n",
      "Epoch 1194/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 4.7565e-07 - acc: 1.0000 - val_loss: 2.1246e-07 - val_acc: 1.0000\n",
      "Epoch 1195/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 4.2080e-07 - acc: 1.0000 - val_loss: 2.1263e-07 - val_acc: 1.0000\n",
      "Epoch 1196/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.6490e-07 - acc: 1.0000 - val_loss: 2.1280e-07 - val_acc: 1.0000\n",
      "Epoch 1197/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.8131e-07 - acc: 1.0000 - val_loss: 2.1042e-07 - val_acc: 1.0000\n",
      "Epoch 1198/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 5.0197e-07 - acc: 1.0000 - val_loss: 2.0986e-07 - val_acc: 1.0000\n",
      "Epoch 1199/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.9422e-07 - acc: 1.0000 - val_loss: 2.0665e-07 - val_acc: 1.0000\n",
      "Epoch 1200/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.1629e-07 - acc: 1.0000 - val_loss: 2.0574e-07 - val_acc: 1.0000\n",
      "Epoch 1201/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6069e-07 - acc: 1.0000 - val_loss: 2.0605e-07 - val_acc: 1.0000\n",
      "Epoch 1202/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.9919e-07 - acc: 1.0000 - val_loss: 2.0503e-07 - val_acc: 1.0000\n",
      "Epoch 1203/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.7496e-07 - acc: 1.0000 - val_loss: 2.0414e-07 - val_acc: 1.0000\n",
      "Epoch 1204/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5401e-07 - acc: 1.0000 - val_loss: 2.0394e-07 - val_acc: 1.0000\n",
      "Epoch 1205/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.8979e-07 - acc: 1.0000 - val_loss: 2.0368e-07 - val_acc: 1.0000\n",
      "Epoch 1206/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.8781e-07 - acc: 1.0000 - val_loss: 2.0245e-07 - val_acc: 1.0000\n",
      "Epoch 1207/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.5020e-07 - acc: 1.0000 - val_loss: 2.0143e-07 - val_acc: 1.0000\n",
      "Epoch 1208/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.2461e-07 - acc: 1.0000 - val_loss: 2.0164e-07 - val_acc: 1.0000\n",
      "Epoch 1209/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6316e-07 - acc: 1.0000 - val_loss: 2.0307e-07 - val_acc: 1.0000\n",
      "Epoch 1210/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.9096e-07 - acc: 1.0000 - val_loss: 2.0387e-07 - val_acc: 1.0000\n",
      "Epoch 1211/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.7819e-07 - acc: 1.0000 - val_loss: 2.0428e-07 - val_acc: 1.0000\n",
      "Epoch 1212/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 4.5750e-07 - acc: 1.0000 - val_loss: 2.0162e-07 - val_acc: 1.0000\n",
      "Epoch 1213/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 3.8867e-07 - acc: 1.0000 - val_loss: 1.9833e-07 - val_acc: 1.0000\n",
      "Epoch 1214/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.5962e-07 - acc: 1.0000 - val_loss: 1.9483e-07 - val_acc: 1.0000\n",
      "Epoch 1215/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 4.3590e-07 - acc: 1.0000 - val_loss: 2.0102e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1216/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.9103e-07 - acc: 1.0000 - val_loss: 1.9970e-07 - val_acc: 1.0000\n",
      "Epoch 1217/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.4946e-07 - acc: 1.0000 - val_loss: 1.9987e-07 - val_acc: 1.0000\n",
      "Epoch 1218/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.9677e-07 - acc: 1.0000 - val_loss: 1.9966e-07 - val_acc: 1.0000\n",
      "Epoch 1219/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5078e-07 - acc: 1.0000 - val_loss: 1.9841e-07 - val_acc: 1.0000\n",
      "Epoch 1220/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.0555e-07 - acc: 1.0000 - val_loss: 1.9764e-07 - val_acc: 1.0000\n",
      "Epoch 1221/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.2262e-07 - acc: 1.0000 - val_loss: 1.9747e-07 - val_acc: 1.0000\n",
      "Epoch 1222/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.2262e-07 - acc: 1.0000 - val_loss: 1.9200e-07 - val_acc: 1.0000\n",
      "Epoch 1223/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.9802e-07 - acc: 1.0000 - val_loss: 1.9074e-07 - val_acc: 1.0000\n",
      "Epoch 1224/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 3.8924e-07 - acc: 1.0000 - val_loss: 1.9081e-07 - val_acc: 1.0000\n",
      "Epoch 1225/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5966e-07 - acc: 1.0000 - val_loss: 1.8930e-07 - val_acc: 1.0000\n",
      "Epoch 1226/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.4170e-07 - acc: 1.0000 - val_loss: 1.8885e-07 - val_acc: 1.0000\n",
      "Epoch 1227/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4384e-07 - acc: 1.0000 - val_loss: 1.8797e-07 - val_acc: 1.0000\n",
      "Epoch 1228/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.0956e-07 - acc: 1.0000 - val_loss: 1.8758e-07 - val_acc: 1.0000\n",
      "Epoch 1229/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5958e-07 - acc: 1.0000 - val_loss: 1.8737e-07 - val_acc: 1.0000\n",
      "Epoch 1230/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4683e-07 - acc: 1.0000 - val_loss: 1.8720e-07 - val_acc: 1.0000\n",
      "Epoch 1231/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.7666e-07 - acc: 1.0000 - val_loss: 1.8796e-07 - val_acc: 1.0000\n",
      "Epoch 1232/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.2482e-07 - acc: 1.0000 - val_loss: 1.8733e-07 - val_acc: 1.0000\n",
      "Epoch 1233/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 3.9293e-07 - acc: 1.0000 - val_loss: 1.8593e-07 - val_acc: 1.0000\n",
      "Epoch 1234/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.0013e-07 - acc: 1.0000 - val_loss: 1.8562e-07 - val_acc: 1.0000\n",
      "Epoch 1235/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 3.3809e-07 - acc: 1.0000 - val_loss: 1.8477e-07 - val_acc: 1.0000\n",
      "Epoch 1236/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5562e-07 - acc: 1.0000 - val_loss: 1.8479e-07 - val_acc: 1.0000\n",
      "Epoch 1237/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.0751e-07 - acc: 1.0000 - val_loss: 1.8290e-07 - val_acc: 1.0000\n",
      "Epoch 1238/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4270e-07 - acc: 1.0000 - val_loss: 1.8285e-07 - val_acc: 1.0000\n",
      "Epoch 1239/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 4.7555e-07 - acc: 1.0000 - val_loss: 1.8706e-07 - val_acc: 1.0000\n",
      "Epoch 1240/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.8422e-07 - acc: 1.0000 - val_loss: 1.8926e-07 - val_acc: 1.0000\n",
      "Epoch 1241/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.8346e-07 - acc: 1.0000 - val_loss: 1.8487e-07 - val_acc: 1.0000\n",
      "Epoch 1242/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5643e-07 - acc: 1.0000 - val_loss: 1.8203e-07 - val_acc: 1.0000\n",
      "Epoch 1243/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4089e-07 - acc: 1.0000 - val_loss: 1.8086e-07 - val_acc: 1.0000\n",
      "Epoch 1244/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6694e-07 - acc: 1.0000 - val_loss: 1.8020e-07 - val_acc: 1.0000\n",
      "Epoch 1245/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.2345e-07 - acc: 1.0000 - val_loss: 1.7774e-07 - val_acc: 1.0000\n",
      "Epoch 1246/10000\n",
      "1139/1139 [==============================] - 0s 16us/step - loss: 3.7372e-07 - acc: 1.0000 - val_loss: 1.7500e-07 - val_acc: 1.0000\n",
      "Epoch 1247/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4507e-07 - acc: 1.0000 - val_loss: 1.7498e-07 - val_acc: 1.0000\n",
      "Epoch 1248/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3639e-07 - acc: 1.0000 - val_loss: 1.7486e-07 - val_acc: 1.0000\n",
      "Epoch 1249/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.1762e-07 - acc: 1.0000 - val_loss: 1.7462e-07 - val_acc: 1.0000\n",
      "Epoch 1250/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 3.1661e-07 - acc: 1.0000 - val_loss: 1.7462e-07 - val_acc: 1.0000\n",
      "Epoch 1251/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 4.3992e-07 - acc: 1.0000 - val_loss: 1.7481e-07 - val_acc: 1.0000\n",
      "Epoch 1252/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8733e-07 - acc: 1.0000 - val_loss: 1.7471e-07 - val_acc: 1.0000\n",
      "Epoch 1253/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.1158e-07 - acc: 1.0000 - val_loss: 1.7358e-07 - val_acc: 1.0000\n",
      "Epoch 1254/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.8019e-07 - acc: 1.0000 - val_loss: 1.7235e-07 - val_acc: 1.0000\n",
      "Epoch 1255/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5479e-07 - acc: 1.0000 - val_loss: 1.7084e-07 - val_acc: 1.0000\n",
      "Epoch 1256/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.4960e-07 - acc: 1.0000 - val_loss: 1.6974e-07 - val_acc: 1.0000\n",
      "Epoch 1257/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3119e-07 - acc: 1.0000 - val_loss: 1.7205e-07 - val_acc: 1.0000\n",
      "Epoch 1258/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5821e-07 - acc: 1.0000 - val_loss: 1.7290e-07 - val_acc: 1.0000\n",
      "Epoch 1259/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 3.5493e-07 - acc: 1.0000 - val_loss: 1.7117e-07 - val_acc: 1.0000\n",
      "Epoch 1260/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.4187e-07 - acc: 1.0000 - val_loss: 1.7120e-07 - val_acc: 1.0000\n",
      "Epoch 1261/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.7801e-07 - acc: 1.0000 - val_loss: 1.6940e-07 - val_acc: 1.0000\n",
      "Epoch 1262/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.9513e-07 - acc: 1.0000 - val_loss: 1.6890e-07 - val_acc: 1.0000\n",
      "Epoch 1263/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6346e-07 - acc: 1.0000 - val_loss: 1.6916e-07 - val_acc: 1.0000\n",
      "Epoch 1264/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3215e-07 - acc: 1.0000 - val_loss: 1.6721e-07 - val_acc: 1.0000\n",
      "Epoch 1265/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.7850e-07 - acc: 1.0000 - val_loss: 1.6727e-07 - val_acc: 1.0000\n",
      "Epoch 1266/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.7383e-07 - acc: 1.0000 - val_loss: 1.6702e-07 - val_acc: 1.0000\n",
      "Epoch 1267/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3573e-07 - acc: 1.0000 - val_loss: 1.6661e-07 - val_acc: 1.0000\n",
      "Epoch 1268/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6257e-07 - acc: 1.0000 - val_loss: 1.6657e-07 - val_acc: 1.0000\n",
      "Epoch 1269/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.9496e-07 - acc: 1.0000 - val_loss: 1.6628e-07 - val_acc: 1.0000\n",
      "Epoch 1270/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.3136e-07 - acc: 1.0000 - val_loss: 1.6470e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1271/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.9821e-07 - acc: 1.0000 - val_loss: 1.6410e-07 - val_acc: 1.0000\n",
      "Epoch 1272/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.0491e-07 - acc: 1.0000 - val_loss: 1.6455e-07 - val_acc: 1.0000\n",
      "Epoch 1273/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 1.8571e-07 - acc: 1.000 - 0s 25us/step - loss: 3.0398e-07 - acc: 1.0000 - val_loss: 1.6447e-07 - val_acc: 1.0000\n",
      "Epoch 1274/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 2.9301e-07 - acc: 1.0000 - val_loss: 1.6343e-07 - val_acc: 1.0000\n",
      "Epoch 1275/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 3.4867e-07 - acc: 1.0000 - val_loss: 1.6393e-07 - val_acc: 1.0000\n",
      "Epoch 1276/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.0311e-07 - acc: 1.0000 - val_loss: 1.6147e-07 - val_acc: 1.0000\n",
      "Epoch 1277/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 3.1687e-07 - acc: 1.000 - 0s 26us/step - loss: 3.0680e-07 - acc: 1.0000 - val_loss: 1.5971e-07 - val_acc: 1.0000\n",
      "Epoch 1278/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 2.9337e-07 - acc: 1.0000 - val_loss: 1.5880e-07 - val_acc: 1.0000\n",
      "Epoch 1279/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 3.4570e-07 - acc: 1.0000 - val_loss: 1.5888e-07 - val_acc: 1.0000\n",
      "Epoch 1280/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.6134e-07 - acc: 1.0000 - val_loss: 1.5862e-07 - val_acc: 1.0000\n",
      "Epoch 1281/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 3.0629e-07 - acc: 1.0000 - val_loss: 1.5779e-07 - val_acc: 1.0000\n",
      "Epoch 1282/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.1078e-07 - acc: 1.0000 - val_loss: 1.5848e-07 - val_acc: 1.0000\n",
      "Epoch 1283/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5977e-07 - acc: 1.0000 - val_loss: 1.5901e-07 - val_acc: 1.0000\n",
      "Epoch 1284/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6398e-07 - acc: 1.0000 - val_loss: 1.5803e-07 - val_acc: 1.0000\n",
      "Epoch 1285/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.7254e-07 - acc: 1.0000 - val_loss: 1.5700e-07 - val_acc: 1.0000\n",
      "Epoch 1286/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6563e-07 - acc: 1.0000 - val_loss: 1.5717e-07 - val_acc: 1.0000\n",
      "Epoch 1287/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.1367e-07 - acc: 1.0000 - val_loss: 1.5839e-07 - val_acc: 1.0000\n",
      "Epoch 1288/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8008e-07 - acc: 1.0000 - val_loss: 1.5815e-07 - val_acc: 1.0000\n",
      "Epoch 1289/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.4119e-07 - acc: 1.0000 - val_loss: 1.5644e-07 - val_acc: 1.0000\n",
      "Epoch 1290/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.9409e-07 - acc: 1.0000 - val_loss: 1.5591e-07 - val_acc: 1.0000\n",
      "Epoch 1291/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3646e-07 - acc: 1.0000 - val_loss: 1.5543e-07 - val_acc: 1.0000\n",
      "Epoch 1292/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8025e-07 - acc: 1.0000 - val_loss: 1.6221e-07 - val_acc: 1.0000\n",
      "Epoch 1293/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6740e-07 - acc: 1.0000 - val_loss: 1.6459e-07 - val_acc: 1.0000\n",
      "Epoch 1294/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8211e-07 - acc: 1.0000 - val_loss: 1.6192e-07 - val_acc: 1.0000\n",
      "Epoch 1295/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 3.7509e-07 - acc: 1.0000 - val_loss: 1.5803e-07 - val_acc: 1.0000\n",
      "Epoch 1296/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.7752e-07 - acc: 1.0000 - val_loss: 1.5548e-07 - val_acc: 1.0000\n",
      "Epoch 1297/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.5131e-07 - acc: 1.0000 - val_loss: 1.5557e-07 - val_acc: 1.0000\n",
      "Epoch 1298/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3729e-07 - acc: 1.0000 - val_loss: 1.5476e-07 - val_acc: 1.0000\n",
      "Epoch 1299/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.1851e-07 - acc: 1.0000 - val_loss: 1.5336e-07 - val_acc: 1.0000\n",
      "Epoch 1300/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.2305e-07 - acc: 1.0000 - val_loss: 1.5323e-07 - val_acc: 1.0000\n",
      "Epoch 1301/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.1858e-07 - acc: 1.0000 - val_loss: 1.5357e-07 - val_acc: 1.0000\n",
      "Epoch 1302/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.3586e-07 - acc: 1.0000 - val_loss: 1.5331e-07 - val_acc: 1.0000\n",
      "Epoch 1303/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.9887e-07 - acc: 1.0000 - val_loss: 1.5315e-07 - val_acc: 1.0000\n",
      "Epoch 1304/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6158e-07 - acc: 1.0000 - val_loss: 1.5295e-07 - val_acc: 1.0000\n",
      "Epoch 1305/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.5663e-07 - acc: 1.0000 - val_loss: 1.5282e-07 - val_acc: 1.0000\n",
      "Epoch 1306/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.3776e-07 - acc: 1.0000 - val_loss: 1.5114e-07 - val_acc: 1.0000\n",
      "Epoch 1307/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.0230e-07 - acc: 1.0000 - val_loss: 1.5049e-07 - val_acc: 1.0000\n",
      "Epoch 1308/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3478e-07 - acc: 1.0000 - val_loss: 1.5038e-07 - val_acc: 1.0000\n",
      "Epoch 1309/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3695e-07 - acc: 1.0000 - val_loss: 1.5027e-07 - val_acc: 1.0000\n",
      "Epoch 1310/10000\n",
      "1139/1139 [==============================] - 0s 18us/step - loss: 3.1300e-07 - acc: 1.0000 - val_loss: 1.4843e-07 - val_acc: 1.0000\n",
      "Epoch 1311/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2781e-07 - acc: 1.0000 - val_loss: 1.5091e-07 - val_acc: 1.0000\n",
      "Epoch 1312/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 3.1016e-07 - acc: 1.0000 - val_loss: 1.5001e-07 - val_acc: 1.0000\n",
      "Epoch 1313/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.5086e-07 - acc: 1.0000 - val_loss: 1.4978e-07 - val_acc: 1.0000\n",
      "Epoch 1314/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3725e-07 - acc: 1.0000 - val_loss: 1.4965e-07 - val_acc: 1.0000\n",
      "Epoch 1315/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6167e-07 - acc: 1.0000 - val_loss: 1.4877e-07 - val_acc: 1.0000\n",
      "Epoch 1316/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.7141e-07 - acc: 1.0000 - val_loss: 1.4785e-07 - val_acc: 1.0000\n",
      "Epoch 1317/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6959e-07 - acc: 1.0000 - val_loss: 1.4801e-07 - val_acc: 1.0000\n",
      "Epoch 1318/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.4896e-07 - acc: 1.0000 - val_loss: 1.4719e-07 - val_acc: 1.0000\n",
      "Epoch 1319/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.7049e-07 - acc: 1.0000 - val_loss: 1.4613e-07 - val_acc: 1.0000\n",
      "Epoch 1320/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2549e-07 - acc: 1.0000 - val_loss: 1.4593e-07 - val_acc: 1.0000\n",
      "Epoch 1321/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.6245e-07 - acc: 1.0000 - val_loss: 1.4597e-07 - val_acc: 1.0000\n",
      "Epoch 1322/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.7484e-07 - acc: 1.0000 - val_loss: 1.4607e-07 - val_acc: 1.0000\n",
      "Epoch 1323/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8716e-07 - acc: 1.0000 - val_loss: 1.4551e-07 - val_acc: 1.0000\n",
      "Epoch 1324/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3880e-07 - acc: 1.0000 - val_loss: 1.4542e-07 - val_acc: 1.0000\n",
      "Epoch 1325/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.4312e-07 - acc: 1.0000 - val_loss: 1.4525e-07 - val_acc: 1.0000\n",
      "Epoch 1326/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.8058e-07 - acc: 1.0000 - val_loss: 1.4581e-07 - val_acc: 1.0000\n",
      "Epoch 1327/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.4653e-07 - acc: 1.0000 - val_loss: 1.4564e-07 - val_acc: 1.0000\n",
      "Epoch 1328/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2560e-07 - acc: 1.0000 - val_loss: 1.4556e-07 - val_acc: 1.0000\n",
      "Epoch 1329/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6383e-07 - acc: 1.0000 - val_loss: 1.4394e-07 - val_acc: 1.0000\n",
      "Epoch 1330/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.5138e-07 - acc: 1.0000 - val_loss: 1.4385e-07 - val_acc: 1.0000\n",
      "Epoch 1331/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3683e-07 - acc: 1.0000 - val_loss: 1.4378e-07 - val_acc: 1.0000\n",
      "Epoch 1332/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3794e-07 - acc: 1.0000 - val_loss: 1.4373e-07 - val_acc: 1.0000\n",
      "Epoch 1333/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2594e-07 - acc: 1.0000 - val_loss: 1.4544e-07 - val_acc: 1.0000\n",
      "Epoch 1334/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1731e-07 - acc: 1.0000 - val_loss: 1.4535e-07 - val_acc: 1.0000\n",
      "Epoch 1335/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.4662e-07 - acc: 1.0000 - val_loss: 1.4364e-07 - val_acc: 1.0000\n",
      "Epoch 1336/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6663e-07 - acc: 1.0000 - val_loss: 1.4297e-07 - val_acc: 1.0000\n",
      "Epoch 1337/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.7448e-07 - acc: 1.0000 - val_loss: 1.3953e-07 - val_acc: 1.0000\n",
      "Epoch 1338/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.4006e-07 - acc: 1.0000 - val_loss: 1.3782e-07 - val_acc: 1.0000\n",
      "Epoch 1339/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.5546e-07 - acc: 1.0000 - val_loss: 1.3691e-07 - val_acc: 1.0000\n",
      "Epoch 1340/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6103e-07 - acc: 1.0000 - val_loss: 1.3666e-07 - val_acc: 1.0000\n",
      "Epoch 1341/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 2.9768e-07 - acc: 1.0000 - val_loss: 1.3649e-07 - val_acc: 1.0000\n",
      "Epoch 1342/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.5316e-07 - acc: 1.0000 - val_loss: 1.3643e-07 - val_acc: 1.0000\n",
      "Epoch 1343/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.5812e-07 - acc: 1.0000 - val_loss: 1.3622e-07 - val_acc: 1.0000\n",
      "Epoch 1344/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3944e-07 - acc: 1.0000 - val_loss: 1.3967e-07 - val_acc: 1.0000\n",
      "Epoch 1345/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3019e-07 - acc: 1.0000 - val_loss: 1.3688e-07 - val_acc: 1.0000\n",
      "Epoch 1346/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.4513e-07 - acc: 1.0000 - val_loss: 1.3586e-07 - val_acc: 1.0000\n",
      "Epoch 1347/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1756e-07 - acc: 1.0000 - val_loss: 1.3586e-07 - val_acc: 1.0000\n",
      "Epoch 1348/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.7328e-07 - acc: 1.0000 - val_loss: 1.3586e-07 - val_acc: 1.0000\n",
      "Epoch 1349/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.5008e-07 - acc: 1.0000 - val_loss: 1.3591e-07 - val_acc: 1.0000\n",
      "Epoch 1350/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.5096e-07 - acc: 1.0000 - val_loss: 1.3529e-07 - val_acc: 1.0000\n",
      "Epoch 1351/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2942e-07 - acc: 1.0000 - val_loss: 1.3531e-07 - val_acc: 1.0000\n",
      "Epoch 1352/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3653e-07 - acc: 1.0000 - val_loss: 1.3511e-07 - val_acc: 1.0000\n",
      "Epoch 1353/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.6589e-07 - acc: 1.0000 - val_loss: 1.3489e-07 - val_acc: 1.0000\n",
      "Epoch 1354/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.4867e-07 - acc: 1.0000 - val_loss: 1.3548e-07 - val_acc: 1.0000\n",
      "Epoch 1355/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1171e-07 - acc: 1.0000 - val_loss: 1.3531e-07 - val_acc: 1.0000\n",
      "Epoch 1356/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2961e-07 - acc: 1.0000 - val_loss: 1.3525e-07 - val_acc: 1.0000\n",
      "Epoch 1357/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 2.4363e-07 - acc: 1.0000 - val_loss: 1.3518e-07 - val_acc: 1.0000\n",
      "Epoch 1358/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.0809e-07 - acc: 1.0000 - val_loss: 1.3506e-07 - val_acc: 1.0000\n",
      "Epoch 1359/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.4881e-07 - acc: 1.0000 - val_loss: 1.3588e-07 - val_acc: 1.0000\n",
      "Epoch 1360/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.1409e-07 - acc: 1.0000 - val_loss: 1.3506e-07 - val_acc: 1.0000\n",
      "Epoch 1361/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2389e-07 - acc: 1.0000 - val_loss: 1.3417e-07 - val_acc: 1.0000\n",
      "Epoch 1362/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3632e-07 - acc: 1.0000 - val_loss: 1.3416e-07 - val_acc: 1.0000\n",
      "Epoch 1363/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1080e-07 - acc: 1.0000 - val_loss: 1.3411e-07 - val_acc: 1.0000\n",
      "Epoch 1364/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.8886e-07 - acc: 1.0000 - val_loss: 1.3415e-07 - val_acc: 1.0000\n",
      "Epoch 1365/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2370e-07 - acc: 1.0000 - val_loss: 1.3421e-07 - val_acc: 1.0000\n",
      "Epoch 1366/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.1753e-07 - acc: 1.0000 - val_loss: 1.3340e-07 - val_acc: 1.0000\n",
      "Epoch 1367/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3736e-07 - acc: 1.0000 - val_loss: 1.3343e-07 - val_acc: 1.0000\n",
      "Epoch 1368/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3938e-07 - acc: 1.0000 - val_loss: 1.3326e-07 - val_acc: 1.0000\n",
      "Epoch 1369/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2201e-07 - acc: 1.0000 - val_loss: 1.3392e-07 - val_acc: 1.0000\n",
      "Epoch 1370/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.7733e-07 - acc: 1.0000 - val_loss: 1.3322e-07 - val_acc: 1.0000\n",
      "Epoch 1371/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2379e-07 - acc: 1.0000 - val_loss: 1.3326e-07 - val_acc: 1.0000\n",
      "Epoch 1372/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0060e-07 - acc: 1.0000 - val_loss: 1.3400e-07 - val_acc: 1.0000\n",
      "Epoch 1373/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.2369e-07 - acc: 1.0000 - val_loss: 1.3375e-07 - val_acc: 1.0000\n",
      "Epoch 1374/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.5509e-07 - acc: 1.0000 - val_loss: 1.3432e-07 - val_acc: 1.0000\n",
      "Epoch 1375/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.4062e-07 - acc: 1.0000 - val_loss: 1.3512e-07 - val_acc: 1.0000\n",
      "Epoch 1376/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3503e-07 - acc: 1.0000 - val_loss: 1.3424e-07 - val_acc: 1.0000\n",
      "Epoch 1377/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 2.1932e-07 - acc: 1.0000 - val_loss: 1.3339e-07 - val_acc: 1.0000\n",
      "Epoch 1378/10000\n",
      "1139/1139 [==============================] - 0s 55us/step - loss: 2.1250e-07 - acc: 1.0000 - val_loss: 1.3347e-07 - val_acc: 1.0000\n",
      "Epoch 1379/10000\n",
      "1139/1139 [==============================] - 0s 55us/step - loss: 2.3942e-07 - acc: 1.0000 - val_loss: 1.3356e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1380/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2947e-07 - acc: 1.0000 - val_loss: 1.3260e-07 - val_acc: 1.0000\n",
      "Epoch 1381/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.5107e-07 - acc: 1.0000 - val_loss: 1.3337e-07 - val_acc: 1.0000\n",
      "Epoch 1382/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2471e-07 - acc: 1.0000 - val_loss: 1.3497e-07 - val_acc: 1.0000\n",
      "Epoch 1383/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2355e-07 - acc: 1.0000 - val_loss: 1.3403e-07 - val_acc: 1.0000\n",
      "Epoch 1384/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2419e-07 - acc: 1.0000 - val_loss: 1.3411e-07 - val_acc: 1.0000\n",
      "Epoch 1385/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0669e-07 - acc: 1.0000 - val_loss: 1.3136e-07 - val_acc: 1.0000\n",
      "Epoch 1386/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 2.1152e-07 - acc: 1.0000 - val_loss: 1.3054e-07 - val_acc: 1.0000\n",
      "Epoch 1387/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1394e-07 - acc: 1.0000 - val_loss: 1.3053e-07 - val_acc: 1.0000\n",
      "Epoch 1388/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0006e-07 - acc: 1.0000 - val_loss: 1.3053e-07 - val_acc: 1.0000\n",
      "Epoch 1389/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0966e-07 - acc: 1.0000 - val_loss: 1.3049e-07 - val_acc: 1.0000\n",
      "Epoch 1390/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1255e-07 - acc: 1.0000 - val_loss: 1.3047e-07 - val_acc: 1.0000\n",
      "Epoch 1391/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2675e-07 - acc: 1.0000 - val_loss: 1.3133e-07 - val_acc: 1.0000\n",
      "Epoch 1392/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0536e-07 - acc: 1.0000 - val_loss: 1.3040e-07 - val_acc: 1.0000\n",
      "Epoch 1393/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0905e-07 - acc: 1.0000 - val_loss: 1.2949e-07 - val_acc: 1.0000\n",
      "Epoch 1394/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2553e-07 - acc: 1.0000 - val_loss: 1.2768e-07 - val_acc: 1.0000\n",
      "Epoch 1395/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9993e-07 - acc: 1.0000 - val_loss: 1.2770e-07 - val_acc: 1.0000\n",
      "Epoch 1396/10000\n",
      "1139/1139 [==============================] - 0s 58us/step - loss: 1.9630e-07 - acc: 1.0000 - val_loss: 1.2769e-07 - val_acc: 1.0000\n",
      "Epoch 1397/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 2.1927e-07 - acc: 1.0000 - val_loss: 1.2750e-07 - val_acc: 1.0000\n",
      "Epoch 1398/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.0572e-07 - acc: 1.0000 - val_loss: 1.2927e-07 - val_acc: 1.0000\n",
      "Epoch 1399/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1730e-07 - acc: 1.0000 - val_loss: 1.2743e-07 - val_acc: 1.0000\n",
      "Epoch 1400/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1479e-07 - acc: 1.0000 - val_loss: 1.2750e-07 - val_acc: 1.0000\n",
      "Epoch 1401/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 2.4071e-07 - acc: 1.000 - 0s 14us/step - loss: 1.9044e-07 - acc: 1.0000 - val_loss: 1.2745e-07 - val_acc: 1.0000\n",
      "Epoch 1402/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.9957e-07 - acc: 1.0000 - val_loss: 1.2735e-07 - val_acc: 1.0000\n",
      "Epoch 1403/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2444e-07 - acc: 1.0000 - val_loss: 1.2736e-07 - val_acc: 1.0000\n",
      "Epoch 1404/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9886e-07 - acc: 1.0000 - val_loss: 1.2742e-07 - val_acc: 1.0000\n",
      "Epoch 1405/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 2.2474e-07 - acc: 1.0000 - val_loss: 1.2737e-07 - val_acc: 1.0000\n",
      "Epoch 1406/10000\n",
      "1139/1139 [==============================] - 0s 60us/step - loss: 1.8281e-07 - acc: 1.0000 - val_loss: 1.2733e-07 - val_acc: 1.0000\n",
      "Epoch 1407/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9970e-07 - acc: 1.0000 - val_loss: 1.2727e-07 - val_acc: 1.0000\n",
      "Epoch 1408/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9373e-07 - acc: 1.0000 - val_loss: 1.2727e-07 - val_acc: 1.0000\n",
      "Epoch 1409/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.0872e-07 - acc: 1.0000 - val_loss: 1.2723e-07 - val_acc: 1.0000\n",
      "Epoch 1410/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3767e-07 - acc: 1.0000 - val_loss: 1.2724e-07 - val_acc: 1.0000\n",
      "Epoch 1411/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2576e-07 - acc: 1.0000 - val_loss: 1.2639e-07 - val_acc: 1.0000\n",
      "Epoch 1412/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8793e-07 - acc: 1.0000 - val_loss: 1.2469e-07 - val_acc: 1.0000\n",
      "Epoch 1413/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.3021e-07 - acc: 1.0000 - val_loss: 1.2460e-07 - val_acc: 1.0000\n",
      "Epoch 1414/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0846e-07 - acc: 1.0000 - val_loss: 1.2533e-07 - val_acc: 1.0000\n",
      "Epoch 1415/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1818e-07 - acc: 1.0000 - val_loss: 1.2519e-07 - val_acc: 1.0000\n",
      "Epoch 1416/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8805e-07 - acc: 1.0000 - val_loss: 1.2517e-07 - val_acc: 1.0000\n",
      "Epoch 1417/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 3.6754e-07 - acc: 1.0000 - val_loss: 1.2851e-07 - val_acc: 1.0000\n",
      "Epoch 1418/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0511e-07 - acc: 1.0000 - val_loss: 1.3476e-07 - val_acc: 1.0000\n",
      "Epoch 1419/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0221e-07 - acc: 1.0000 - val_loss: 1.3569e-07 - val_acc: 1.0000\n",
      "Epoch 1420/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9832e-07 - acc: 1.0000 - val_loss: 1.3292e-07 - val_acc: 1.0000\n",
      "Epoch 1421/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1633e-07 - acc: 1.0000 - val_loss: 1.3298e-07 - val_acc: 1.0000\n",
      "Epoch 1422/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9911e-07 - acc: 1.0000 - val_loss: 1.2939e-07 - val_acc: 1.0000\n",
      "Epoch 1423/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.0960e-07 - acc: 1.0000 - val_loss: 1.2856e-07 - val_acc: 1.0000\n",
      "Epoch 1424/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0264e-07 - acc: 1.0000 - val_loss: 1.2590e-07 - val_acc: 1.0000\n",
      "Epoch 1425/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0149e-07 - acc: 1.0000 - val_loss: 1.2592e-07 - val_acc: 1.0000\n",
      "Epoch 1426/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8837e-07 - acc: 1.0000 - val_loss: 1.2592e-07 - val_acc: 1.0000\n",
      "Epoch 1427/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0244e-07 - acc: 1.0000 - val_loss: 1.2598e-07 - val_acc: 1.0000\n",
      "Epoch 1428/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8662e-07 - acc: 1.0000 - val_loss: 1.2593e-07 - val_acc: 1.0000\n",
      "Epoch 1429/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0029e-07 - acc: 1.0000 - val_loss: 1.2588e-07 - val_acc: 1.0000\n",
      "Epoch 1430/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8307e-07 - acc: 1.0000 - val_loss: 1.2491e-07 - val_acc: 1.0000\n",
      "Epoch 1431/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1503e-07 - acc: 1.0000 - val_loss: 1.2306e-07 - val_acc: 1.0000\n",
      "Epoch 1432/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.2499e-07 - acc: 1.0000 - val_loss: 1.2215e-07 - val_acc: 1.0000\n",
      "Epoch 1433/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.7438e-07 - acc: 1.0000 - val_loss: 1.2120e-07 - val_acc: 1.0000\n",
      "Epoch 1434/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8735e-07 - acc: 1.0000 - val_loss: 1.2292e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1435/10000\n",
      "1139/1139 [==============================] - 0s 55us/step - loss: 1.9227e-07 - acc: 1.0000 - val_loss: 1.2286e-07 - val_acc: 1.0000\n",
      "Epoch 1436/10000\n",
      "1139/1139 [==============================] - 0s 21us/step - loss: 1.8929e-07 - acc: 1.0000 - val_loss: 1.2284e-07 - val_acc: 1.0000\n",
      "Epoch 1437/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8117e-07 - acc: 1.0000 - val_loss: 1.2283e-07 - val_acc: 1.0000\n",
      "Epoch 1438/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.1193e-07 - acc: 1.0000 - val_loss: 1.2283e-07 - val_acc: 1.0000\n",
      "Epoch 1439/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0186e-07 - acc: 1.0000 - val_loss: 1.2275e-07 - val_acc: 1.0000\n",
      "Epoch 1440/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1814e-07 - acc: 1.0000 - val_loss: 1.2363e-07 - val_acc: 1.0000\n",
      "Epoch 1441/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 2.0093e-07 - acc: 1.0000 - val_loss: 1.2176e-07 - val_acc: 1.0000\n",
      "Epoch 1442/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7362e-07 - acc: 1.0000 - val_loss: 1.2174e-07 - val_acc: 1.0000\n",
      "Epoch 1443/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8696e-07 - acc: 1.0000 - val_loss: 1.2261e-07 - val_acc: 1.0000\n",
      "Epoch 1444/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6909e-07 - acc: 1.0000 - val_loss: 1.2258e-07 - val_acc: 1.0000\n",
      "Epoch 1445/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8973e-07 - acc: 1.0000 - val_loss: 1.2164e-07 - val_acc: 1.0000\n",
      "Epoch 1446/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6521e-07 - acc: 1.0000 - val_loss: 1.2070e-07 - val_acc: 1.0000\n",
      "Epoch 1447/10000\n",
      "1139/1139 [==============================] - 0s 13us/step - loss: 1.8612e-07 - acc: 1.0000 - val_loss: 1.2158e-07 - val_acc: 1.0000\n",
      "Epoch 1448/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8839e-07 - acc: 1.0000 - val_loss: 1.2065e-07 - val_acc: 1.0000\n",
      "Epoch 1449/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0863e-07 - acc: 1.0000 - val_loss: 1.2066e-07 - val_acc: 1.0000\n",
      "Epoch 1450/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7352e-07 - acc: 1.0000 - val_loss: 1.2069e-07 - val_acc: 1.0000\n",
      "Epoch 1451/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8758e-07 - acc: 1.0000 - val_loss: 1.2070e-07 - val_acc: 1.0000\n",
      "Epoch 1452/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7245e-07 - acc: 1.0000 - val_loss: 1.2069e-07 - val_acc: 1.0000\n",
      "Epoch 1453/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7792e-07 - acc: 1.0000 - val_loss: 1.1977e-07 - val_acc: 1.0000\n",
      "Epoch 1454/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8538e-07 - acc: 1.0000 - val_loss: 1.1976e-07 - val_acc: 1.0000\n",
      "Epoch 1455/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8882e-07 - acc: 1.0000 - val_loss: 1.1974e-07 - val_acc: 1.0000\n",
      "Epoch 1456/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5310e-07 - acc: 1.0000 - val_loss: 1.1883e-07 - val_acc: 1.0000\n",
      "Epoch 1457/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6549e-07 - acc: 1.0000 - val_loss: 1.1875e-07 - val_acc: 1.0000\n",
      "Epoch 1458/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.8142e-07 - acc: 1.0000 - val_loss: 1.1870e-07 - val_acc: 1.0000\n",
      "Epoch 1459/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8190e-07 - acc: 1.0000 - val_loss: 1.1869e-07 - val_acc: 1.0000\n",
      "Epoch 1460/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8308e-07 - acc: 1.0000 - val_loss: 1.1866e-07 - val_acc: 1.0000\n",
      "Epoch 1461/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.7020e-07 - acc: 1.0000 - val_loss: 1.1866e-07 - val_acc: 1.0000\n",
      "Epoch 1462/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6377e-07 - acc: 1.0000 - val_loss: 1.1859e-07 - val_acc: 1.0000\n",
      "Epoch 1463/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0464e-07 - acc: 1.0000 - val_loss: 1.2036e-07 - val_acc: 1.0000\n",
      "Epoch 1464/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0226e-07 - acc: 1.0000 - val_loss: 1.1849e-07 - val_acc: 1.0000\n",
      "Epoch 1465/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7940e-07 - acc: 1.0000 - val_loss: 1.1849e-07 - val_acc: 1.0000\n",
      "Epoch 1466/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6860e-07 - acc: 1.0000 - val_loss: 1.1845e-07 - val_acc: 1.0000\n",
      "Epoch 1467/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5907e-07 - acc: 1.0000 - val_loss: 1.1843e-07 - val_acc: 1.0000\n",
      "Epoch 1468/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0830e-07 - acc: 1.0000 - val_loss: 1.1842e-07 - val_acc: 1.0000\n",
      "Epoch 1469/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6024e-07 - acc: 1.0000 - val_loss: 1.1837e-07 - val_acc: 1.0000\n",
      "Epoch 1470/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8391e-07 - acc: 1.0000 - val_loss: 1.1839e-07 - val_acc: 1.0000\n",
      "Epoch 1471/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.9133e-07 - acc: 1.0000 - val_loss: 1.1750e-07 - val_acc: 1.0000\n",
      "Epoch 1472/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7757e-07 - acc: 1.0000 - val_loss: 1.1757e-07 - val_acc: 1.0000\n",
      "Epoch 1473/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0230e-07 - acc: 1.0000 - val_loss: 1.1749e-07 - val_acc: 1.0000\n",
      "Epoch 1474/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6048e-07 - acc: 1.0000 - val_loss: 1.1837e-07 - val_acc: 1.0000\n",
      "Epoch 1475/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1132e-07 - acc: 1.0000 - val_loss: 1.1835e-07 - val_acc: 1.0000\n",
      "Epoch 1476/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6506e-07 - acc: 1.0000 - val_loss: 1.1740e-07 - val_acc: 1.0000\n",
      "Epoch 1477/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 1.6552e-07 - acc: 1.0000 - val_loss: 1.1741e-07 - val_acc: 1.0000\n",
      "Epoch 1478/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0681e-07 - acc: 1.0000 - val_loss: 1.1649e-07 - val_acc: 1.0000\n",
      "Epoch 1479/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6123e-07 - acc: 1.0000 - val_loss: 1.1648e-07 - val_acc: 1.0000\n",
      "Epoch 1480/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0728e-07 - acc: 1.0000 - val_loss: 1.1731e-07 - val_acc: 1.0000\n",
      "Epoch 1481/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6066e-07 - acc: 1.0000 - val_loss: 1.1727e-07 - val_acc: 1.0000\n",
      "Epoch 1482/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6369e-07 - acc: 1.0000 - val_loss: 1.1724e-07 - val_acc: 1.0000\n",
      "Epoch 1483/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.0553e-07 - acc: 1.0000 - val_loss: 1.1723e-07 - val_acc: 1.0000\n",
      "Epoch 1484/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7361e-07 - acc: 1.0000 - val_loss: 1.1723e-07 - val_acc: 1.0000\n",
      "Epoch 1485/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9349e-07 - acc: 1.0000 - val_loss: 1.1631e-07 - val_acc: 1.0000\n",
      "Epoch 1486/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6912e-07 - acc: 1.0000 - val_loss: 1.1633e-07 - val_acc: 1.0000\n",
      "Epoch 1487/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8270e-07 - acc: 1.0000 - val_loss: 1.1635e-07 - val_acc: 1.0000\n",
      "Epoch 1488/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7493e-07 - acc: 1.0000 - val_loss: 1.1632e-07 - val_acc: 1.0000\n",
      "Epoch 1489/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7447e-07 - acc: 1.0000 - val_loss: 1.1626e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1490/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5830e-07 - acc: 1.0000 - val_loss: 1.1626e-07 - val_acc: 1.0000\n",
      "Epoch 1491/10000\n",
      "1139/1139 [==============================] - 0s 55us/step - loss: 1.6140e-07 - acc: 1.0000 - val_loss: 1.1627e-07 - val_acc: 1.0000\n",
      "Epoch 1492/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 1.6493e-07 - acc: 1.0000 - val_loss: 1.1626e-07 - val_acc: 1.0000\n",
      "Epoch 1493/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5991e-07 - acc: 1.0000 - val_loss: 1.1625e-07 - val_acc: 1.0000\n",
      "Epoch 1494/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7644e-07 - acc: 1.0000 - val_loss: 1.1622e-07 - val_acc: 1.0000\n",
      "Epoch 1495/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7001e-07 - acc: 1.0000 - val_loss: 1.1620e-07 - val_acc: 1.0000\n",
      "Epoch 1496/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6253e-07 - acc: 1.0000 - val_loss: 1.1619e-07 - val_acc: 1.0000\n",
      "Epoch 1497/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5357e-07 - acc: 1.0000 - val_loss: 1.1619e-07 - val_acc: 1.0000\n",
      "Epoch 1498/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5387e-07 - acc: 1.0000 - val_loss: 1.1618e-07 - val_acc: 1.0000\n",
      "Epoch 1499/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8880e-07 - acc: 1.0000 - val_loss: 1.1618e-07 - val_acc: 1.0000\n",
      "Epoch 1500/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5263e-07 - acc: 1.0000 - val_loss: 1.1616e-07 - val_acc: 1.0000\n",
      "Epoch 1501/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6060e-07 - acc: 1.0000 - val_loss: 1.1615e-07 - val_acc: 1.0000\n",
      "Epoch 1502/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.6127e-07 - acc: 1.0000 - val_loss: 1.1615e-07 - val_acc: 1.0000\n",
      "Epoch 1503/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7418e-07 - acc: 1.0000 - val_loss: 1.1614e-07 - val_acc: 1.0000\n",
      "Epoch 1504/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6472e-07 - acc: 1.0000 - val_loss: 1.1614e-07 - val_acc: 1.0000\n",
      "Epoch 1505/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5296e-07 - acc: 1.0000 - val_loss: 1.1614e-07 - val_acc: 1.0000\n",
      "Epoch 1506/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4024e-07 - acc: 1.0000 - val_loss: 1.1613e-07 - val_acc: 1.0000\n",
      "Epoch 1507/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6286e-07 - acc: 1.0000 - val_loss: 1.1519e-07 - val_acc: 1.0000\n",
      "Epoch 1508/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5568e-07 - acc: 1.0000 - val_loss: 1.1518e-07 - val_acc: 1.0000\n",
      "Epoch 1509/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.6064e-07 - acc: 1.0000 - val_loss: 1.1518e-07 - val_acc: 1.0000\n",
      "Epoch 1510/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5505e-07 - acc: 1.0000 - val_loss: 1.1517e-07 - val_acc: 1.0000\n",
      "Epoch 1511/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6352e-07 - acc: 1.0000 - val_loss: 1.1517e-07 - val_acc: 1.0000\n",
      "Epoch 1512/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 2.1626e-07 - acc: 1.0000 - val_loss: 1.1520e-07 - val_acc: 1.0000\n",
      "Epoch 1513/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6092e-07 - acc: 1.0000 - val_loss: 1.1522e-07 - val_acc: 1.0000\n",
      "Epoch 1514/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5598e-07 - acc: 1.0000 - val_loss: 1.1427e-07 - val_acc: 1.0000\n",
      "Epoch 1515/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6276e-07 - acc: 1.0000 - val_loss: 1.1425e-07 - val_acc: 1.0000\n",
      "Epoch 1516/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7206e-07 - acc: 1.0000 - val_loss: 1.1516e-07 - val_acc: 1.0000\n",
      "Epoch 1517/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6774e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1518/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.6480e-07 - acc: 1.0000 - val_loss: 1.1607e-07 - val_acc: 1.0000\n",
      "Epoch 1519/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6232e-07 - acc: 1.0000 - val_loss: 1.1607e-07 - val_acc: 1.0000\n",
      "Epoch 1520/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7032e-07 - acc: 1.0000 - val_loss: 1.1607e-07 - val_acc: 1.0000\n",
      "Epoch 1521/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8655e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1522/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5207e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1523/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.8451e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1524/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5097e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1525/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7017e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1526/10000\n",
      "1139/1139 [==============================] - 0s 20us/step - loss: 1.5199e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1527/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.5512e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1528/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.7054e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1529/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.7712e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1530/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6259e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1531/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.5628e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1532/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5343e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000\n",
      "Epoch 1533/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4836e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1534/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4581e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1535/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.7417e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1536/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4329e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1537/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4777e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1538/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4938e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1539/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4629e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1540/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4882e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1541/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6102e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1542/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5572e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1543/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5045e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n",
      "Epoch 1544/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.7715e-07 - acc: 1.0000 - val_loss: 1.1419e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1545/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.9861e-07 - acc: 1.0000 - val_loss: 1.1325e-07 - val_acc: 1.0000\n",
      "Epoch 1546/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.4384e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1547/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.4903e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1548/10000\n",
      "1139/1139 [==============================] - 0s 22us/step - loss: 1.6227e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1549/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.7123e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1550/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6291e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1551/10000\n",
      "1139/1139 [==============================] - 0s 14us/step - loss: 1.4396e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1552/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6270e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1553/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6551e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1554/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5611e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1555/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.4595e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1556/10000\n",
      "1139/1139 [==============================] - 0s 44us/step - loss: 1.6528e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1557/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.4312e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1558/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.5021e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1559/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.5697e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1560/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.5185e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1561/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.4422e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1562/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.4776e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1563/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.4632e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1564/10000\n",
      "1139/1139 [==============================] - 0s 62us/step - loss: 1.5578e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1565/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.7334e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1566/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.4146e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1567/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4008e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1568/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.5215e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1569/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.3862e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1570/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.3351e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1571/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.4163e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1572/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4505e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1573/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.3805e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1574/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.5661e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1575/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.4642e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1576/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 2.1259e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1577/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6291e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1578/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.6490e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1579/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.4091e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1580/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5202e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1581/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.3908e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1582/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5016e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1583/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.6316e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1584/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5326e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1585/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4585e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1586/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.7618e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1587/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.4892e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1588/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.3984e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1589/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.4313e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1590/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.4082e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1591/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3875e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1592/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5731e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1593/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4508e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1594/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.4434e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1595/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.3848e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1596/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.4625e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1597/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.4946e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1598/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 1.3422e-07 - acc: 1.000 - 0s 27us/step - loss: 1.4731e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n",
      "Epoch 1599/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4341e-07 - acc: 1.0000 - val_loss: 1.1231e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1600/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.5575e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1601/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.5226e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1602/10000\n",
      "1139/1139 [==============================] - 0s 35us/step - loss: 1.4006e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1603/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.5143e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1604/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4033e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1605/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.4221e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1606/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4954e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1607/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3764e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1608/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.3541e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1609/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.3785e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1610/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4304e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1611/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.3589e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1612/10000\n",
      "1139/1139 [==============================] - 0s 41us/step - loss: 1.4568e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1613/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.5392e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1614/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3636e-07 - acc: 1.0000 - val_loss: 1.1138e-07 - val_acc: 1.0000\n",
      "Epoch 1615/10000\n",
      "1139/1139 [==============================] - 0s 45us/step - loss: 1.7548e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1616/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3683e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1617/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3833e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1618/10000\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 1.3250e-07 - acc: 1.000 - 0s 27us/step - loss: 1.2884e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1619/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.5112e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1620/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3749e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1621/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3670e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1622/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3920e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1623/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.4364e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1624/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.3451e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1625/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3899e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1626/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3540e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1627/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.2959e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1628/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.3544e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1629/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.3656e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1630/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.3406e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1631/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.4311e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1632/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.2996e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1633/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3387e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1634/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.3563e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1635/10000\n",
      "1139/1139 [==============================] - 0s 36us/step - loss: 1.2734e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1636/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.3273e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1637/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.4737e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1638/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.3495e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1639/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.2752e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1640/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.3093e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1641/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.2851e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1642/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.3487e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1643/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.4768e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1644/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.4228e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1645/10000\n",
      "1139/1139 [==============================] - 0s 33us/step - loss: 1.3651e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1646/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.2852e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1647/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.3004e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1648/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.3788e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1649/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.3657e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1650/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.3921e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1651/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.4056e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1652/10000\n",
      "1139/1139 [==============================] - 0s 46us/step - loss: 1.3202e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1653/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3477e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1654/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.3075e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1655/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4720e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1656/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.2580e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1657/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.2872e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1658/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.6622e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1659/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3360e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1660/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.2690e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1661/10000\n",
      "1139/1139 [==============================] - 0s 24us/step - loss: 1.3446e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1662/10000\n",
      "1139/1139 [==============================] - 0s 12us/step - loss: 1.3426e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1663/10000\n",
      "1139/1139 [==============================] - 0s 38us/step - loss: 1.2764e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1664/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4266e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1665/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3229e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1666/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3166e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1667/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.6084e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1668/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3131e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1669/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.4174e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1670/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3270e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1671/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3191e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1672/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.4264e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1673/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2357e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1674/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3527e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1675/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.3742e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1676/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3659e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1677/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2635e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1678/10000\n",
      "1139/1139 [==============================] - 0s 37us/step - loss: 1.4899e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1679/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3475e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1680/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3195e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1681/10000\n",
      "1139/1139 [==============================] - 0s 31us/step - loss: 1.4298e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1682/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.3408e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1683/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.3715e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1684/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.3907e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1685/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3237e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1686/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3139e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1687/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3645e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1688/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.3184e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1689/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2890e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1690/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.3239e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1691/10000\n",
      "1139/1139 [==============================] - 0s 30us/step - loss: 1.3890e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1692/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3212e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1693/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2457e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1694/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.2476e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1695/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.2975e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1696/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3726e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1697/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.4171e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1698/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.3016e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1699/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3734e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1700/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.2073e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1701/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.2851e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1702/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3676e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1703/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3550e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1704/10000\n",
      "1139/1139 [==============================] - 0s 34us/step - loss: 1.3161e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1705/10000\n",
      "1139/1139 [==============================] - 0s 25us/step - loss: 1.3457e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1706/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.2803e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1707/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2619e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1708/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.2590e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1709/10000\n",
      "1139/1139 [==============================] - 0s 26us/step - loss: 1.2894e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1710/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.2621e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1711/10000\n",
      "1139/1139 [==============================] - 0s 32us/step - loss: 1.2749e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1712/10000\n",
      "1139/1139 [==============================] - 0s 27us/step - loss: 1.2525e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1713/10000\n",
      "1139/1139 [==============================] - 0s 29us/step - loss: 1.2939e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1714/10000\n",
      "1139/1139 [==============================] - 0s 28us/step - loss: 1.2097e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 1715/10000\n",
      "1139/1139 [==============================] - 0s 51us/step - loss: 1.2877e-07 - acc: 1.0000 - val_loss: 1.1044e-07 - val_acc: 1.0000\n",
      "Epoch 01715: early stopping\n"
     ]
    }
   ],
   "source": [
    "#hyper parameters\n",
    "validation_data_split = 0.1\n",
    "num_epochs = 10000\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 32\n",
    "early_patience =100\n",
    "\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "\n",
    "# Read Dataset\n",
    "#dataset = pd.read_csv('training.csv')\n",
    "\n",
    "# Process Dataset\n",
    "\n",
    "history1 = model1.fit(SubtractedTrainingDataMatrix\n",
    "                    , SubtractedTrainingTarget\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb,earlystopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 49us/step\n",
      "The Validation Accuracy on the human observed dataset is: 1.0\n",
      "The Validation Loss on the human observed dataset is: 1.0936151575885525e-07\n",
      "157/157 [==============================] - 0s 38us/step\n",
      "The Test Accuracy on the human observed dataset is: 1.0\n",
      "The Test Loss on the human observed dataset is: 1.0991055077534363e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history1.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))\n",
    "\n",
    "\n",
    "test_loss, test_acc = model1.evaluate(SubtractedValidationDataMatrix, SubtractedValidationTarget)\n",
    "print('The Validation Accuracy on the human observed dataset is: ' +str(test_acc))\n",
    "print('The Validation Loss on the human observed dataset is: ' +str(test_loss))\n",
    "\n",
    "\n",
    "test_loss, test_acc = model1.evaluate(SubtractedTestingDataMatrix, SubtractedTestingTarget)\n",
    "print('The Test Accuracy on the human observed dataset is: ' +str(test_acc))\n",
    "print('The Test Loss on the human observed dataset is: ' +str(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the concatenated data set on GSC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ravali pinnaka\\desktop\\python\\lib\\site-packages\\ipykernel_launcher.py:115: DeprecationWarning: 'U' mode is deprecated\n",
      "c:\\users\\ravali pinnaka\\desktop\\python\\lib\\site-packages\\ipykernel_launcher.py:125: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-20d1208b950d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mTestPercent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mConcatenatedTrainingTarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGenerateTrainingTarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawConcatenatedTarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTrainingPercent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mConcatenatedTrainingDataMatrix\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGenerateTrainingDataMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawConcatenatedData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTrainingPercent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The shape of ConcatenatedTrainingTarget is \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConcatenatedTrainingTarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The shape of ConcatenatedTrainingDataMatrix is \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mConcatenatedTrainingDataMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c07bfff4dc91>\u001b[0m in \u001b[0;36mGenerateTrainingDataMatrix\u001b[1;34m(rawData, TrainingPercent)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mGenerateTrainingDataMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainingPercent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[0mT_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mTrainingPercent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[0md2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrawData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mT_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m    \u001b[1;31m# print(str(TrainingPercent) + \"% Training Data Generated..\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0md2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# concatenate('gsc/concatenated_same_pairs.csv','gsc/gsc_same_pairs.csv','gsc/GSC-Features.csv',500)\n",
    "# subtract('gsc/subtracted_same_pairs.csv','gsc/concatenated_same_pairs.csv',500)\n",
    "# concatenate('gsc/concatenated_diff_pairs.csv','gsc/gsc_diffn_pairs.csv','gsc/GSC-Features.csv',502)\n",
    "# subtract('gsc/subtracted_diff_pairs.csv','gsc/concatenated_diff_pairs.csv',502)\n",
    "# combine_pairs('gsc/concatenated_pairs.csv','gsc/concatenated_same_pairs.csv','gsc/concatenated_diff_pairs.csv');\n",
    "# combine_pairs('gsc/subtracted_pairs.csv','gsc/subtracted_same_pairs.csv','gsc/subtracted_diff_pairs.csv');\n",
    "# shuffled_pairs('gsc/shuffled_concatenated_pairs.csv','gsc/concatenated_pairs.csv');\n",
    "# shuffled_pairs('gsc/shuffled_subtracted_pairs.csv','gsc/subtracted_pairs.csv');\n",
    "\n",
    "#RawTarget\n",
    "rawConcatenatedTarget = GetTarget('gsc/shuffled_concatenated_pairs.csv')\n",
    "rawSubtractedTarget = GetTarget('gsc/shuffled_subtracted_pairs.csv')\n",
    "#RawData\n",
    "rawConcatenatedData=GetRawData('gsc/shuffled_concatenated_pairs.csv')\n",
    "rawSubtractedData=GetRawData('gsc/shuffled_subtracted_pairs.csv')\n",
    "# print(rawConcatenatedData.shape)\n",
    "# print(rawSubtractedData.shape)\n",
    "#splitting\n",
    "TrainingPercent=80;\n",
    "ValidationPercent=10;\n",
    "TestPercent=10;\n",
    "ConcatenatedTrainingTarget = np.array(GenerateTrainingTarget(rawConcatenatedTarget,TrainingPercent))\n",
    "ConcatenatedTrainingDataMatrix   = np.transpose(GenerateTrainingDataMatrix(rawConcatenatedData,TrainingPercent))\n",
    "print(\"The shape of ConcatenatedTrainingTarget is \", ConcatenatedTrainingTarget.shape)\n",
    "print(\"The shape of ConcatenatedTrainingDataMatrix is \",ConcatenatedTrainingDataMatrix.shape)\n",
    "\n",
    "ConcatenatedValidationTarget = np.array(GenerateTargetVector(rawConcatenatedTarget,ValidationPercent, (len(ConcatenatedTrainingTarget))))\n",
    "ConcatenatedValidationDataMatrix    =np.transpose(GenerateTargetData(rawConcatenatedData,ValidationPercent, (len(ConcatenatedTrainingTarget))))\n",
    "\n",
    "print(\"The shape of ConcatenatedValidationTarget is \", ConcatenatedValidationTarget.shape)\n",
    "print(\"The shape of ConcatenatedValidationDataMatrix is \",ConcatenatedValidationDataMatrix.shape)\n",
    "ConcatenatedTestingTarget = np.array(GenerateTargetVector(rawConcatenatedTarget,TestPercent, (len(ConcatenatedTrainingTarget)+len(ConcatenatedValidationTarget))))\n",
    "ConcatenatedTestingDataMatrix = np.transpose(GenerateTargetData(rawConcatenatedData,TestPercent, (len(ConcatenatedTrainingTarget)+len(ConcatenatedValidationTarget))))\n",
    "\n",
    "print(\"The shape of ConcatenatedTestingTarget is \", ConcatenatedTestingTarget.shape)\n",
    "print(\"The shape of ConcatenatedTestingDataMatrix is \",ConcatenatedTestingDataMatrix.shape)\n",
    "#subtracted\n",
    "\n",
    "SubtractedTrainingTarget = np.array(GenerateTrainingTarget(rawSubtractedTarget,TrainingPercent))\n",
    "SubtractedTrainingDataMatrix   = np.transpose(GenerateTrainingDataMatrix(rawSubtractedData,TrainingPercent))\n",
    "SubtractedValidationTarget = np.array(GenerateTargetVector(rawSubtractedTarget,ValidationPercent, (len(SubtractedTrainingTarget))))\n",
    "SubtractedValidationDataMatrix    = np.transpose(GenerateTargetData(rawSubtractedData,ValidationPercent, (len(SubtractedTrainingTarget))))\n",
    "SubtractedTestingTarget = np.array(GenerateTargetVector(rawSubtractedTarget,TestPercent, (len(SubtractedTrainingTarget)+len(SubtractedValidationTarget))))\n",
    "SubtractedTestingDataMatrix = np.transpose(GenerateTargetData(rawSubtractedData,TestPercent, (len(SubtractedTrainingTarget)+len(SubtractedValidationTarget))))\n",
    "print(\"The shape of SubtractedTrainingTarget is \", SubtractedTrainingTarget.shape)\n",
    "print(\"The shape of SubtractedTrainingDataMatrix is \",SubtractedTrainingDataMatrix.shape)\n",
    "print(\"The shape of SubtractedValidationTarget is \", SubtractedValidationTarget.shape)\n",
    "print(\"The shape of SubtractedValidationDataMatrix is \",SubtractedValidationDataMatrix.shape)\n",
    "print(\"The shape of SubtractedTestingTarget is \", SubtractedTestingTarget.shape)\n",
    "print(\"The shape of SubtractedTestingDataMatrix is \",SubtractedTestingDataMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_size = 1024 \n",
    "drop_out = 0.2   # to remove overfitting we use dropout\n",
    "first_dense_layer_nodes  = 512 \n",
    "second_dense_layer_nodes = 1\n",
    "\n",
    "def get_model_congsc():\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    \n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('sigmoid')) \n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_model_congsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "validation_data_split = 0.1\n",
    "num_epochs = 10000\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 32\n",
    "early_patience =100\n",
    "\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "\n",
    "# Read Dataset\n",
    "#dataset = pd.read_csv('training.csv')\n",
    "\n",
    "# Process Dataset\n",
    "\n",
    "history2 = model2.fit(ConcatenatedTrainingDataMatrix\n",
    "                    , ConcatenatedTrainingTarget\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb,earlystopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history2.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))\n",
    "\n",
    "\n",
    "\n",
    "test_loss, test_acc = model2.evaluate(ConcatenatedValidationDataMatrix, ConcatenatedValidationTarget)\n",
    "print('The Validation Accuracy on the human observed dataset is: ' +str(test_acc*100))\n",
    "print('The Validation loss on the human observed dataset is: ' +str(test_loss))\n",
    "\n",
    "test_loss, test_acc = model2.evaluate(ConcatenatedTestingnDataMatrix, ConcatenatedTestingTarget)\n",
    "print('The Testing Accuracy on the human observed dataset is: ' +str(test_acc*100))\n",
    "print('The Testing loss on the human observed dataset is: ' +str(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model on difference of datasets on GSC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_size = 512\n",
    "drop_out = 0.2   # to remove overfitting we use dropout\n",
    "first_dense_layer_nodes  = 512 \n",
    "second_dense_layer_nodes = 1\n",
    "\n",
    "def get_model_difgsc():\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    \n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('sigmoid')) \n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = get_model_difgsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_split = 0.1\n",
    "num_epochs = 10000\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 32\n",
    "early_patience =100\n",
    "\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "\n",
    "# Read Dataset\n",
    "#dataset = pd.read_csv('training.csv')\n",
    "\n",
    "# Process Dataset\n",
    "\n",
    "history3 = model3.fit(SubtractedTrainingDataMatrix\n",
    "                    , SubtractedTrainingTarget\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb,earlystopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))\n",
    "\n",
    "test_loss, test_acc = model3.evaluate(SubtractedValidationDataMatrix, SubtractedValidationTarget) \n",
    "print('The Validation Accuracy on the human observed dataset is: ' +str(test_acc))\n",
    "print('The Validation Loss on the human observed dataset is: ' +str(test_loss))\n",
    "\n",
    "test_loss, test_acc = model3.evaluate(SubtractedTestingDataMatrix, SubtractedTestingTarget)\n",
    "print('The Testing Accuracy on the human observed dataset is: ' +str(test_acc))\n",
    "print('The Testing loss on the human observed dataset is: ' +str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
